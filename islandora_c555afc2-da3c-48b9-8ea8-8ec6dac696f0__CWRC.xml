<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="https://cwrc.ca/templates/css/tei.css" type="text/css"?>
<?xml-model href="https://cwrc.ca/schemas/cwrc_tei_lite.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:cw="http://cwrc.ca/ns/cw#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xml:id="j2z_msz_g1b">


    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>Advancing Linked Open Data in the Humanities</title>
            </titleStmt>
            <publicationStmt>
                <publisher>
                    <orgName role="publisher">Canadian Writing Research Collaboratory</orgName>
                    <address>
                        <addrLine>www.cwrc.ca</addrLine>
                    </address>
                </publisher>
                <availability>
                    <p xml:id="vjz_msz_g1b">Creative Commons CC-BY-NC</p>
                </availability>
            </publicationStmt>
            <sourceDesc>
                <p xml:id="wjz_msz_g1b">This is where the ToC info should go, in a listBibl tag.</p>
            </sourceDesc>
        </fileDesc>
        <xenoData>
<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:cw="http://cwrc.ca/ns/cw#">
<rdf:Description rdf:about="https://cwrc.ca/sites/default/modules/islandora_cwrc_writer/build/editor/documents/islandora:c555afc2-da3c-48b9-8ea8-8ec6dac696f0">
	<cw:mode>0</cw:mode>
	<cw:allowOverlap>false</cw:allowOverlap>
</rdf:Description></rdf:RDF></xenoData><encodingDesc>
            <projectDesc>
                <p xml:id="xjz_msz_g1b"/>
            </projectDesc>
            <classDecl>
                <taxonomy>
                    <desc>Library and Archives Canada Cataloguing in Publication</desc>
                </taxonomy>
            </classDecl>
        </encodingDesc>
        <profileDesc>
            <langUsage>
                <language ident="en-CA">English</language>
            </langUsage>
        </profileDesc>
    </teiHeader>
    <text>
        <front>
            <figure>
                <graphic url="https://beta.cwrc.ca/islandora/object/cwrc%3A3a7e1597-5ca0-4062-a900-a7a1b5c7d4af/datastream/MEDIUM_SIZE/view"/>
            </figure>
            <titlePage>
                <byline><docAuthor><hi rend="italic">A DH2017 Workshop</hi></docAuthor></byline>
            </titlePage>
            <div>
                <head><title level="m"><hi rend="bold">Advancing Linked Open Data in the Humanities </hi></title></head>
                <p xml:id="yjz_msz_g1b">Since its inception, Linked Open Data (LOD) has been primarily about publishing and defining data standards. As the technologies have matured and the amount of data available for consumption has dramatically increased, questions of consumption and processing are now at the forefront.</p>
                <p xml:id="zjz_msz_g1b">For this workshop at DH2017 in Montreal, we invited scholars working on LOD projects within the larger spectrum of the humanities to participate in a workshop that aimed to understand the limits of current work in this area and possible ways forward.</p>
                <p xml:id="akz_msz_g1b">We asked participants to consider questions such as:</p>
                <list>
                    <item> What will scholars do with a large universe of linked open data? </item>
                    <item> What initiatives are needed? Which tools do we need most? </item>
                    <item> If we consider access, discovery, and search to be solved (although that is debatable) what is missing to enable humanities scholars to benefit more from the turn to LOD? </item>
                </list>
                <p xml:id="bkz_msz_g1b">Susan Brown, for the Workshop Program Committee:</p>
                <p xml:id="ckz_msz_g1b"><persName>Stacy Allison-Cassin</persName>, <orgName>York University</orgName>; <persName>Susan Brown</persName>, <orgName>University of Guelph</orgName>; <persName>Abigel Lemak</persName>, <orgName>University of Guelph</orgName>; <persName>Kim Martin</persName>, <orgName>University of Guelph</orgName>; <persName>John Simpson</persName>, <orgName>Compute Canada</orgName>; <persName>Rob Warren</persName>, <orgName>University of Guelph</orgName>.</p>
                <p xml:id="ekz_msz_g1b">Text preparation and encoding assistance: <persName>Micaela Jimenez</persName>, <orgName>University of Guelph</orgName>.</p>
                <p xml:id="p_z2x_m3q_h1b"><hi rend="italic">Image source: Linking Open Data cloud diagram 2017, by <persName>Andrejs Abele</persName>, <persName>John P. McCrae</persName>, <persName>Paul Buitelaar</persName>, <persName>Anja Jentzsch</persName> and <persName>Richard Cyganiak</persName>. <ref target="http://lod-cloud.net/">http://lod-cloud.net/</ref> . License: CC BY-SA.</hi></p>
            </div>
        </front>
        <body>
            <div type="chapter">
                <head><title level="m">SCHEDULE</title></head>
                <p xml:id="p_q1f_yts_p1b"><title level="m"><hi rend="bold">SCHEDULE</hi></title></p>
                <table rows="0" cols="3">
                    <head rend="bold"><hi rend="italic">Monday, August 7th, 1:30-5pm</hi></head>
                    <row>
                        <cell role="label"><hi rend="bold">Workshop Introduction</hi></cell>
                        <cell/>
                        <cell>10 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Pecha Kuchas #1</hi></cell>
                        <cell>
                            <list>
                                <item> Goddard</item>
                                <item> Middle</item>
                                <item> Brown</item>
                                <item> Han et al.</item>
                                <item> Crompton / Schwartz</item>
                            </list>
                        </cell>
                        <cell>25 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Transition</hi></cell>
                        <cell/>
                        <cell>5 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Workshop sessions #1</hi></cell>
                        <cell>
                            <p xml:id="p_lzz_gzs_p1b"><hi rend="italic">Workshop 1A.</hi> From Production to Consumption (Tools) </p>
                            <p xml:id="p_mw2_qzs_p1b">***</p>
                            <p xml:id="p_ekd_gzs_p1b"><hi rend="italic">Workshop 1B.</hi> TEI to Linked Data</p>
                        </cell>
                        <cell>50 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Break (eat snacks during next session)</hi></cell>
                        <cell/>
                        <cell>10 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Pecha Kuchas #2</hi></cell>
                        <cell>
                            <list>
                                <item> Garcia</item>
                                <item> Murphy</item>
                                <item> Hedley</item>
                                <item> Allison-Cassin / Kirchner</item>
                                <item> Nurmikko-Fuller et al.</item>
                            </list>
                        </cell>
                        <cell>25 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Transition</hi></cell>
                        <cell/>
                        <cell>5 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Workshop sessions #2</hi></cell>
                        <cell>
                            <p xml:id="p_nfb_jzs_p1b"><hi rend="italic">Workshop 2A.</hi> Natural Language GUI for SPARQL</p>
                            <p xml:id="p_gv1_rzs_p1b">***</p>
                            <p xml:id="p_xkx_3zs_p1b"><hi rend="italic">Workshop 2B.</hi> Politics of Ontologies: Homogeneity, Heterogeneity, Intersectionality</p>
                        </cell>
                        <cell>50 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Regroup, report and discuss next steps</hi></cell>
                        <cell/>
                        <cell>30 min.</cell>
                    </row>
                    <row>
                        <cell role="label"><hi rend="bold">Total</hi></cell>
                        <cell/>
                        <cell>3.5 hours</cell>
                    </row>
                </table>
            </div>
            <div type="chapter">
                <head><title level="m">CONTRIBUTOR AND PROJECT PROFILES</title></head>
                <figure>
                    <graphic url="http://beta.cwrc.ca/islandora/object/cwrc%3Acf544d9c-3d7d-4713-8c5e-92b7d9626761/datastream/MEDIUM_SIZE/view"/>
                </figure>
                <p xml:id="fkz_msz_g1b"><title level="m"><hi rend="bold">CONTRIBUTOR AND PROJECT PROFILES</hi></title></p>
                <p xml:id="gkz_msz_g1b">Contributors were asked to provide a summary of their work in Linked Open Data to date, with an emphasis on current projects.</p>
                <p xml:id="p_wcl_r3q_h1b"><hi rend="italic">Image source: <ref target="http://www.publicdomainpictures.net/pictures/60000/velka/networking-diagram.jpg">http://www.publicdomainpictures.net/pictures/60000/velka/networking-diagram.jpg</ref>. License: CC0 Public Domain.</hi></p>
            </div>
            <div type="chapter">
                <head><title level="a">Advancing social justice in the LAM, Wikipedia, and Wikidata communities through linked data </title></head>
                <docAuthor><hi rend="italic"><persName>Stacy Allison-Cassin</persName>, <persName>Joy Kirchner</persName></hi>, <orgName>York University</orgName></docAuthor>
                <p xml:id="p_zds_j11_h1b"><hi rend="bold">Advancing social justice in the LAM, Wikipedia, and Wikidata communities through linked data</hi></p>
                <p xml:id="p_a2s_j11_h1b"><hi rend="italic"><persName>Stacy Allison-Cassin</persName>, <persName>Joy Kirchner</persName>, <orgName>York University</orgName></hi></p>
                <p xml:id="p_h2s_j11_h1b">Website: <ref target="http://yorku.ca/library">http://yorku.ca/library</ref></p>
                <p xml:id="p_i2s_j11_h1b">Keywords: Wikidata, libraries, diversity, cultural heritage, archives</p>
                <p xml:id="p_o2s_j11_h1b">York University is leading a project with the <orgName>Association of Research Libraries</orgName> to model a collaborative and inclusive approach to creating linked data for special collections, focusing on diverse and underrepresented populations and more specifically on indigenous communities in North America. Across the library, archive, and museum (LAM) community, a strong commitment to diversity, inclusion and social justice has surfaced attention to description as an area where bias and inequality are replicated or reified.</p>
                <p xml:id="p_p2s_j11_h1b">To maximize exposure of linkable structured data, the inclusiveness of its creation, and its usability across the network, this project will collaborate within the Wikimedia community to use Wikidata as the global, openly licensed knowledgebase where the data can be deposited, queried and reused. Goals for the project include 1) stronger community participation and agency in archival description, 2) advancement of linked open data within the LAM community and alignment with social justice work, and 3) the creation of referenced structured data that can be used to connect reliable sources with topics to help justify “notability” in <orgName>Wikipedia</orgName> in order to redress a known diversity gap in Wikipedia’s coverage.</p>
                <p xml:id="p_w2s_j11_h1b">An open, collaborative data set is necessary for advancing the LOD work of libraries and researchers, particularly for archival and unique materials, because existing data structures and environments tend to favour those with high-level metadata skills and tools, library-specific metadata schemas, highly customized ontologies and can lead to the unintended creation of data silos.</p>
            </div>
            <div type="chapter">
                <head><title level="a">Collaborative Linked Data Infrastructures</title></head>
                <docAuthor><hi rend="italic"><persName>Susan Brown</persName></hi>, <orgName>University of Guelph</orgName></docAuthor>
                <p xml:id="ppz_msz_g1b"><hi rend="bold">Collaborative Linked Data Infrastructures</hi></p>
                <p xml:id="qpz_msz_g1b"><hi rend="italic"><persName>Susan Brown</persName>, <orgName>University of Guelph</orgName></hi></p>
                <p xml:id="rpz_msz_g1b">Website: <ref target="http://ualberta.ca/orlando">http://ualberta.ca/orlando</ref>; <ref target="http://orlando.cambridge.org">http://orlando.cambridge.org</ref>; <ref target="http://beta.crwrc.ca">http://beta.crwrc.ca</ref></p>
                <p xml:id="spz_msz_g1b">Keywords: infrastructure, collaboration, women's writing</p>
                <div type="section">
                    <head>The Orlando Project</head>
                    <p xml:id="tpz_msz_g1b"><orgName>The Orlando Project</orgName>’s longstanding experiment in feminist literary history has produced a richly tagged set of documents describing the lives, biographies, bibliographies, and historical contexts of 1300+ writers. We are extracting hundreds of thousands of triples from relationships embedded in the XML tags, and retaining links to their context by adapting the Web Annotation Data Model.</p>
                </div>
                <div type="section">
                    <head>The Canadian Writing Research Collaboratory</head>
                    <p xml:id="upz_msz_g1b"><orgName>The Canadian Writing Research Collaboratory (CWRC)</orgName>, launched in Fall 2016, is an online virtual research environment designed to support digital literary and cultural scholarship in a range of forms. Its online environment is designed to be usable by mainstream literary scholars, individually or in teams, working with a sustainable model for born-digital scholarship and the digitization of cultural heritage materials. CWRC supports work with images, audio, and video, but is focused on textual scholarship including born digital scholarship, bibliography, editing, and the digitization through scanning of existing manuscript or print texts, optical character recognition, transcription, and markup of those texts. CWRC supports individual project identities through separate collections and home pages, and aims to provide linkages across projects through common data formats, use of linked open data identifiers, and open annotations.</p>
                    <p xml:id="vpz_msz_g1b">I am strongly committed to exploring the potential of the semantic web for wide-spread uptake by scholars in the humanities. To do so we need better infrastructure to support non-expert participation and we will get better infrastructure through collaboration.</p>
                </div>
                <div type="section">
                    <head>
                        LINCS: Linked Infrastructure for Networked Cultural Scholarship
                    </head>
                    <p xml:id="wpz_msz_g1b"><orgName>Linked Infrastructure for Networked Cultural Scholarship (LINCS)</orgName> is a project being proposed to the <orgName>Canada Foundation for Innovation</orgName>, which funds infrastructure for the humanities, under their <orgName>Cyberinfrastructure Program</orgName>. We will know in July whether we are invited to go forward with a full application. Regardless, we are very interested to learn what other initiatives for LOD infrastructure we can learn from and what existing tools or platform components we might adapt. LINCS aims to mobilize large data sets to catalyze basic and translational humanities research by producing a LOD ecosystem for humanities research that integrates researcher and institutional datasets for access, analysis, and visualization. LINCS will develop:</p>
                    <list>
                        <item> A scalable and extensible Canadian linked data store connecting to and mobilizing a large body of cultural data.</item>
                        <item> Core tools for converting existing datasets to linked data.</item>
                        <item> A set of interfaces to serve everyone from casual users to mainstream scholars to digital humanists.</item>
                    </list>
                </div>
                <div type="section">
                    <head>In connection with this work we have produced the following:</head>
                    <p xml:id="xpz_msz_g1b"><hi rend="bold">CWRC-Writer</hi>: an in-browser WYSIWYG XML editor that also produces LOD annotations for named entities using the <title>Open Annotation Data Model</title>. The CWRC-Writer javascript application is designed to integrate easily with a range of software stacks using delegators and APIs. A version that runs straight out of Github will be released shortly. We have technical support for adoption of CWRC-Writer by other projects.</p>
                    <p xml:id="ypz_msz_g1b"><hi rend="italic">Codebase:</hi> <ref target="https://github.com/jchartrand/CWRC-WriterBase">https://github.com/jchartrand/CWRC-WriterBase</ref>; <ref target="https://github.com/cwrc/CWRC-Writer">https://github.com/cwrc/CWRC-Writer</ref></p>
                    <p xml:id="zpz_msz_g1b"><hi rend="italic">Github configuration:</hi> <ref target="https://github.com/jchartrand/cwrc-gitwriter">https://github.com/jchartrand/cwrc-gitwriter</ref></p>
                    <p xml:id="aqz_msz_g1b"><hi rend="bold"><orgName>Islandora</orgName> modules</hi> for such things as entity lookup and entity management. Various modules within <ref target="https://github.com/cwrc">https://github.com/cwrc</ref></p>
                    <p xml:id="bqz_msz_g1b"><hi rend="bold">Named Entity Recognition Vetting Environment (NERVE):</hi> a web service that takes XML files (currently only the TEI and Orlando schemas), runs them through the Stanford NER tool, and provides the user with a GUI that will allow them to add, remove, or re-class entities, and to link them to LOD authorities. The identifiers currently go into attributes of the XML tags but the goal is to make it possible to produce stand-off Web Annotations as well or instead. <ref target="http://dh.sharcnet.ca/nerve/">http://dh.sharcnet.ca/nerve/</ref>; <ref target="https://github.com/cwrc/NERVE">https://github.com/cwrc/NERVE</ref></p>
                    <p xml:id="cqz_msz_g1b"><hi rend="bold">Orlando Women's Writing linked dataset:</hi> produced with an extraction script from 8 million words of XML-encoded scholarly born-digital text regarding women's writing in the British Isles from the Beginnings to the Present.</p>
                    <p xml:id="dqz_msz_g1b"><hi rend="italic">Datahub site:</hi> <ref target="http://datahub.io/dataset/orlando-womens-writing-linked-open-data-set">http://datahub.io/dataset/orlando-womens-writing-linked-open-data-set</ref></p>
                    <p xml:id="eqz_msz_g1b"><hi rend="bold">CWRC ontology:</hi> currently in progress but available at <ref target="http://sparql.cwrc.ca">http://sparql.cwrc.ca</ref>; <ref target="https://github.com/cwrc/ontology">https://github.com/cwrc/ontology</ref></p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Nice to Have: Easing the Conversion of LOD to TEI</title></head>
                <docAuthor><hi rend="italic"><persName>Constance Crompton</persName></hi>, <orgName>University of Ottawa</orgName>; <hi rend="italic"><persName>Michelle Schwartz</persName></hi>, <orgName>Ryerson University</orgName></docAuthor>
                <p xml:id="o4z_msz_g1b"><hi rend="bold">Nice to Have: Easing the Conversion of LOD to TEI</hi></p>
                <p xml:id="p4z_msz_g1b"><hi rend="italic"><persName>Constance Crompton</persName>, <orgName>University of Ottawa</orgName>; <persName>Michelle Schwartz</persName>, <orgName>Ryerson University</orgName></hi></p>
                <p xml:id="q4z_msz_g1b">Website: <ref target="http://lglc.ca">http://lglc.ca</ref></p>
                <p xml:id="r4z_msz_g1b">Keywords: TEI, graph databases, queer studies, Canada</p>
                <div type="section">
                    <p xml:id="s4z_msz_g1b">We represent the <orgName>Lesbian and Gay Liberation in Canada (LGLC)</orgName> research team. The LGLC project reconfigures <persName>Donald McLeod</persName>’s remarkable monograph, <title level="j">Lesbian and Gay Liberation In Canada: A Selected Annotated Chronology, 1964-1981</title> as a TEI-encoded resource and graph database. The text consists of event records spanning from the founding of the first homophile associations in <placeName>Canada</placeName> through to the start of the AIDS crisis, which we have augmented with gazetteers, prosopographies and other contextual 'ographies. Our data will be "LOD ready" following two shortcomings: 1) while our 34,000 entities all have URIs, most don't resolve to anything machine- or human readable- on the web and 2) the relationships in a database are bespoke and are as yet not mapped onto existing ontologies. We are keen to talk through where our LOD might go for maximum utility once it is created.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Zeri &amp; LODE</title></head>
                <docAuthor><hi rend="italic"><persName>Marilena Daquino</persName></hi>, <orgName>CRR-MM - University of Bologna</orgName>; <hi rend="italic"><persName>Francesca Mambelli</persName></hi>, <orgName>Fondazione Federico Zeri - University of Bologna</orgName>; <hi rend="italic"><persName>Silvio Peroni</persName></hi>, <orgName>Department of Computer Science and Engineering - University of Bologna</orgName>; <hi rend="italic"><persName>Francesca Tomasi</persName></hi>, <orgName>Department of Classical Philology and Italian Studies - University of Bologna - Italy</orgName>; <hi rend="italic"><persName>Fabio Vitali</persName></hi>, <orgName>Department of Computer Science and Engineering - University of Bologna</orgName></docAuthor>
                <p xml:id="p_xlg_v3n_kbb"><hi rend="bold">Zeri &amp; LODE</hi></p>
                <p xml:id="p_qzp_hjm_kbb"><hi rend="italic"><persName>Marilena Daquino</persName>, <orgName>CRR-MM - University of Bologna</orgName>; <persName>Francesca Mambelli</persName>, <orgName>Fondazione Federico Zeri - University of Bologna</orgName>; <persName>Silvio Peroni</persName>, <orgName>Department of Computer Science and Engineering - University of Bologna</orgName>; <persName>Francesca Tomasi</persName>, <orgName>Department of Classical Philology and Italian Studies - University of Bologna - Italy</orgName>; <persName>Fabio Vitali</persName>, <orgName>Department of Computer Science and Engineering - University of Bologna</orgName>, <orgName>Laurentian University</orgName></hi> </p>
                <p xml:id="p_rzp_hjm_kbb">Website: <ref target="http://data.fondazionezeri.unibo.it/">http://data.fondazionezeri.unibo.it/</ref></p>
                <p xml:id="p_szp_hjm_kbb">Keywords: photo archive, ontology, authorship, attribution</p>
                <div type="section">
                    <p xml:id="p_g31_2km_kbb">My work on Zeri summarizes my interest in LOD as a possibility of interlinking between GLAMs. In fact the <orgName>Zeri &amp; LODE</orgName> project is a first and in fieri attempt to concretely realize a semantic integration between cultural heritage domains (galleries, libraries, archives, museums), aiming at representing heterogeneous information in the wide scenario of Linked Open Data.</p>
                    <p xml:id="p_h31_2km_kbb">In this context, by defining as much as possible exhaustive and cross-domain ontologies for the cultural heritage domain we want to provide theoretical and technical bases to several stakeholders. Thus results are applicable and reusable by other cultural institutions than photo archives. It can be considered as a mapping of terms from existent vocabularies wherein peculiarities and traditions of each single domain are preserved, so as to enable a comprehensive description of complex scenarios – and the Zeri Photo Archive can be considered a representative example.</p>
                    <p xml:id="p_i31_2km_kbb">Moreover, by publishing a RDF dataset we want to offer another practical support to institutions, who can reuse data in similar projects. Current dataset includes about 11 million triples describing mainly photographs, artworks, artists, people and corporate bodies involved in events, and relations between cultural objects and documents (books, journals, archival documentation, etc.). Main entities were recognized and linked to online authority records (<orgName>VIAF</orgName>, <orgName>Getty ULAN</orgName>, <orgName>GeoNames</orgName>), datasets (from <orgName>Dbpedia</orgName> and <orgName>Wikidata</orgName>) and web resources (Zeri Catalog web pages and <orgName>Wikipedia</orgName> pages). Terms referring to materials, artistic technics and types of objects are aligned to relevant thesauri, like <title>Getty AAT</title>.</p>
                    <p xml:id="p_j31_2km_kbb">The final goal of the project is the realization of new instruments for research and discovery by means of Semantic Web technologies, also contributing to highlight information not yet represented in a meaningful way. Indeed, the description of cataloguing process is enhanced by annotating subjective aspects underlying questionable attributions, as it is one of the most interesting topics for final users of such kind of archives, i.e. focused on art history. Information like how technical analysis on photographs was performed, which archival classification was chosen, or which opinion of art critics was provided by cataloguers to support attributions, are all fundamental points to reflect on with the perspective of the conversion into Linked Open Data.</p>
                    <p xml:id="p_k31_2km_kbb">In fact, Semantic Web enables the coexistence of contradictory statements about the same subject, as provided by different authors that can be considered less or more authoritative. Therefore how to ensure data quality, trustiness and provenance is something we have to manage, in order to avoid inconsistencies when merging heterogeneous knowledge bases and to identify which cultural institution provides the most authoritative information. This issue was taken into account when formalizing the HiCO model, so as to ensure a correct management of contradictory information.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Cultural Contact in Early Roman Spain through Linked Open Data</title></head>
                <docAuthor><hi rend="italic"><persName>Paula Loreto Granados García</persName></hi>, <orgName>The Open University</orgName></docAuthor>
                <p xml:id="ilz_msz_g1b"><hi rend="bold">Cultural Contact in Early Roman Spain through Linked Open Data</hi></p>
                <p xml:id="jlz_msz_g1b"><hi rend="italic"><persName>Paula Loreto Granados García</persName></hi></p>
                <p xml:id="klz_msz_g1b">Website: <ref target="http://open.ac.uk">http://open.ac.uk</ref></p>
                <p xml:id="llz_msz_g1b">Keywords: cultural contact, Early Roman <placeName>Spain</placeName>, linked open data, data integration</p>
                <div type="section">
                    <p xml:id="mlz_msz_g1b">I am a research student at the <orgName>Open University</orgName>, department of Classics and my research title is “<title>Cultural Contact in Early Roman Spain through Linked Open Data</title>”. My study looks at the Roman colonisation of the <placeName>Iberian Peninsula</placeName> with a special emphasis on examination of cultural contact and identity development through the application of Linked Open Data technology. My doctoral work involves a comprehensive analysis of cultural, social and political contacts in Early Roman <placeName>Spain</placeName> by means of connection to and creation of Linked Data resources. The application of Linked Open Data to Spanish databases and the integration of these with existing research methodologies can provide large amounts of contextualised data in a fixed standard and open format. This Linked and Open complex of databases will allow the establishment of effective relations within large amounts of data making possible multifaceted and richer queries that will contribute to our knowledge of the cultural dynamics in Spain at a level never envisaged before. So far, my work on Linked Open Data has been focused on the access and manipulation of online Linked Data resources: first, I have been looking at different projects and Open Linked databases to evaluate them and assess to what extend these projects fulfil the standards of LOD and therefore can be integrated in my research. Furthermore, I have been looking at the standards that Linked Open data requires to be modelled and published online and how these could be fulfilled by other databases that still do not produce LOD. During this year, I have also been working on the development of a Pilot Project on the province of <placeName>Baetica</placeName> in the south of Spain by the linkage of the data coming from different projects such as: <orgName>Pelagios</orgName>, <orgName>EDH</orgName>, <orgName>Arachne</orgName>, <orgName>NOMISMA</orgName> and <orgName>DARE</orgName>. I have been looking at the possible gaps and errors in the data and finding new ways of implementing the data coming from these repositories. During the cataloguing of the resources I am looking at, I have come up with several issues related to some of the databases that can present barriers in the users' access especially from the point of view of the archaeologist, as it is my case. Some of the resources I work with present problems in the access of the data or do not provide an API or a SPARQL endpoint, which is the interface developed to query the data through SPARQL. The non-incorporation of this tool undermines significantly the usability of the data and therefore the benefits that LOD can offer.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Trismegistos, a Linked Open Data environment for metadata on Ancient World Texts</title></head>
                <docAuthor><hi rend="italic">Tom Gheldof</hi>, <orgName>KU Leuven/DARIAH-BE</orgName></docAuthor>
                <p xml:id="dmz_msz_g1b"><hi rend="bold">Trismegistos, a Linked Open Data environment for metadata on Ancient World Texts</hi></p>
                <p xml:id="emz_msz_g1b"><hi rend="italic"><persName>Tom Gheldof</persName>, <orgName>KU Leuven/DARIAH-BE</orgName></hi></p>
                <p xml:id="fmz_msz_g1b">Website: <ref target="http://trismegistos.org">http://trismegistos.org</ref></p>
                <p xml:id="gmz_msz_g1b">Keywords: ancient history, digital humanities, ancient world texts, metadata, linked open data</p>
                <div type="section">
                    <p xml:id="hmz_msz_g1b"><orgName>Trismegistos</orgName> (TM) is a metadata platform for the study of texts from the Ancient World, coordinated and maintained by the <orgName>KU Leuven research group of Ancient History</orgName>. Originating from the <orgName>Prosopographia Ptolemaica</orgName>, TM was developed in 2005 as a database containing information about people mentioned in papyrus documents from Ptolemaic <placeName>Egypt</placeName>. In other related databases additional information about these texts was found: when they were written (dates), where they are stored (collections) and to which archive they belong (archives). The following years, more (meta)data from epigraphical sources were added to these databases, for example as the result of collaborating with other scientific partners in the Europeana project <orgName>EAGLE</orgName>.</p>
                    <p xml:id="imz_msz_g1b">With over 700,000 entries, it is currently not feasible to keep all data up to date. The philosophy of TM is to bring everything together into a single system and provide links to partner projects, where more details can be found. The online platform thus has two important goals: firstly it functions as an aggregator of metadata for which it also links to other projects (e.g. <orgName>Papyrological Navigator</orgName> from <orgName>Duke University</orgName> for papyri and the <orgName>Epigraphic Database</orgName> from <orgName>Heidelberg University</orgName> for epigraphy), secondly it can be used as an identifying tool for all of its content, such as Ancient World texts, places and people.</p>
                    <p xml:id="jmz_msz_g1b">With its unique identifying numbers and stable URI's, TM also bridges the gap between the different digital representations of Ancient World texts in several projects and aims to set a standard for linking to many aspects of the written sources from Ancient History. Currently, the project is focussing on developing a platform to bridge the gap between Academia and Museums. Many museums have put large parts of their material online, making them effectively accessible to scholars and the general public. Yet the detailed information of the academic projects still remains in a separate, hard-to-find silo. In cooperation with the Egyptian Department, Trismegistos has included all data of the papyri and related objects of the <orgName>British Museum</orgName>, and has connected these with the academic projects studying them. Something similar is currently being done for the <placeName>Vienna</placeName> papyrus collection, but it is hoped that more and more of these cooperations will progressively disclose all the available material, both to academics and to the general public.</p>
                    <p xml:id="kmz_msz_g1b">Trismegistos has also become a pilot project within the recently founded <orgName>DARIAH</orgName> project in <placeName>Belgium</placeName>. One of its contributions to the global DARIAH consortium in Europe is the sharing of the Trismegistos linked data, for example via vocabularies set up during the Europeana project EAGLE that focussed on epigraphic texts and their metadata or via its partnership with the <orgName>PELAGIOS</orgName> consortium that links together gazetteers of place names, which the Trismegistos Places (<ref target="http://www.trismegistos.org/geo">http://www.trismegistos.org/geo</ref>), a collections of Ancient World place names, is a subset of.</p>
                    <p xml:id="lmz_msz_g1b">In the near future, Trismegistos hopes to make much more of its datasets available in various LOD formats and under a CC-BY license (which is in the pipeline). TM is also constantly on the lookout for new partnerships with both established and new stakeholders, not only in the field of (Ancient History) DH, but in the broader domain of cultural heritage as well.</p>
                </div>
            </div>
            <div type="chapter">
                <head>Library Linked Data Using Fedora-Based Digital Asset Management</head>
                <docAuthor><hi rend="italic"><persName>Lisa Goddard</persName></hi>, <orgName>University of Victoria Libraries</orgName></docAuthor>
                <p xml:id="hkz_msz_g1b"><hi rend="bold">Library Linked Data Using Fedora-Based Digital Asset Management</hi></p>
                <p xml:id="ikz_msz_g1b"><hi rend="italic"><persName>Lisa Goddard</persName>, <orgName>University of Victoria Libraries</orgName></hi></p>
                <p xml:id="jkz_msz_g1b">Website: <ref target="http://uvic.ca/library/">http://uvic.ca/library/</ref></p>
                <p xml:id="kkz_msz_g1b">Keywords: linked data, RDF, digital asset management, Hydra, metadata, libraries</p>
                <div type="section">
                    <head>Biography:</head>
                    <p xml:id="lkz_msz_g1b"><persName>Lisa Goddard</persName> is the Associate University Librarian for Digital Scholarship and Strategy at <orgName>University of Victoria Libraries</orgName>. She was previously the Head of Library Systems at <orgName>Memorial University of Newfoundland</orgName>. She holds degrees from <orgName>Queen's</orgName>, <orgName>McGill</orgName>, and <orgName>Memorial University</orgName>. Lisa’s research interests include open access publishing, semantic web technologies, digital publishing and preservation, and digital humanities.</p>
                </div>
                <div type="section">
                    <head>Summary of work:</head>
                    <p xml:id="mkz_msz_g1b">I have had a research interest in linked data since <date when="2008">2008</date>, when I began to deliver conference presentations to introduce librarians to some of the foundational concepts and technologies underlying what we then called the “semantic web”. In <date when="2010">2010</date> I published an article in the journal <title level="j">D-Lib</title> which was one of the early works on libraries and linked data. I was on the organizing committee for the <title>LOD/LAM Summit</title> that took place in <placeName>Montreal</placeName> in 2010. In 2011/12 I was fortunate to work as a GA on the <orgName>CWRC</orgName> project with <persName>Dr. Susan Brown</persName>. I later presented on this work at the <title>Access Conference</title> in 2012. I’m currently implementing the <orgName>Hydra Digital Asset Management System</orgName> that is based on the <orgName>Fedora 4</orgName> repository platform. Fedora stores metadata in key/value pairs that translate very easily into RDF triples. I’m working closely with our Head of Metadata to develop and deploy a data model that leverages linked vocabularies. Our model incorporates the contextual fonds-level metadata that is important to archivists, along with object level metadata that is critical for web discovery. As we migrate our existing collections and metadata we’re planning a significant data cleanup project that will transform our existing structured data into linked data. This linked data will be exposed through a local triple store. We hope to harvest and expose other linked data sets created at <orgName>UVic</orgName> and beyond, and to work on linking those datasets to make it easier to explore seamlessly across collections, and to uncover new connections across topics and disciplines.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Linked Pasts</title></head>
                <docAuthor><hi rend="italic"><persName>Karl Grossner</persName></hi>, <orgName>University of Pittsburgh World History Center</orgName></docAuthor>
                <p xml:id="vnz_msz_g1b"><hi rend="bold">Linked Pasts</hi></p>
                <p xml:id="wnz_msz_g1b"><hi rend="italic"><persName>Karl Grossner</persName>, <orgName>University of Pittsburgh World History Center</orgName></hi></p>
                <p xml:id="xnz_msz_g1b">Website: <ref target="http://commons.pelagios.org/groups/linked-pasts/">http://commons.pelagios.org/groups/linked-pasts/</ref>; <ref target="http://linkedplaces.org">http://linkedplaces.org</ref>; <ref target="http://catalhoyuk.stanford.edu/">http://catalhoyuk.stanford.edu/</ref>; <ref target="http://commons.pelagios.org/2017/03/events-and-pelagios/"> http://commons.pelagios.org/2017/03/events-and-pelagios/</ref></p>
                <p xml:id="ynz_msz_g1b">Keywords: historical gazetteers, historical journeys and routes, archaeology, living archive</p>
                <div type="section">
                    <p xml:id="znz_msz_g1b">I am currently serving as Technical Director on the <orgName>World-Historical Gazetteer project (WHG)</orgName> at the University of Pittsburgh World History Center, for which I co-authored the successful <title level="j">NEH grant proposal</title>. The gazetteer will be developed over the next three years, becoming a significant resource within the growing Pelagios-led ecosystem of Linked Open Data for place-focused historical research.</p>
                    <p xml:id="a4z_msz_g1b">Another current LOD project is my own <orgName>Linked Places</orgName> (<ref target="http://linkedplaces.org">http://linkedplaces.org</ref>), an experiment in representing spatial, temporal, and thematic attributes of historical geographic movement. In recent months I have been developing a temporal extension to GeoJSON (GeoJSON-T), and use it to model seven exemplar datasets, each as one of three classes of movement: journeys, flows, and named routes/route systems. A web interface exposes the data on an interactive map and on four dataset-specific temporal visualizations. The application draws place LOD from external gazetteers, including Pleiades, <orgName>GeoNames</orgName>, <orgName>TGAZ (the Harvard China Historical GIS temporal gazetteer)</orgName>, and period records from the <orgName>PeriodO</orgName> project.</p>
                    <p xml:id="b4z_msz_g1b">In 2014 I launched <orgName>Çatalhöyük Living Archive</orgName>, an LOD project concerning core and analytic data from 21 years of excavation at that Late-Neolithic settlement site in present-day <placeName>Turkey</placeName>. The ultimate goal was the open publication of all Çatalhöyük data so it can be more readily re-interpreted, now and beyond the period of active excavation. Towards that end, I reorganized a large volume of data into a graph RDF representation and published it via a SPARQL endpoint and a REST API. The project’s work products also included a pilot web application (some functions currently disabled; <ref target="http://catalhoyuk.stanford.edu">http://catalhoyuk.stanford.edu</ref>) running against a “graphicised” version of the original data within a PostgreSQL database, demonstrating the viability of coexisting relational and graph data stores as a pragmatic workflow.</p>
                    <p xml:id="c4z_msz_g1b">I am also co-coordinator of the <orgName>Linked Pasts Working Group</orgName> within <orgName>Pelagios Commons</orgName>, an effort I will refer to in my position paper. Linked Pasts aims to "help make sure digital humanists have the infrastructure they need to support the work they want to do," beyond Pelagios' 2020 funding horizon. We are fostering a community that will collectively design systems and tools that leverage the advances in scholarly LOD practice Pelagios has already made. For example, there is significant interest in further linking gazetteers for places and periods to data stores for people, artifacts, and events. The WG stages an annual international symposium to advance these ideas and to bring current Pelagios project and data partners together.</p>
                    <p xml:id="d4z_msz_g1b">In 2016, a book chapter I co-authored on Linked Data and historical gazetteers was published: <title level="j">The Place of Linked Data for Historical Gazetteers</title> (Grossner et al.).</p>
                </div>
                <div type="section">
                    <head>Works Cited</head>
                    <p xml:id="e4z_msz_g1b">Engel, C. and Grossner, K. (2015). The Archaeological Process at Çatalhöyük: Creating A Living Archive. In I. Hodder, A. Marciniak (Eds.) Themes in Contemporary Archaeology: Assembling Çatalhöyük. Maney Publishing.</p>
                    <p xml:id="f4z_msz_g1b">Grossner, K., Janowicz, K. and Keßler, C. (2016). The Place of Linked Data for Historical Gazetteers. In R. Mostern, H. Southall, and M.L. Berman (Eds.). Placing Names: Enriching and Integrating Gazetteers. Bloomington: Indiana University Press.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">TEI to Linked Data: Exploring Opportunities to publish TEI-encoded text collection as Linked Data</title></head>
                <docAuthor><hi rend="italic"><persName>Myung-Ja (MJ) K. Han</persName>, <persName>Timothy W. Cole</persName>, <persName>Jacob Jett</persName>, <persName>Caroline Szylowicz</persName></hi>, <orgName>University of Illinois at Urbana-Champaign</orgName></docAuthor>
                <p xml:id="fpz_msz_g1b"><hi rend="bold">TEI to Linked Data: Exploring Opportunities to publish TEI-encoded text collection as Linked Data</hi></p>
                <p xml:id="gpz_msz_g1b"><hi rend="italic"><persName>Myung-Ja (MJ) K. Han</persName>, <persName>Timothy W. Cole</persName>, <persName>Jacob Jett</persName>, <persName>Caroline Szylowicz</persName>, <orgName>University of Illinois at Urbana-Champaign</orgName></hi></p>
                <p xml:id="hpz_msz_g1b">Website: <ref target="http://publish.illinois.edu/linkedspcollections/">http://publish.illinois.edu/linkedspcollections/</ref></p>
                <p xml:id="ipz_msz_g1b">Keywords: TEI to schema.org, TEI to linked data, Schema.org, scholar engagement with LOD, LOD for special digital collections, LOD for improving user experience</p>
                <div type="section">
                    <p xml:id="jpz_msz_g1b">Library’s digitized special collections provide primary research resources for humanities scholars. As libraries have started experimenting with Linked Open Data (LOD), questions have naturally arisen: How can we best transform legacy metadata describing resources in digitized special collections? What additional services can we provide to support scholars by utilizing available LOD sources? Funded by the <orgName>Andrew W. Mellon Foundation</orgName>, the <orgName> Linked Open Data for Digitized Special Collections project </orgName>(<ref target="http://publish.illinois.edu/linkedspcollections/">http://publish.illinois.edu/linkedspcollections/</ref>) is working to identify some of the unique challenges and opportunities presented by adding LOD to three digital special collections at the University of Illinois at Urbana-Champaign: <title level="j">the Motley Collection of Theatre and Costume Design and Portraits of Actors, 1720-1920</title> (which are both theater special collections) and a TEI-encoded text collection, <title level="j">the Kolb-Proust Archive for Research</title>.</p>
                    <p xml:id="kpz_msz_g1b">On this project we have focused on following three work areas:</p>
                </div>
                <div type="section">
                    <head>1. Enrich the existing special collections’ metadata with links to outside resources.</head>
                    <p xml:id="lpz_msz_g1b">Metadata reconciliation is an essential first step towards integrating with the semantic web and producing and consuming linked open data. We started by reconciling names and subjects used in our metadata with linked open data sources, including <title level="j">VIAF</title>, <title level="j">Wikipedia</title>, <title level="j">LCSH</title>, and <title level="j">TGMI</title>, authorities all widely used by libraries. However, we learned that special collection’s metadata often reference vocabularies and individuals not found in common library sources. So we identified new sources that were unconventional to the library domain but relevant to the domain of our collections, including <title level="j">Theatricalia</title>, <title level="j">IMDb</title> and <title level="j">IBDb</title>.</p>
                </div>
                <div type="section">
                    <head>2. Map the legacy metadata into linked data friendly vocabularies</head>
                    <p xml:id="mpz_msz_g1b">To make the collections and items discoverable on the web, we mapped legacy metadata for our collections to the Schema.org vocabulary that is supported and used by major search engines, like Google. Transformed metadata were then serialized in JSON-LD and embedded into the HTML pages that present item metadata descriptions to users, using the HTML script element, i.e., &lt;script id="rdf" type="application/ld+json"&gt;.</p>
                </div>
                <div type="section">
                    <head>3. Make the linked data visible to consumers</head>
                    <p xml:id="npz_msz_g1b">To better provide our users with the benefits of being integrated with other LOD services, we add JavaScript to our webpages that integrates metadata from external LOD services like <title level="j">DBpedia</title> and VIAF. Linked open data is not only publishing data to the web, but also bringing other information available on the web to local user's fingertips so users do not need to search for this information.</p>
                    <p xml:id="opz_msz_g1b">Additionally, we are exploring ways to publish in innovative ways already processed and transformed data from this project so scholars can reuse this information, including though visualization tools that can help provide additional layers of interconnectivity between data in our collections and the semantic web. We are also conducting usability tests to better learn how scholars engage with our new LOD-based features and services.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">An Ontology for the Work of the Early Modern Printing Trade</title></head>
                <docAuthor>
                    <hi rend="italic">
                        <persName>Molly O'Hagan Hardy</persName>
                    </hi>
                    ,
                    <orgName>American Antiquarian Society</orgName>
                </docAuthor>
                <p xml:id="skz_msz_g1b"><hi rend="bold">An Ontology for the Work of the Early Modern Printing Trade</hi></p>
                <p xml:id="tkz_msz_g1b"><hi rend="italic"><persName>Molly O'Hagan Hardy</persName>, <orgName>American Antiquarian Society</orgName></hi></p>
                <p xml:id="ukz_msz_g1b">Website: <ref target="http://link.americanantiquarian.org">http://link.americanantiquarian.org</ref> (Username: libhub Password: Hixlid54)</p>
                <p xml:id="vkz_msz_g1b">Keywords: prosopography, catalog, bibliography, rare books, book history</p>
                <div type="section">
                    <p xml:id="wkz_msz_g1b">For the last three years, I have served as the director the <orgName>Printers File Online</orgName> (PFO). This project aims to make available a unique set of data on the printing trade in what is now the <placeName>United States</placeName> from first printing in 1640 through 1820. This information set, which was created in the twentieth-century has already been entered as data so that it could be transformed into <title>BIBFRAME</title>, the library standard for linked open data. We are now seeking to make this data and its structures available by creating the PFO, a front-end user interface to query, extract, and enhance the data, as well as by developing an ontology that captures the work of printing in the early modern period in a transnational context.</p>
                    <p xml:id="xkz_msz_g1b">Founded in 1812, the <orgName>American Antiquarian Society</orgName> (AAS) has long been the home of the study of the history of the book in America as well as a leader in rare book cataloging. The PFO exists at the intersection of our two great strengths, as well as allows us to help the international effort to bring the data around the early printing trades into the twenty-first century by enabling it to be machine-actionable in the semantic web environment.</p>
                    <p xml:id="ykz_msz_g1b">The project not only enhances the humanities because of its content and the ability to interact with this content in innovative ways, but also because of the framework in which it has been built. This framework is the structure from which other prosopography work in linked open data can be built, that is to say, scholarly work on people’s lives can follow this model, so that the work is usable by the web. We have, in essence, created a recipe or a blueprint for linked open data prosopographies.</p>
                    <p xml:id="zkz_msz_g1b">We have brought the principles of interoperability and extensibility to bear on the <orgName>Printers’ File</orgName> data. So, for example, we could imagine much of the personal or not-strictly professional information in these prosopographies going into a generic notes field--the equivalent of a <orgName>Machine Readable Cataloging Record</orgName> (MARC) 500 field--where it would not be lost, but it would not be actionable or linked to other similar events. In an effort to not lose such valuable facts about people’s lives, we are entered them as triples, so that the notes exist in subject-predicate-object relationship. These triples allow for maximum flexibility. Any resource in the world (the subject) can have a specific relationship (the predicate) to any resource in the world (the object). When <orgName>Zepheira</orgName> designed BIBFRAME for the <orgName>Library of Congress</orgName>, its principal consideration was to create a framework that could work for objects. The Printers’ File data created a new need for BIBFRAME as it is the people creating the imprints, rather than the objects themselves, that were the organizing principal of the File. The Printers’ File therefore necessitated an extension of BIBFRAME, so that the events of a printer’s life could be accounted for.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">The Yellow Nineties Personography</title></head>
                <docAuthor><hi rend="italic"><persName>Alison Hedley</persName>, <persName>Lorraine Janzen Kooistra</persName></hi>, <orgName>Ryerson University</orgName></docAuthor>
                <p xml:id="vmz_msz_g1b"><hi rend="bold">The Yellow Nineties Personography</hi></p>
                <p xml:id="wmz_msz_g1b"><hi rend="italic"><persName>Alison Hedley</persName>, <persName>Lorraine Janzen Kooistra</persName>, <orgName>Ryerson University</orgName></hi></p>
                <p xml:id="xmz_msz_g1b">Website: <ref target="http://1890s.ca">http://1890s.ca</ref></p>
                <p xml:id="ymz_msz_g1b">Keywords: LOD, ontology, personography, biography, victorian</p>
                <div type="section">
                    <p xml:id="zmz_msz_g1b">The Yellow Nineties (Y90s) Personography documents the contributors to four avant-garde magazines: the <title level="j">Yellow Book</title> (1894-97), the <title level="j">Pagan Review</title> (1892), the <title level="j">Savoy</title> (1896), and the <title level="j">Evergreen: A Northern Seasonal</title> (1895-97). When completed, the <orgName>Yellow Nineties Personography</orgName> will become a research and data visualization tool on <orgName>The Yellow Nineties Online</orgName>, a scholarly e-resource for the study of these magazines. The personographic method enables us to investigate the Yellow Nineties periodicals as records of collaboration. The project’s goal is to develop a database that others can query to learn about the complex network of editors, authors, illustrators, and readers that participated in fin-de-siècle British print culture. Our current dataset is modest, documenting 351 persons in 21 fields, but it will grow in tandem with the expansion of the corpus of The Yellow Nineties Online. </p>
                    <p xml:id="anz_msz_g1b">We initially sought to accomplish this project’s goals using the guidelines of the <orgName>Text Encoding Initiative (TEI)</orgName> to model our dataset. After completing our initial research phase, which involved collating biographical data in a spreadsheet, and honing TEI expertise in preparation for transforming the dataset, the Y90s Personography team decided that TEI is not, in fact, a suitable model for realizing the project’s desired outcomes. The text-based hierarchy of TEI readily lends itself to the chronological and/or genealogical organization of data; it does not as readily enable a non-hierarchical, relational data structure. While the Y90s Personography includes information about dates and texts, our project emphasizes the relational, socio-cultural roles of historical persons. We have therefore revised our project’s goals so that the outcome will be a non-relational, linked open RDF database. Modelling our personography as linked open data will allow us to maintain a somewhat heterogeneous dataset while linking this data to other records of our persons that exist elsewhere, such as the database of <orgName>Virtual International Authority Files (VIAF)</orgName> and the <orgName>Library of Congress</orgName>. We also hope that, in the future, our database can link to other digital humanities projects that include the artists, authors, and editors who populate our database. </p>
                    <p xml:id="bnz_msz_g1b">Our revised process for the Y90s Personography involves four phases: developing an ontology, cleaning and reorganizing data currently in spreadsheet form, transforming this data into RDF, and creating a user interface so that researchers can querying the RDF data to identify patterns among Y90s contributors such as biological sex, education, and relationships with other contributors. In consultation with three Ryerson librarians—<persName>Naomi Eichenlaub</persName>, <persName>Trina Grover</persName>, and <persName>MJ Suhonas</persName>—as well as <persName>Paige Morgan</persName>, digital humanities librarian at <orgName>Miami State University</orgName>, the Y90s Personography team has nearly completed the first and second phases of our project with a pilot dataset of 20 persons. Once we have established an ontology and successful workflow, we can clean and transforming the rest of the personography dataset into RDF while advancing to the next major phase: developing a user interface. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Salmon Pueblo Archaeological Research Collection / Chaco Research Archive</title></head>
                <docAuthor><hi rend="italic"><persName>Carrie Heitman</persName></hi>, <orgName>University of Nebraska-Lincoln</orgName>; <hi rend="italic"><persName>Worthy Martin</persName></hi>, <orgName>University of Virginia</orgName></docAuthor>
                <p xml:id="cnz_msz_g1b"><hi rend="bold">Salmon Pueblo Archaeological Research Collection / Chaco Research Archive </hi> </p>
                <p xml:id="dnz_msz_g1b"><hi rend="italic"><persName>Carrie Heitman</persName>, <orgName>University of Nebraska-Lincoln</orgName>; <persName>Worthy Martin</persName>, <orgName>University of Virginia</orgName> </hi> </p>
                <p xml:id="enz_msz_g1b">Website: <ref target="http://chacoarchive.org">http://chacoarchive.org</ref>; <ref target="http://salmonpueblo.org">http://salmonpueblo.org</ref> (in development) </p>
                <p xml:id="fnz_msz_g1b">Keywords: semantic web, ontologies, RDF, material culture, archaeology, cyberinfrastructure</p>
                <div type="section">
                    <p xml:id="gnz_msz_g1b">We have two projects (one completed, one ongoing) where we have been considering our options with regard to LOD. These are archaeological projects for which there is not a ready mechanism (something like <orgName>NINES</orgName>) where we can submit RDFs. Where specific ontologies do exist, they are under construction (e.g., <orgName>Period0</orgName>), and do not yet meaningfully capture the fluid ways scholars use time period terms. The challenges of LOD are much greater with regard to certain forms of material culture such as ceramics. With our new <orgName>Salmon Pueblo project (SPARC)</orgName>, we would like to expose our data through LOD and have had some discussions with the <orgName>DINAA</orgName> and <orgName>OpenContext</orgName> teams regarding resource IDs. We have roughly 600k data records and have spent time in technical development meetings discussing both generic and specific approaches to LOD. At this point in our project, we are also interested to learn how LOD are currently being used and by whom so this might help drive our decisions. In sum, given the complexities referenced above we are eager to work with others to resolve the technical who, what, where and how LOD questions for our SPARC data. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Geospatial and Linguistic LOD</title> </head>
                <docAuthor><hi rend="italic"><persName>Timo Homburg</persName></hi>, PhD Student, <orgName>Mainz University Of Applied Sciences</orgName></docAuthor>
                <p xml:id="mnz_msz_g1b"><hi rend="bold">Geospatial and Linguistic LOD</hi> </p>
                <p xml:id="nnz_msz_g1b"><hi rend="italic"><persName>Timo Homburg</persName>, PhD Student, <orgName>Mainz University Of Applied Sciences</orgName></hi> </p>
                <p xml:id="onz_msz_g1b">Website: <ref target="http://situx.github.io/SemanticDictionary/">http://situx.github.io/SemanticDictionary/</ref> </p>
                <p xml:id="pnz_msz_g1b">Keywords: ancient languages, dictionaries, semantics, cultural heritage, ontologies </p>
                <div type="section">
                    <p xml:id="qnz_msz_g1b">My name is Timo Homburg. I am a PhD student at i3Mainz/Mainz University Of Applied Sciences currently engaged to integrate geospatial data into the Semantic Web. </p>
                </div>
                <div type="section">
                    <head>Geospatial Linked Open Data - Semantic GIS Project:</head>
                    <p xml:id="rnz_msz_g1b">In our research project Semantic GIS (<ref target="https://i3mainz.hs-mainz.de/en/projekte/semanticgis">https://i3mainz.hs-mainz.de/en/projekte/semanticgis</ref>) we work on the integration of geospatial data in general into a Semantic Web environment and focus on aspects of data quality and the automaed discovery of knowledge domains related to the geospatial data we process. While in the Semantic GIS project we focus on integrating geospatial data for environment and energy usecases, our institute deals with geospatial linked data in the context of cultural heritage. Examples of this are the COSCH (<ref target="http://cosch.info">http://cosch.info</ref>) for spatial object documentation using Semantics and the <orgName>TextElSem</orgName> project which aims at reconstructing the location of ancient Mesopotamian cities through text mining in a linked data environment. </p>
                </div>
                <div type="section">
                    <head>Linguistic Linked Open Data - Semantic Dictionaries for Ancient Languages:</head>
                    <p xml:id="snz_msz_g1b">During my master's study I was engaged in computational linguistics, in particular in researching ways to automatically process transliteration/unicode representations of ancient languages such as cuneiform or egyptian hieroglyphs, as well as to facilitate the usage of unicode charactes in said languages by developing state-of-the-art input method engines. Recently I became engaged in the Linguistic Linked Open data community and am working on a wordnet-like <title level="j">Lemon</title> (<ref target="http://lemon-model.net">http://lemon-model.net</ref>)-based dictionary for cuneiform languages to interlink existing dictionary resources with appropriate concepts of the LOD world to create a state-of-the art dictionary of currently cuneiform languages, but in perspective more ancient languages (<ref target="https://situx.github.io/SemanticDictionary/">https://situx.github.io/SemanticDictionary/</ref>). </p>
                    <p xml:id="tnz_msz_g1b">The dictionary will in the future be combined with metadata of cultural heritage artifacts, encompassing respective words, etymology information, geolocation of the artifacts and much more. </p>
                    <p xml:id="unz_msz_g1b">[At] this conference I present efforts in Part-Of-Speech Tagging on Hittite cuneiform and the creation of a Semantic dictionary for this language as well as its benefit for automated translation of Hittite cuneiform. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Linking REED London to all the other Londons</title> </head>
                <docAuthor><hi rend="italic"><persName>Diane Jakacki</persName></hi>, <orgName>Bucknell University</orgName> </docAuthor>
                <p xml:id="t4z_msz_g1b"><hi rend="bold">Linking REED London to all the other Londons</hi> </p>
                <p xml:id="u4z_msz_g1b"><hi rend="italic"><persName>Diane Jakacki</persName>, <orgName>Bucknell University</orgName> </hi> </p>
                <p xml:id="p_av4_2dx_h1b">Website: <ref target="http://dianejakacki.net/">http://dianejakacki.net/</ref> (<ref target="http://dianejakacki.net/data-envy-at-mla-2016/">Data Envy</ref>; <ref target="http://dianejakacki.net/reed-and-the-prospect-of-networked-data/">REED and the Prospect of Networked Data</ref>; <ref target="http://dianejakacki.net/reed-london-humanistic-roots-humanistic-futures/">REED London: Humanistic Roots, Humanistic Futures</ref>)</p>
                <p xml:id="v4z_msz_g1b">Keywords: <placeName>London</placeName>, theatre, performance, history, archives </p>
                <div type="section">
                    <p xml:id="w4z_msz_g1b"><orgName>REED London</orgName> establishes an openly accessible online resource of London-centric documentary, editorial, and bibliographical materials related to performance, theatre, and music spanning the pre-modern period. It develops from the <orgName>Records of Early English Drama (REED)</orgName>, an international scholarly project that has for the last forty years worked to locate, transcribe, and edit historical documents that contain evidence of drama, secular music, and other communal entertainment and ceremony in <placeName>England</placeName>, <placeName>Wales</placeName>, and <placeName>Scotland</placeName> from the Middle Ages until 1642. REED's output constitutes twenty-seven collections of records in print - over 17,000 pages of transcribed records plus invaluable contextual materials. </p>
                    <p xml:id="x4z_msz_g1b">REED London weaves together London-centric materials from three printed REED collections (Inns of Court, Ecclesiastical London, and Civic London to 1558), the prosopographical material from Patrons and Performances (which already includes biographical information of over one thousand people associated with English performance and music), the bibliographical database of Early Modern London Theatre and in-progress collections of records focusing on London performance spaces. All materials are diplomatically transcribed and include granular glosses, bibliographic metadata, and extensive contextual editorial materials. </p>
                    <p xml:id="y4z_msz_g1b">The REED London team will develop customized publication interface components that will enable the publication of the following: 1) machine-readable, fully-searchable text records; 2) a comprehensive and customizable compendium of all contextual and editorial materials; 3) an authority list of all identifiable people, places, organizations, and offices referred to in the records; 4) a comprehensive finding aid of all archival documents referred to, pages or leaves consulted, and their current locations/availability in archives and libraries. These published materials will comprise a series of thematic editions that respond to scholars' research and teaching needs; dynamic interactive textual, geographical, and prosopographical visualizations; and exportable customized datasets. </p>
                    <p xml:id="z4z_msz_g1b">REED London focuses our efforts on creating new environments for scholarly presentation of archival materials gathered from legal, ecclesiastical, civic, political, and personal archival sources in and around London. Through our partnership with the <orgName>Canadian Writing Research Collaboratory</orgName>, we intend to build a stable, extensible publication environment that optimizes access to the compiled materials in ways that respond to scholars’ research interests across pre-modern disciplines. It is thanks to this partnership that we believe we will be able to establish processes through which REED data can be prepared properly to integrate with other projects complementary in scope. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Linking Early Modern London Toponyms</title> </head>
                <docAuthor><hi rend="italic"><persName>Janelle Jenstad</persName></hi>, <orgName>University of Victoria / MoEML / ISE</orgName> </docAuthor>
                <p xml:id="apz_msz_g1b"><hi rend="bold">Linking Early Modern London Toponyms</hi> </p>
                <p xml:id="bpz_msz_g1b"><hi rend="italic"><persName>Janelle Jenstad</persName>, <orgName>University of Victoria / MoEML / ISE</orgName> </hi> </p>
                <p xml:id="cpz_msz_g1b">Website: <ref target="http://mapoflondon.uvic.ca">http://mapoflondon.uvic.ca</ref>; <ref target="http://internetshakespeare.uvic.ca">http://internetshakespeare.uvic.ca</ref> </p>
                <p xml:id="dpz_msz_g1b">Keywords: <placeName>London</placeName>, toponyms, gazetteer, personography, JSON, GIS, variant names, authority names </p>
                <div type="section">
                    <p xml:id="epz_msz_g1b"><orgName>MoEML</orgName> (<ref target="http://mapoflondon.uvic.ca">http://mapoflondon.uvic.ca</ref>) is a robust, well documented TEI-GIS project with interlinked datasets, editions, and resources pertaining to <persName>Shakespeare</persName>’s London (1550-1666). MoEML’s long-term research objective is to facilitate a deep reading of London locations, their broad cultural significance, and the particular significance of location to individual subjects or communities. To do so, we need far more data and texts than MoEML itself can transcribe, encode, and publish. Such a reading depends on aggregating and linking many corpora and databases compiled by projects and individuals with specialized interests and expertise. MoEML’s well structured XML has produced a number of datasets that are ready for deposit in a triple store, including a gazetteer of 6500 geocoded placename variants and a personography of 5000 early modern Londoners. The gazetteer has the most potential to link the many other datasets and projects with a geographical datapoint. It is more granular than any existing gazetteer in that it includes buildings and features smaller than the smallest administrative unit normally captured in gazetteers, and will facilitate NER applications to non-normalized early modern texts because it captures variant spellings and alternate names. Since MoEML’s data is already georeferenced with lat-long coordinates, any dataset tagged with MoEML ids can be dynamically mapped onto any georeferenced London map. Extracted from MoEML’s XML, the JSON version of the gazetteer is already organized in triples: variant, authority name, and id. The RDF triple should be (toponym) (is variant of) (id). Example: Chepesyde is a variant of CHEA2. The authority name, Cheapside, should be contained in a data crosswalk that maps id to authority name. The id can be used to predict URLs (<ref target="http://mapoflondon.uvic.ca/CHEA2">http://mapoflondon.uvic.ca/CHEA2</ref>) or mint URIs in the UVic triple store. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Linked Open Data and Geographic Analysis for Early Modern French Texts</title></head>
                <docAuthor><hi rend="italic"><persName>Katherine McDonough</persName>, <persName>Matje van de Camp</persName></hi>, <orgName>Western Sydney University</orgName> </docAuthor>
                <p xml:id="slz_msz_g1b"><hi rend="bold">Linked Open Data and Geographic Analysis for Early Modern French Texts</hi> </p>
                <p xml:id="tlz_msz_g1b"><hi rend="italic"><persName>Katherine McDonough</persName>, <persName>Matje van de Camp</persName>, <orgName>Western Sydney University</orgName> </hi> </p>
                <p xml:id="ulz_msz_g1b">Website: <ref target="http://geoviz.taalmonsters.nl">http://geoviz.taalmonsters.nl</ref>; <ref target="http://fbtee.uws.edu.au/mpce">http://fbtee.uws.edu.au/mpce</ref>; <ref target="http://academia.edu/32309040/Poster_for_Linked_Pasts_2016_Geography_of_the_Enlightenment_Creating_an_Early_Modern_Gazetteer">http://academia.edu/32309040/Poster_for_Linked_Pasts_2016_Geography_of_the_Enlightenment_Creating_an_Early_Modern_Gazetteer </ref>; <ref target="http://commons.pelagios.org/groups/linked-pasts/forum/topic/experimenting-wner-and-georesolution-for-early-modern-french-texts/#post-2669">http://commons.pelagios.org/groups/linked-pasts/forum/topic/experimenting-wner-and-georesolution-for-early-modern-french-texts/#post-2669</ref></p>
                <p xml:id="vlz_msz_g1b">Keywords: eighteenth century, ethics, methods, database, gazetteer </p>
                <div type="section">
                    <p xml:id="wlz_msz_g1b">My work in LOD has focused on ways to leverage existing metadata repositories for new DH projects on the early modern world. First, I have begun working on annotations of places mentioned in <persName>Diderot</persName>’s 18th-century <title level="m">Encyclopédie</title>. With my co-researcher Matje van de Camp (Independent Scholar, <placeName>Netherlands</placeName>), we have developed an annotation application for annotating the <title level="m">Encyclopédie</title> articles and are developing a methodology for aligning existing gazetteer, periodization, and other openly available metadata with attestations of place names specific to the early modern period. One goal is to enable researchers to analyze and map the places of the Encyclopédie (and eventually other geographic reference works printed between ca. 1500-1789). Another is to provide a tool that helps researchers connect evidence in historical texts to readily available LOD (<orgName>Wikipedia</orgName>, <orgName>Geonames</orgName>, <orgName>Pleiades</orgName>, etc.). We are working in coordination with the <orgName>Pelagios Commons</orgName> team as we advance this project. Mapping the Encyclopédie and other pre-1789 texts is the beginning of a longer project to create an early modern gazetteer. </p>
                    <p xml:id="xlz_msz_g1b">Second, as part of my postdoctoral work with the “<orgName>Mapping Print, Charting Enlightenment</orgName>” project at <orgName>Western Sydney University</orgName>, I am working on the creation of a database of all novelesque works published in French in the eighteenth century. This grows out of a printed bibliography from 1977, where the authors’ intentions were to provide a research tool for people asking questions about the relationship between book editions, access to copies of specific editions, and the study of titles, publication places, authorship, etc. Today, we want to connect this rich assemblage of information about French books with authority records on booksellers/publishers from the <orgName>French National Library (BnF)</orgName> and instances of particular editions available around the world. Our work with the BnF has been a comedy of errors, revealing the challenges of accessing LOD at scale even with an institution that is quickly working to make collection data available to the public. Additionally, individual researchers (like us) cannot access the <orgName>WorldCat</orgName> API, which would be the ideal pathway to linking database editions to existing copies. Ideally, the database will be a crossroads for collections housing real books and other databases about print runs and censorship (part of the broader “<orgName>Mapping Print</orgName>” project). </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Investigating Humanities Linked Data by connecting UK projects</title> </head>
                <docAuthor><hi rend="italic"><persName>Sarah Middle</persName></hi>, <orgName>The Open University, UK</orgName> </docAuthor>
                <p xml:id="mmz_msz_g1b"><hi rend="bold">Investigating Humanities Linked Data by connecting UK projects</hi> </p>
                <p xml:id="nmz_msz_g1b"><hi rend="italic"><persName>Sarah Middle</persName>, <orgName>The Open University, UK</orgName> </hi> </p>
                <p xml:id="omz_msz_g1b">Website: <ref target="http://data.open.ac.uk/page/context/ahrc">http://data.open.ac.uk/page/context/ahrc</ref> </p>
                <p xml:id="pmz_msz_g1b">Keywords: linked data, Arts and Humanities Research Council, projects, research methods, data production, data consumption, project classification, funding, infrastructure </p>
                <div type="section">
                    <p xml:id="qmz_msz_g1b">While studying Archaeology, much of my time was spent sifting through excavation reports to identify objects of similar types from different sites. This process could have been more efficient and thorough, had there been an online facility to search multiple collections simultaneously. I later became aware of Linked Data when working in academic libraries, and immediately saw its potential for increasing access to information and connecting resources, in a way that might provide a solution to my earlier issue. </p>
                    <p xml:id="rmz_msz_g1b">I am now a PhD student at the Open University in the UK, examining how Linked Data approaches might be integrated with existing Humanities research methodologies, particularly in disciplines relating to the Ancient World. So far, this work has concentrated on identifying Humanities projects that have used or produced digital data, to use as potential case studies. I am focussing on projects funded by the UK's <orgName>Arts and Humanities Research Council (AHRC)</orgName> since 2006, which should provide a good cross-section of Humanities research activity across the UK. Data that describes these projects is available via <orgName>Research Councils UK’s (RCUK)</orgName> <orgName>Gateway to Research</orgName> (<ref target="http://gtr.rcuk.ac.uk/">http://gtr.rcuk.ac.uk/</ref>) and may be exported to JSON format via the API. I have converted this data to RDF using a Python script, and published it at <ref target="http://data.open.ac.uk/page/context/ahrc">http://data.open.ac.uk/page/context/ahrc</ref>; it can be queried via the Open University's SPARQL endpoint at <ref target="http://data.open.ac.uk/sparql">http://data.open.ac.uk/sparql</ref>. </p>
                    <p xml:id="smz_msz_g1b">Initial findings show that 24 out of the 5349 AHRC-funded projects (0.45%) explicitly mentioned phrases relating to Linked Data. Twelve of these projects form an interconnected network based on people and institutions that they have in common, and five of these twelve projects are from the disciplines of Classics and/or Archaeology. These include phase 4 of <orgName>Pelagios</orgName> (<ref target="http://commons.pelagios.org/">http://commons.pelagios.org/</ref>); <orgName>Standards for Networking Ancient Prosopographies: Data and Relations in Greco-roman Names</orgName> (SNAP:DRGN - <ref target="https://snapdrgn.net/">https://snapdrgn.net/</ref>); <orgName>Semantic Tools for Archaeological Resources</orgName> (STAR - <ref target="http://hypermedia.research.southwales.ac.uk/kos/star/">http://hypermedia.research.southwales.ac.uk/kos/star/</ref>); <orgName> Semantic Tools Enhancing Links and Linked data for Archaeological Resources </orgName> (STELLAR - <ref target="http://hypermedia.research.southwales.ac.uk/kos/stellar/">http://hypermedia.research.southwales.ac.uk/kos/stellar/</ref>), and <orgName> Semantic ENrichment Enabling Sustainability of arCHAeological Links </orgName> (SENESCHAL - <ref target="http://www.heritagedata.org/blog/">http://www.heritagedata.org/blog/</ref>). My current research involves evaluating resources produced by these projects, with a particular focus on their usability and sustainability.</p>
                    <p xml:id="tmz_msz_g1b">Additionally, I have been studying ontologies for describing Humanities research methods, with a view to enhancing the linked AHRC project data with terms from the <orgName>Network for Digital Methods in the Arts and Humanities (NeDiMAH) Methods Ontology</orgName> (NeMO - <ref target="http://nemo.dcu.gr/">http://nemo.dcu.gr/</ref>) and/or the <orgName>Taxonomy of Digital Research Activities in the Humanities</orgName> (TaDiRAH - <ref target="http://tadirah.dariah.eu/vocab/index.php">http://tadirah.dariah.eu/vocab/index.php</ref>). Classifying the data in this way should improve discoverability, and reveal relationships between projects that may not otherwise have been apparent. </p>
                    <p xml:id="umz_msz_g1b">I also intend to use this data to identify Humanities projects that have used or produced digital data in a different format, but which might have benefited from a Linked Data approach. Possible examples found so far include representing social networks using relational databases, and linking texts in a digitised archive using TEI. In such cases I will explore the reasons why particular decisions were made regarding data, and identify potential barriers to the implementation or consumption of Linked Data. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Linked Modernisms</title> </head>
                <docAuthor><hi rend="italic"><persName>Jana Millar Usiskin</persName></hi>, <orgName>UVic</orgName> PhD candidate; <hi rend="italic"><persName>Stephen Ross</persName></hi>, <orgName>Linked Modernisms</orgName> project lead; <hi rend="italic"><persName>Christine Walde</persName></hi>, <orgName>UVic</orgName> librarian; <hi rend="italic"><persName>Caroline Winter</persName></hi>, <orgName>UVic</orgName>  PhD candidate</docAuthor>
                <p xml:id="p_f3s_pfn_kbb"><hi rend="bold">Linked Modernisms</hi> </p>
                <p xml:id="p_g3s_pfn_kbb"><hi rend="italic"><persName>Sarah Middle</persName>, <orgName>The Open University, UK</orgName> </hi> </p>
                <p xml:id="p_h3q_lgn_kbb">Website: <ref target="http://linkedmods.uvic.ca/">http://linkedmods.uvic.ca/</ref></p>
                <p xml:id="p_i3s_pfn_kbb">Keywords: modernism, modernity, ontology, visualization, metadata, Protege, information, digital humanities, machine reasoning</p>
                <div type="section">
                    <p xml:id="p_j3s_pfn_kbb"><orgName>Linked Modernisms</orgName> is a landmark web-based visualization and open-source analysis portal for browsing, searching, and visualizing the metadata associated with the content of <title level="j">The Routledge Encyclopedia of Modernism</title> (REM). Through a combination of machine reasoning and human intervention, Linked Modernisms employs Causabon, a customized information ontology that allows users to search specific terms, relationships, characteristics, or combinations of these terms as they explore the world of modernism.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Intersectional (Open) Data: Feminism, Decolonialist Ethics, and the Politics of Linked Open Data</title></head>
                <docAuthor><hi rend="italic"><persName>Emily Christina Murphy</persName></hi>, <orgName>Queen's University</orgName>; <hi rend="italic"><orgName>Linked Modernisms</orgName></hi>, <orgName>University of Victoria</orgName> </docAuthor>
                <p xml:id="hnz_msz_g1b"><hi rend="bold">Intersectional (Open) Data: Feminism, Decolonialist Ethics, and the Politics of Linked Open Data </hi> </p>
                <p xml:id="inz_msz_g1b"><hi rend="italic"><persName>Emily Christina Murphy</persName>, <orgName>Queen's University</orgName>; <hi rend="italic"> <orgName>Linked Modernisms</orgName> </hi>, <orgName>University of Victoria</orgName> </hi> </p>
                <p xml:id="jnz_msz_g1b">Website: <ref target="http://linkedmods.uvic.ca/">http://linkedmods.uvic.ca/</ref> </p>
                <p xml:id="knz_msz_g1b">Keywords: feminism, intersectionality, decolonization, women's writing, digital cultural history, decolonial ethics </p>
                <div type="section">
                    <p xml:id="lnz_msz_g1b">My experience working with Linked Open Data emerges both from professional training environments and from independent research. In 2014, I attended a week-long workshop at <orgName>DH@Oxford</orgName> entitled “<title level="j">Data Curation and Access for the Digital Humanities</title>,” led by library staff from the <orgName>University of Illinois Urbana-Champaign</orgName> and the <orgName>Bodleian</orgName>. In 2015 I undertook a directed reading in “<title level="j">Linked Open Data, Curation, and Ontologies in Humanities Research</title>” with <persName>Dr. J. Matthew Huculak</persName> as part of the <title level="j">UVic Graduate Certificate in Digital Humanities</title>. My reading sought to comprehend dynamic metadata creation for modelling contemporary and historical communities, building upon my knowledge of library-centered curation practices and surveying the field of scholarly projects that use and develop LOD approaches to curation. The directed reading resulted in an annotated bibliography and a white paper, which I have since adapted into conference presentations and a full-length article currently under submission to an academic journal. In the Fall of 2017, I join the Linked Modernisms project at the University of Victoria as a SSHRC Postdoctoral Fellow under the supervision of <persName>Dr. Stephen Ross</persName>, where my postdoctoral project, “<title level="j">Modernism, Feminism, and the Ego-Network</title>,” will adapt the RDF ontology developed by Linked Modernisms to the study of women’s editorship in the modernist period. In preparation for this fellowship, I am spending this summer broadening the scope of my knowledge on theories and practices of networked data. Such practices, in addition to LOD and its RDF standards, include social network analysis and actor-network theory. In order to gain this knowledge, I am enrolled in “<title level="j">Extracting Cultural Networks from Thematic Research Collections</title>” with <persName>Dr. Rafael Alvarado</persName> at <orgName>DHSI</orgName>, in which class we will explore ways to “extract, visualize, analyze, and interpret implied cultural networks” in text. Such theories include the long history of the network as metaphor in literary history; in my research on the culture of the early-twentieth century, metaphors of networked connectedness are particularly prominent in the literature of and the scholarship on this historical period. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Balancing the Needs of Web Publication for Humans and Linked Open Data</title> </head>
                <docAuthor><persName>Dr. Patrick Murray-John</persName>, <orgName>Roy Rosenzweig Center for History and New Media</orgName></docAuthor>
                <p xml:id="nlz_msz_g1b"><hi rend="bold">Balancing the Needs of Web Publication for Humans and Linked Open Data </hi> </p>
                <p xml:id="olz_msz_g1b"><hi rend="italic"><persName>Dr. Patrick Murray-John</persName>, <orgName>Roy Rosenzweig Center for History and New Media</orgName></hi> </p>
                <p xml:id="plz_msz_g1b">Website: <ref target="http://github.com/omeka/omeka-s">http://github.com/omeka/omeka-s</ref>; <ref target="http://omeka.org">http://omeka.org</ref> </p>
                <p xml:id="qlz_msz_g1b">Keywords: omeka, omeka s, metadata creation, web publishing </p>
                <div type="section">
                    <p xml:id="rlz_msz_g1b">In 2012, the <orgName>Roy Rosenzweig Center for History and New Media</orgName> (RRCHNM) at <orgName>George Mason University</orgName> (GMU) started developing a new version of our popular open-source web-publishing platform, <orgName>Omeka</orgName> (Classic), that was designed specifically with the principles of Linked Open Data (LOD) in mind. Developed for medium and larger GLAMs, Omeka S, currently in a fourth beta, uses JavaScript Object Notation-Linked Data (JSON-LD) as its native data format, which makes it possible to enmesh Omeka S in the LOD world. Every Omeka S Resource (item, item set, media) has a URI, and the core software includes the following Resource Description Framework (RDF) vocabularies, which maximizes its data interoperability with other data publishers: <orgName>Dublin Core Metadata Initiative</orgName> (DCMI) Terms; DCMI Type; <orgName>The Bibliographic Ontology</orgName> (BIBO); and <orgName>The Friend of A Friend Vocabulary</orgName> (FOAF). In our progress toward ensuring and maintaining interrelationships between humanities data, connectors between Omeka S and other systems will ensure that LOD is maintained. For example, the connector to Fedora fosters import of both Fedora's own vocabulary, and the W3C Recommendation Linked Open Data Vocabulary that it rests on. Together, these features prepare data in Omeka S to be fully embedded in the semantic web. For example, a series of modules for Omeka S takes advantage of LOD authority files from the <orgName>Library of Congress</orgName> and from the <orgName>Getty Research Institute</orgName> to facilitate standardized and linked metadata creation. </p>
                </div>
            </div>
            <div type="chapter">
                <head>JazzCats - Jazz Collection of Aggregated Triples</head>
                <docAuthor><persName>Dr Terhi Nurmikko-Fuller</persName>, <persName>Dr Daniel Bangert</persName>, <persName>Dr Alfie Abdul-Rahman</persName>, <orgName>Australian National University</orgName> </docAuthor>
                <p xml:id="nkz_msz_g1b"><hi rend="bold">JazzCats - Jazz Collection of Aggregated Triples</hi> </p>
                <p xml:id="okz_msz_g1b"><hi rend="italic"><persName>Dr Terhi Nurmikko-Fuller</persName>, <persName>Dr Daniel Bangert</persName>, <persName>Dr Alfie Abdul-Rahman</persName>, <orgName>Australian National University</orgName></hi></p>
                <p xml:id="pkz_msz_g1b">Website: <ref target="http://jazzcats.oerc.ox.ac.uk">http://jazzcats.oerc.ox.ac.uk</ref> </p>
                <p xml:id="qkz_msz_g1b">Keywords: metadata, RDF workflow, jazz music, prosopography </p>
                <div type="section">
                    <p xml:id="rkz_msz_g1b"><orgName>JazzCats - a Jazz Collection of Aggregated Triples</orgName> - utilizes RDF to bridge three previously unconnected but complementary datasets containing information about jazz music, and links them to external online resources (<title>VIAF</title>, <orgName>DBpedia</orgName>, <orgName>MusicBrainz</orgName>, <orgName>Wikidata</orgName>, <orgName>BBC</orgName>). It equips scholars with a tool to ask research questions about performance histories enriched by discography metadata and a prosopography of musicians. It allows users to trace the development of musical features within specific works, and to identify key performers. We describe the datasets, evaluate the workflows used for data modelling and semantic integration, show example results generated though <title>SPARQL</title> queries. We conclude with an eye to future stages of development, and are eager to receive feedback and comments regarding JazzCats, currently at the end of the first stage of development. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Canadiana.org: Annotations and Linked Data</title> </head>
                <docAuthor><hi rend="italic"><persName>Julienne Pascoe</persName></hi>, <orgName>Canadiana.org</orgName> </docAuthor>
                <p xml:id="alz_msz_g1b"><hi rend="bold">Canadiana.org: Annotations and Linked Data</hi> </p>
                <p xml:id="blz_msz_g1b"><hi rend="italic"><persName>Julienne Pascoe</persName>, <orgName>Canadiana.org</orgName> </hi> </p>
                <p xml:id="clz_msz_g1b">Website: <ref target="http://canadiana.ca">http://canadiana.ca</ref> </p>
                <p xml:id="dlz_msz_g1b">Keywords: cultural heritage, linked open data, semantic web, annotations, digital humanities, transcriptions, metadata </p>
                <div type="section">
                    <p xml:id="elz_msz_g1b">Canadiana.org is a membership-based alliance dedicated to the preservation and discovery of Canadian documentary heritage. In addition to collaborating on digitization, preservation and access projects, Canadiana has digitized and made available large-scale cultural heritage collections, constituting an extensive digital corpus and dataset that can be experimented with and transformed into linked data output and digital humanities applications. These include <orgName>Early Canadiana Online</orgName>, a collection of over several hundred thousand early Canadian print titles, and <orgName>Héritage</orgName>, with over sixty million digitized pages of archival material from the <orgName>Library and Archives Canada</orgName>. Linked data and the semantic web connect to our goals of preserving and providing access to Canadian documentary heritage as well as building and connecting collections and digital resources across community based silos. As we have different collections within our platform, LOD presents an opportunity to connect our datasets internally as well as externally with both Canadian and international resources. </p>
                    <p xml:id="flz_msz_g1b">As Lead Metadata Architect, I am responsible for leading our research and development activities investigating the application of LOD principles and technologies with our collections and partnerships. Previous Canadiana LOD work includes forming the <orgName>Héritage Metadata Consultations Group</orgName> to develop a linked data resource description model for describing the Héritage digital resources. The workshops that followed resulted in a white paper summarizing the results and a RDF-compliant data model, which we are currently evaluating amongst other interoperable instances being developed internationally. Recently, we completed a substantial overhaul of our infrastructure and metadata platform to a dynamic, adaptive system that supports the concept of living metadata. This upgrade facilitated the separation of our preservation layer from our access layer, resulting in three core interrelated, interactive components: digitization, preservation, access. In doing so the access layer becomes robust, flexible and lightweight, and it is easy to design, test, and implement emerging technology for semantic web deployment. </p>
                    <p xml:id="glz_msz_g1b">While our platform upgrade has really shifted the focus to data-driven responsiveness and adaptability, Canadiana has also established collaborations with other organizations to provide LOD expertise and support. A recent example is our partnership with <orgName>CHIN</orgName>, in which we were able to work with the Museum sector in exploring the application of LOD to connecting museum data to other community resources. Our role was to provide data-driven consultation and guidance based on our recent linked data research as well as technical support in hosting the site including. In exchange Canadiana staff are able to access the prototype application for evaluation and research purposes. The result is site that explores intersections and links made to the works with data visualizations and pre- compiled artist’s stories. </p>
                    <p xml:id="hlz_msz_g1b">In summary, the principles of the Semantic Web connect with Canadiana’s goals of linking collections and providing enriched access to the cultural heritage corpus. Our extensive collections represent a significant dataset with which to test and generate LOD applications. Current research investigates the latest RDF models, data normalization tools, and publishing technologies for our collections. A critical area however, is the user requirements and publishing interface that will expose these datasets for further enhancement and discovery. Due to the recent infrastructure overhaul, this is an opportune moment for us to reach out and connect to the Digital Humanities community, one that is deeply engaged in developing strategies for greater enhancement and connection of the digital heritage corpus. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Expanding the Institutional Repository Mission: Innovating with Linked Data for NASA Digital Curation</title> </head>
                <docAuthor><hi rend="italic"><persName>Matt Pearson</persName>, <persName>Adrienne Heib</persName></hi>, <orgName>NASA Goddard Space Flight Center</orgName> </docAuthor>
                <p xml:id="ylz_msz_g1b"><hi rend="bold">Expanding the Institutional Repository Mission: Innovating with Linked Data for NASA Digital Curation </hi> </p>
                <p xml:id="zlz_msz_g1b"><hi rend="italic"><persName>Matt Pearson</persName>, <persName>Adrienne Heib</persName>, <orgName>NASA Goddard Space Flight Center</orgName></hi> </p>
                <p xml:id="amz_msz_g1b">Website: <ref target="http://gsfcir.gsfc.nasa.gov/">http://gsfcir.gsfc.nasa.gov/</ref> </p>
                <p xml:id="bmz_msz_g1b">Keywords: thesaurus, digital repository, linked data, searching </p>
                <div type="section">
                    <p xml:id="cmz_msz_g1b">The <orgName>NASA Goddard Space Flight Center Institutional Repository (GSFCIR)</orgName> manages, preserves, tracks, and provides access to the Center’s digital collections and research output. As GSFCIR moves to an entirely RDF-based platform, the <orgName>Goddard Library</orgName> is taking this opportunity to leverage linked data’s capabilities to enhance digital curation efforts, particularly in the area of adding value to digital collections. Objects in GSFCIR’s existing collections have little inter-relation through back-end metadata or front-end interfaces. As representatives of the research and knowledge output of Goddard, these collections and digital objects do have a common thread among them: <orgName>NASA</orgName> missions. Current repository cross-collection searching allows for discovery of some of these connections; however, it is often frustrated by variant names and it does not support a variety of common search behaviors. Historically, NASA mission information has not been maintained in any single, accessible authority. To both achieve its goal of creating better connections in GSFCIR and to provide a valuable resource to present and future NASA communities, the Goddard Library is producing a linked data thesaurus of NASA mission names, including equivalence, hierarchical, and associative relationships. This presentation will focus on how the Library established the need for a NASA-focused linked data missions thesaurus, the careful process of domain analysis and vocabulary development, and its role in aiding future digital curation efforts as GSFCIR grows with new collections. </p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Discovering Literature' in the BBC's Research and Education Space (RES) Project</title> </head>
                <docAuthor><hi rend="italic"><persName>Mia Ridge</persName></hi>, <orgName>British Library</orgName> </docAuthor>
                <p xml:id="p_ncd_2kn_kbb"><hi rend="bold">Discovering Literature' in the BBC's Research and Education Space (RES) Project</hi></p>
                <p xml:id="p_ocd_2kn_kbb"><hi rend="italic"><persName>Mia Ridge</persName>, <orgName>British Library</orgName></hi> </p>
                <p xml:id="p_pcd_2kn_kbb">Website: <ref target="http://blogs.bl.uk/digital-scholarship/2017/05/how-can-a-turtle-and-the-bbc-connect-learners-with-literature.html">http://blogs.bl.uk/digital-scholarship/2017/05/how-can-a-turtle-and-the-bbc-connect-learners-with-literature.html</ref> </p>
                <div type="section">
                    <p xml:id="p_fzy_nkn_kbb">We created LOD records for use by the <orgName>BBC</orgName> <orgName>RES</orgName> project in order to help learners in schools discover our collections and knowledge.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Setting local culture on a global stage with Wikidata</title></head>
                <docAuthor><hi rend="italic"><persName>Dan Scott</persName></hi>, <orgName>Laurentian University</orgName></docAuthor>
                <p xml:id="p_r4h_y3n_kbb"><hi rend="bold">Setting local culture on a global stage with Wikidata</hi></p>
                <p xml:id="p_hnt_d3y_31b"><hi rend="italic"><persName>Dan Scott</persName>, <orgName>Laurentian University</orgName></hi> </p>
                <p xml:id="p_int_d3y_31b">Website: <ref target="http://coffeecode.net">http://coffeecode.net</ref> </p>
                <p xml:id="p_jnt_d3y_31b">Keywords: Wikidata, memory institutions, libraries, local culture</p>
                <div type="section">
                    <p xml:id="p_qg4_v3y_31b">I was a core contributor to the <orgName><ref target="http://schema.org">schema.org</ref> Bibliographic Extension community</orgName>, driving many vocabulary proposals, and implemented the expression of <title level="j">MARC</title> data as schema.org via RDFa in the <title level="j">Evergreen</title>, <title level="j">Koha</title>, and <title level="j">VuFind</title> library catalogues, with a paper presented at the <title level="j">European Semantic Web Conference</title> 2014 (DOI: 10.1007/978-3-319-07443-6_44). I have remained active in schema.org vocabulary development and am currently the sixth most frequent contributor to the schema.org repository (<ref target="https://github.com/schemaorg/schemaorg/graphs/contributors">https://github.com/schemaorg/schemaorg/graphs/contributors</ref>).</p>
                    <p xml:id="p_rg4_v3y_31b">I have led various workshops on publishing LOD via RDFa, including <title level="j">SWIB</title> 2014 and <title level="j">LODLAM</title> (Toronto) in 2016. In 2015, I published "<title level="j">White Hat Search Engine Optimization (SEO): Structured Web Data for Libraries</title>" (<ref target="https://journal.lib.uoguelph.ca/index.php/perj/article/view/3328">https://journal.lib.uoguelph.ca/index.php/perj/article/view/3328</ref>) to encourage libraries to publish machine-readable data to the web. To track the adoption of these approaches in our community, I launched the <orgName>Distributed Index of All Library Location and Event Data</orgName> (DIALLED: <ref target="https://dialled.ca/">https://dialled.ca/</ref>) project to aggregate LOD published by all known Canadian library and archive homepages. As part of the project, I customized the <title level="j">RDFLib</title> library to extract and harmonize JSON-LD, RDFa, and microdata and submitted fixes upstream.</p>
                    <p xml:id="p_sg4_v3y_31b">In 2015, to support the newly launched <title level="j">Canadian Labour Studies Index </title>(<ref target="https://labourstudies.ca">https://labourstudies.ca</ref>) I created the <orgName>RIS2Web</orgName> open source project (<ref target="https://github.com/dbs/ris2web/">https://github.com/dbs/ris2web/</ref>). This enables scholars to create a bibliography using standard <orgName>Zotero</orgName> and have it published as a human and machine-readable database, with content expressed in the schema.org vocabulary.</p>
                    <p xml:id="p_tg4_v3y_31b">I was an invited speaker at the <title level="j">Ohio DevFest</title> 2016 on the subject of schema.org, the <title level="j">Google Knowledge Graph</title>, and Wikidata, which I dubbed "the modern semantic web" (<ref target="https://ohiodevfest.com/schedule/8">https://ohiodevfest.com/schedule/8</ref>). Most recently, at the <title level="j">CAML</title> preconference in May 2017, I led a workshop on using Wikidata to store and retrieve structured data for music festivals with a focus on Canadian musicians (<ref target="https://coffeecode.net/wikidata-workshop-for-librarians.html">https://coffeecode.net/wikidata-workshop-for-librarians.html</ref>).</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">LITMUS (Linked Irish Traditional MUSic)</title></head>
                <docAuthor><hi rend="italic"><persName>Lynnsey Weissenberger</persName></hi>, <orgName>Irish Traditional Music Archive</orgName></docAuthor>
                <p xml:id="p_k1l_1jn_kbb"><hi rend="bold">LITMUS (Linked Irish Traditional MUSic)</hi></p>
                <p xml:id="p_mqw_r3n_kbb"><hi rend="italic"><persName>Lynnsey Weissenberger</persName>, <orgName>Irish Traditional Music Archive</orgName></hi></p>
                <p xml:id="p_nqw_r3n_kbb">Website: <ref target="http://itma.ie">http://itma.ie</ref></p>
                <p xml:id="p_oqw_r3n_kbb">Keywords: ontology, oral transmission, Ireland, music, dance</p>
                <div type="section">
                    <p xml:id="p_nzr_jjn_kbb">Current project: <orgName>LITMUS (Linked Irish Traditional Music)</orgName>. The project has a 2-year time period, beginning in July 2017. We are currently in the planning and information gathering phase of the project; the completed ontology will be delivered in 12 months' time and shortly thereafter published to the web.</p>
                </div>
            </div>
            <div type="chapter">
                <head><title level="a">Oxford Text Archive</title></head>
                <docAuthor><hi rend="italic"><persName>Martin Wynne</persName></hi>, <orgName>University of Oxford</orgName></docAuthor>
                <p xml:id="p_tdy_bjn_kbb"><hi rend="bold">Oxford Text Archive</hi></p>
                <p xml:id="p_eyv_22m_kbb"><hi rend="italic"><persName>Martin Wynne</persName>, <orgName>University of Oxford</orgName></hi></p>
                <p xml:id="p_fyv_22m_kbb">Website: <ref target="http://ota.ox.ac.uk/">http://ota.ox.ac.uk/</ref></p>
                <p xml:id="p_gyv_22m_kbb">Keywords: English, historical texts, bibliography</p>
                <div type="section">
                    <p xml:id="p_kyv_22m_kbb">As well as making available the full text of many works, including the 60,000+ texts of the <orgName>Text Creation Partnership </orgName>which are in the public domain, the <orgName>Oxford Text Archive</orgName> holds and makes available detailed metadata for its collection, including dates of publication of original works, names and dates of authors, places of publication, etc. We are currently investigating ways to make this information available as linked open data, in order to make it possible for users to search across repositories and collections for works and other information about people, places, dates, events, etc.</p>
                </div>
            </div>
            
            <div>
                <div type="chapter">
                    <head><hi rend="italic"><title>PROGRAM PITCHES</title></hi></head>
                    <figure>
                        <graphic url="http://beta.cwrc.ca/islandora/object/cwrc%3A414cd250-9b80-49c4-95d2-c9b068d132bb/datastream/MEDIUM_SIZE/view"/>
                    </figure>
                    <p xml:id="fqz_msz_g1b"><title level="m"><hi rend="bold">PROGRAM PITCHES</hi></title></p>
                    <p xml:id="gqz_msz_g1b">These pitches are extracts and composites derived from the <emph>Position Papers</emph> (below) on gaps or opportunities with respect to Linked Open Data for the humanities. We have tracked indebtedness to each paper by author. They can be read in full below for context. </p>
                    <p xml:id="p_wt1_v3q_h1b"><hi rend="italic">Image credit: <persName>Elco van Staveren</persName> on flickr (<ref target="https://www.flickr.com/photos/103454225@N06/9965173654">https://www.flickr.com/photos/103454225@N06/9965173654</ref>). License: CC BY-SA 2.0</hi></p>
                </div>
                <div type="chapter">
                    <head>Balancing Needs: Engagement, Outreach, Training</head>
                    <docAuthor>Pitch #1</docAuthor>
                    <p xml:id="hqz_msz_g1b">Pitch #1: Balancing Needs: Engagement, Outreach, Training </p>
                    <p xml:id="iqz_msz_g1b">. . . [O]ne of the possible ways of improving the reuse of data would be to provide specific training on how to overcome these difficulties. In the same way, many of the projects that are starting to publish linked Open data from scratch deal with data coming from very different disciplines making it is difficult to find a unique connecting thread to link all this data together. I think that the election of a common feature such as place to produce this data as a shared reference that everyone can link to would be a very good improvement to facilitate the access to these resources. This is already being achieved by <ref target="http://pelagios.org">Pelagios.org</ref> and the data related to the ancient world but could be applied to many other disciplines in the Digital Humanities. The only way to get Linked Data to really take off as a technological resource capable of advancing humanities research is to get researchers to start working with it. Because of this, I think that some of the main barriers we need to surpass are the lack of training and a more insightful documentation of the projects that are being carried out at the moment so that new users can have a model to look at the time to integrate or link their own data. The improvement of these two will reduce the barriers for beginners to get into the use of this technology. Finally, The next step would be to get all these new researchers to become part of a big community of LOD users as a place to share common difficulties and possible solutions. I expect this workshop to be the appropriate forum for qualified researchers to present their projects and discuss their difficulties and possible ways to advance research in LOD by facilitating the creation of a big community of LOD users. </p>
                    <p xml:id="jqz_msz_g1b">(<persName>Paula Loreto Granados García</persName>) </p>
                    <p xml:id="kqz_msz_g1b">***</p>
                    <p xml:id="lqz_msz_g1b">. . . I have often encountered a divergence between the needs of easy, flexible, and attractive web publishing for a general audience and the needs of producing and consuming precise and consistent metadata. Because <orgName>Omeka</orgName> (both Classic and S) are primarily web publishing platforms (as opposed, e.g., to a cataloging system), we design the system to encourage good metadata practices, but also need to facilitate the web-publishing needs of our users. This can sometimes led to choices that emphasize public presentation over good metadata practices. For example, a request we received for Omeka classic was to allow HTML to be entered in the Dublin Core metadata fields, with the result that people could and would use the embed code for a YouTube video in the Dublin Core Description field. </p>
                    <p xml:id="mqz_msz_g1b">Other users, of course, are more precise in their use of metadata fields, and Omeka S takes greater pains to enforce interoperable metadata, as outlined above. Indeed, many of the design choices for Omeka S were informed by our experience with Omeka Classic in negotiating the balance of easy website creation (with good metadata), and best Linked Open Data practices (that still allows experts and non-experts alike to build the sites they want to build). </p>
                    <p xml:id="nqz_msz_g1b">I would like to explore this balance, and discuss how others have approached it. </p>
                    <p xml:id="oqz_msz_g1b">(<persName>Dr. Patrick Murray-John</persName>) </p>
                </div>
                <div type="chapter">
                    <head>Beyond Silos: Data Exchange (APIs, etc.)</head>
                    <docAuthor>Pitch #2</docAuthor>
                    <p xml:id="pqz_msz_g1b">Pitch #2: Beyond Silos: Data Exchange (APIs, etc.)</p>
                    <p xml:id="tqz_msz_g1b">As the <orgName>Trismegistos</orgName> project focuses on the domain of linked open data in digital (ancient) history, a lot of work remains to be done. Initiatives such as <orgName>EAGLE</orgName> (<ref target="https://www.eagle-network.eu/">https://www.eagle-network.eu/</ref>), <orgName>PELAGIOS</orgName> (<ref target="http://commons.pelagios.org/">http://commons.pelagios.org/</ref>) or <orgName>SNAP:DRGN</orgName> (<ref target="https://snapdrgn.net/">https://snapdrgn.net/</ref>) have proven that it is possible to establish a working linked open data environment in their respective field of epigraphy, (ancient) place names and prosopography. Still, a lot of newly founded digital projects in the field of ancient history try to reinvent the wheel with their own vocabularies, data standards, et cetera, mostly because they are unaware of the existence or the possibilities of the existing LOD environments. The Trismegistos project believes in a better communication about these tools, as well as documenting their user specifications and requirements. Hence it takes part in initiatives such as the <orgName>Digital Classicist Wiki</orgName> (<ref target="https://wiki.digitalclassicist.org/">https://wiki.digitalclassicist.org/</ref>) or the aforementioned Pelagios Commons. </p>
                    <p xml:id="uqz_msz_g1b">(<persName>Tom Gheldof</persName>) </p>
                    <p xml:id="sqz_msz_g1b">***</p>
                    <p xml:id="qqz_msz_g1b">The real benefit of linked data is derived when datasets are tightly interlinked through the reuse of instance URIs and shared vocabularies. DH linked data is often fairly siloed in a single project infrastructure, and only rarely are well-documented HTTP APIs offered to allow machine access to the data store. There is a huge opportunity to collaboratively develop fairly standardized APIs to allow researchers to query, harvest, mash-up, and hack stores of cultural linked data. </p>
                    <p xml:id="rqz_msz_g1b">(<persName>Lisa Goddard</persName>)</p>
                </div>
                <div type="chapter">
                    <head>Bridging Difference in (Local) Data Production</head>
                    <docAuthor>Pitch #3</docAuthor>
                    <p xml:id="vqz_msz_g1b">Pitch #3: Bridging Difference in (Local) Data Production </p>
                    <p xml:id="p_gvm_m44_h1b"><orgName>Wikidata</orgName> is an international community-driven platform and a reliable data store for persistent, common URIs. It is international in scope and already supports a multilingual environment allowing users to work in their language of choice. Properties can be added with community consensus. Because it has a very low threshold for the creation of entities, including the upload of datasets, it possible to think of it as a productive space for the creation of entities outside, or alongside, the more formal bounds of academic institutions and cultural heritage institutions. </p>
                    <p xml:id="p_nrm_5x4_h1b">(<persName>Stacy Allison-Cassin</persName>, <persName>Joy Kirchner</persName>) </p>
                    <p xml:id="brz_msz_g1b">***</p>
                    <p xml:id="crz_msz_g1b">Entities, including personal names, place names, and event names, included in the Archive are very specific to one person, <persName>Marcel Proust</persName>, and his family, i.e., entities found in the collection often are not expressed using established controlled authority names that could provide additional contextual information or authorized forms of names. While trying to reconcile entities with authorized LOD sources, including VIAF and BnF, we also tried to publish information about personal names housed in the local database as Schema.org vocabularies assuming the schema:Person class. We analyzed the information included in the database and selected appropriate vocabularies so it can integrate with LOD sources when found. This work was only possible because the local authority control that has been undertaken for the Archive. In the absence of such upfront investment, questions arise, such as what is the best way to ensure the authority work for digitized special collections, and how to make them available as LOD? </p>
                    <p xml:id="drz_msz_g1b">(<persName>Myung-Ja K. Han</persName>, <persName>Timothy W. Cole</persName>, <persName>Jacob Jett</persName>, <persName>Caroline Szylowicz</persName>) </p>
                    <p xml:id="erz_msz_g1b">***</p>
                    <p xml:id="frz_msz_g1b">My goal for participating in this workshop is to gain a better understanding and develop the vocabulary to articulate ways in which my nascent research project, <orgName>REED London</orgName>, can from its inception integrate best practices for designing its data structure to make it linkable and worth linking from (and to). This need to focus on outward-facing data speaks to a larger challenge as REED London assists in supporting the Records of Early English Drama's shift from a position of closed to open data structures. </p>
                    <p xml:id="hrz_msz_g1b">REED's experience to date with LOD has been focused on establishing ontologies that make sense of REED's entities for REED's "internal" publication purposes. In its first born-digital edition, Staffordshire, the REED staff worked with an EATS/KILN process to develop and publish people, places, and organizations included in the Staffordshire records (see "<ref target="https://ereed.library.utoronto.ca/about/digital/#introduction">REED Online Digital Methodology</ref>" for an outline of REED's current approach to mark-up and entity tagging; see the <ref target="https://eats.readthedocs.io/en/latest/">Entity Authority Tool Set</ref> website for an overview of EATS; see the <ref target="https://wiki.tei-c.org/index.php/Kiln">Kiln TEI wiki</ref> page for an overview of its features and capabilities). With REED London we are at a juncture where we need to think about how to work forward with the <placeName>London</placeName>-centric data, which has obvious value for other research projects beyond performance history, including and political, religious, and cultural studies, and linguistics. At the same time, we need to ensure that the dataset outlined in Staffordshire and developed for further deployment with future REED collections is synchronized with the LOD development we undertake for REED London. </p>
                    <p xml:id="jrz_msz_g1b">(<persName>Diane Jakacki</persName>) </p>
                    <p xml:id="krz_msz_g1b">***</p>
                    <p xml:id="lrz_msz_g1b">Three potential paths for MoEML’s [<orgName>Map of Early Modern London</orgName>'s] triples in LINCS [the <orgName>Linked Infrastructure for Networked Cultural Scholarship</orgName>, see profile for Brown] are as follows. </p>
                    <list>
                        <item> Other projects use MoEML ids to handcode and curate their own location entities. REED, ISE, and DRE are already hoping to do so in its new texts and collections. LINCS would enable these projects to realize a long-standing research objective to locate REED, ISE, and DRE locations on MoEML’s maps. If their locations already have ids, LINCS helps build a crosswalk to link their ids to MoEML ids and URIs. These crosswalks are then published on LINCS to facilitate tagging. </item>
                        <item>
                            Other projects use the MoEML-Pantzer, MoEML-GIS, and MoEML-(E)STC crosswalks (published on LINCS) to collocate pre-existing tagging in their texts or fields in their data with MoEML ids. MoEML and DEEP have already used the MoEML-Pantzer crosswalk to parse DEEP’s XML and resolve its Pantzer ids into MoEML ids.
                        </item>
                        <item> MoEML’s gazetteer enables NER to identify <placeName>London</placeName> toponyms in untagged, unmodernized early modern texts. LINCS’ NER tools, coupled with MoEML’s triples, will be able to find new instances of placenames in the EEBO-STC corpus and in the remainder of the EEBO-corpus as OCR’d by eMOP, or in <orgName>Voyant</orgName>'s DREaM corpus (as tokenized and VARD-standardized by the EMC project). MoEML will publish these instances with links to their URIs. NER will also help parse location metadata in the prosopographical database proposed by <persName>Brent Nelson</persName>’s <orgName>Early Modern Social Networks</orgName>. Ideally, users would run their data through LINCS NER application, using MoEML’s gazetteer triples to find location entities. </item>
                    </list>
                    <p xml:id="nrz_msz_g1b">(<persName>Janelle Jenstad</persName>) </p>
                    <p xml:id="p_bjb_m44_h1b">***</p>
                    <p xml:id="wqz_msz_g1b">Researchers and practitioners have demonstrated an encouraging understanding and embrace of the principles of publishing five-star LOD. Datahub.io catalogues over 11,000 linked data sets (<ref target="https://datahub.io/dataset">https://datahub.io/dataset</ref>), although many of these data sets do not specify an open license and are thus LD, not LOD; or their license requires attribution, which can be cumbersome when integrating data from many different data sets; or the data is not offered in a linked format. These are all barriers that prevent digital humanists from using LOD tools and methodologies to incorporate the data in their work. </p>
                    <p xml:id="xqz_msz_g1b">We must also acknowledge the prevalence of non-LOD practices by memory institutions like libraries, archives, and galleries that continue to describe entities such as people, texts, fonds, art, music, and events using traditional techniques and formats. Even the use of authority fields in a "machine readable" format such as MARC that does link to a data set often leads to the barest additional data; in the case of the <orgName>Virtual International Authority File (VIAF)</orgName>, birth and death dates, a sampling of works to which the person has contributed, and selected publishers is typical. There is no richness in the representation of the human being central to the work: no expression of relationships to others outside of potential collaborations, or to events in which they participated, or the lives they have lived, or samples of their work, or images, or videos. </p>
                    <p xml:id="yqz_msz_g1b">Many of the traditional centralized data sets for memory institutions impose barriers to participation. For an author, musician, or artist to surface in VIAF, they must appear in records contributed to <orgName>WorldCat</orgName> by a library that is a member of <orgName>OCLC</orgName>; not only does this rule out many libraries that cannot afford an OCLC cataloguing membership, but it also prevents individuals from contributing to the data set. As a result, the perspectives of that subset of libraries that can afford the financial and resource cost of a membership are privileged, and a band like <title level="j">A Tribe Called Red</title> that has received multiple Juno awards has only a skeletal presence (<ref target="http://viaf.org/viaf/308795327">http://viaf.org/viaf/308795327</ref>); individual band members, such as <persName>Deejay NDN aka Ian Campeau</persName>, are not represented at all in VIAF. </p>
                    <p xml:id="zqz_msz_g1b">A potential solution is to adopt <orgName>Wikidata</orgName> as a ready-to-hand tool, only publishing data outside of Wikidata when its constraints demand an augmented solution. By requiring the Creative Commons Zero dedication for all contributions, Wikidata's truly open dataset can be used for any purpose. Its SPARQL endpoint supports dynamic use by standard LOD tools, while the complete dataset can be mirrored for more intense local use. Memory institutions, researchers, and practitioners can adopt Wikidata as not only a source of authority data, but can independently add new entities and extend existing descriptions to reflect local culture in a global database--and they can dynamically integrate Wikidata's rich representations of people, places, and events back into their own collections and works. </p>
                    <p xml:id="arz_msz_g1b">(<persName>Dan Scott</persName>)</p>
                </div>
                <div type="chapter">
                    <head>Certainty</head>
                    <docAuthor>Pitch #4</docAuthor>
                    <p xml:id="orz_msz_g1b">Pitch #4: Certainty</p>
                    <p xml:id="prz_msz_g1b">
                        When cataloguing rare and unpublished material librarians often make assertions that are either probable or approximate. It would be useful in a linked data environment to capture the degree of certainty with which an assertion has been made.
                    </p>
                    <p xml:id="qrz_msz_g1b">(<persName>Lisa Goddard</persName>) </p>
                </div>
                <div type="chapter">
                    <head>Event Models</head>
                    <docAuthor>Pitch #5</docAuthor>
                    <p xml:id="rrz_msz_g1b">Pitch #5: Event Models</p>
                    <p xml:id="srz_msz_g1b">The <orgName>Linked Pasts Working Group</orgName> of <orgName>Pelagios Commons</orgName> has a near-term goal of coordinating collaborative development a set of requirements for technical infrastructure useful to the historical LOD scholarly community (<ref target="http://commons.pelagios.org/groups/linked-pasts/">http://commons.pelagios.org/groups/linked-pasts/</ref>). Towards that end we are organizing a working meeting in London in late July to hammer out a draft high-level specification document for consideration by the community. The <title level="j">DH2017 LOD Workshop</title> would be a great opportunity for the Linked Pasts WG to outline the results of that meeting and solicit feedback.</p>
                    <p xml:id="trz_msz_g1b">One key aspect of a Linked Pasts infrastructure will be integrating data about cultural objects and people with the place LOD now being successfully integrated by the <orgName>Pelagios</orgName> project. We speculate that events and event models may be highly relevant. Events are a powerfully integrative category of data, as demonstrated by their effective modeling in the <orgName>CIDOC-CRM ontology</orgName>, which has arguably seen growing uptake in the <title level="j">GLAM</title> domain. Arguably, CIDOC-CRM is too complex to garner support from small projects—but a simple, upwardly-compatible event data standard may be a worthwhile goal.</p>
                    <p xml:id="p_sdc_zmy_31b">What are other essential elements of a future Linked Pasts? We are hoping to hear many perspectives from the participants in this workshop.</p>
                    <p xml:id="urz_msz_g1b"><ref target="http://commons.pelagios.org/groups/linked-pasts/">http://commons.pelagios.org/groups/linked-pasts/</ref> </p>
                    <p xml:id="vrz_msz_g1b"><ref target="http://commons.pelagios.org/2017/03/events-and-pelagios/">http://commons.pelagios.org/2017/03/events-and-pelagios/</ref> </p>
                    <p xml:id="wrz_msz_g1b">(<persName>Karl Grossner</persName>) </p>
                </div>
                <div type="chapter">
                    <head>From Production to Consumption (Tools)</head>
                    <docAuthor>Pitch #6</docAuthor>
                    <p xml:id="xrz_msz_g1b">Pitch #6: From Production to Consumption (Tools)</p>
                    <p xml:id="isz_msz_g1b">Aggregator widget: a generic and easily adaptable piece of web code that could be configured to </p>
                    <div>
                        <list>
                            <item>Start from a privilege a particular LOD store</item>
                            <item>
                                Look for associated triples/objects by order of priority in a configurable list
                            </item>
                            <item>
                                Provide an organized view of the results, along the lines of the information box generated from the
                                <title level="j">Google Knowledge Graph</title>
                                or the
                                <orgName>
                                    Social Networks and Archival Context (SNAC) project
                                </orgName>
                                (e.g.
                                <ref target="http://socialarchive.iath.virginia.edu/ark:/99166/w6dz07bk">
                                    http://socialarchive.iath.virginia.edu/ark:/99166/w6dz07bk
                                </ref>
                                ), with extensibility to allow for greater interaction with the content such as inviting contributions or sending it to tools.
                            </item>
                        </list>
                        <p xml:id="jsz_msz_g1b">(<persName>Susan Brown</persName>) </p>
                    </div>
                    <div>
                        <p xml:id="p_hbq_qz4_h1b">***</p>
                        <p xml:id="yrz_msz_g1b">We need improved tools for exploring linked data. Most academics are not going to learn SPARQL in order to query linked data stores, just as few people learned SQL in order to query relational databases. Better visualization and discovery tools are essential in order to demonstrate the benefits of linked data (for example, the ability to find connections across degrees of separation), and to drive wider adoption of these technologies. <orgName>Big Diva</orgName> is a good early example of a linked data visualization interface, but we really need more examples that expose the richness and unique capabilities of linked data stores. In order to develop these interfaces, however, we need to be able to query the data via APIs, as in the pitch for <title level="j">Beyond Silos: Data Exchange</title>. </p>
                        <p xml:id="zrz_msz_g1b">(<persName>Lisa Goddard</persName>) </p>
                        <p xml:id="asz_msz_g1b">***</p>
                        <p xml:id="p_dff_3y4_h1b">While libraries are busily experimenting with LOD, how scholars engage with LOD is not well-known. Do scholars harvest and publish LOD directly or only consume them indirectly through LOD-aware applications. What do they want to get out of new LOD-based user services? LOD promise new models of discovery, improved connectedness and machine-assisted analysis, but we need to better understand what LOD tools they find attractive, what LOD tools really facilitate scholarly research and teaching. This is a gap in current understanding. What are the best ways to gather and discuss these needs with DH scholars in semantic and linked data environment? </p>
                        <p xml:id="p_eff_3y4_h1b">(<persName>Myung-Ja (MJ) K. Han</persName>, <persName>Timothy W. Cole</persName>, <persName>Jacob Jett</persName>, <persName>Caroline Szylowicz</persName>)</p>
                        <p xml:id="p_fff_3y4_h1b">***</p>
                        <p xml:id="bsz_msz_g1b">It seems that there is often a lack of awareness about the possibilities of Linked Data, leading to a reliance on familiar approaches such as relational databases. Additionally, where Linked Data is considered as an option, the technical barrier may be seen as too high. Both of these issues could be resolved by researchers and developers forming a collaborative relationship, rather than the developers being seen predominantly as service providers. This way of working would ensure that Humanities researchers receive sufficient advice on the data structures that would best allow them to fulfil their research objectives, as well as providing an insight into the development process. For the developers, working with potential users would facilitate the successful development of accessible tools and resources. Both parties would also benefit by learning to speak the other's 'language', which would be extremely valuable when communicating with new colleagues in future collaborations.</p>
                        <p xml:id="csz_msz_g1b">More opportunities lie not in the production of new datasets and the creation of new resources, but in enhancing existing material. Projects that focus on improving resource usability should increase the reach of the data, making it more accessible to researchers without a technical background, as well as users beyond academia.</p>
                        <p xml:id="dsz_msz_g1b">(<persName>Sarah Middle</persName>)</p>
                    </div>
                </div>
                <div type="chapter">
                    <head>Linguistic LOD</head>
                    <docAuthor>Pitch #7</docAuthor>
                    <p xml:id="ksz_msz_g1b">Pitch #7: Linguistic LOD</p>
                    <p xml:id="lsz_msz_g1b">The linguistic linked open data working group (<ref target="http://linguistic-lod.org/llod-cloud">http://linguistic-lod.org/llod-cloud</ref>) is pushing to depict most languages in a Semantic Web representation. This includes word forms, Part-of-Speech Tags, translations, unicode representations, word etymology and senses ususally modelled according to one of the different available standards such as Lemon-RDF. While such resources can play a valuable role in applications such as machine translation, the impact of semantic dictionaries in the Digital Humanities has in the opinion of the author been underrepresented. The author therefore proposes to increasingly link linguistic linked open data with artifacts that are already present on the web in whatever form. A great example of such an interlinkage is the SPARQL endpoint of the <orgName>British museum</orgName> in <placeName>London</placeName> (<ref target="http://collection.britishmuseum.org">http://collection.britishmuseum.org</ref>). Here, artifacts of the museum are highlighted and linked together in a semantic sense. What is usually missing however, is the interlinkage on an inscription text level. With the emergence of linguistic linked data, artifacts could be: </p>
                    <div>
                        <list>
                            <item> Categorized using textual semantics</item>
                            <item> Automatically cross-related to different artifacts/important people of that time or other referenced content recognized from the text </item>
                            <item>
                                Ready for applying data science algorithms to increase knowledge gain from historical objects
                            </item>
                        </list>
                    </div>
                    <div>
                        <head>Application example:</head>
                        <p xml:id="psz_msz_g1b">As an application example the author recommends an automated analysis of cuneiform texts present in the <orgName>Cuneiform Digital Library Initiative (CDLI)</orgName> (<ref target="http://cdli.ucla.edu">http://cdli.ucla.edu</ref>) repository. Every cuneiform tablet available would be registered using a URI and properties appended to the cuneiform tablet would be interlinked in an automated fashion. Meanwhile a textual analysis of the cuneiform tablets, typically done via concept matching over nouns and named entities would provide an additional categorization which complements already existing metadata well. In a next step further analysis for co-ocurrence and various other text mining approaches can be tested to extract information previously inaccessible to the domain experts.</p>
                    </div>
                    <div>
                        <head>Possible Benefits:</head>
                        <p xml:id="qsz_msz_g1b">Benefits the aforementioned approach can be summarized as follows: </p>
                    </div>
                    <div>
                        <list>
                            <item>
                                Accessibility - A universal SPARQL access point for a particular set of cultural heritage objects (here cuneiform tablets) adhering to the linked data principles and interlinked to other knowledge bases
                            </item>
                            <item>
                                Flexible text precategorization and text mining analysis in order to find new correlations of knowledge in already existing non-harvested text repositories
                            </item>
                        </list>
                    </div>
                    <div>
                        <p xml:id="tsz_msz_g1b">(<persName>Timo Homburg</persName>)</p>
                    </div>
                </div>
                <div type="chapter">
                    <head>Natural Language GUI for SPARQL</head>
                    <docAuthor>Pitch #8</docAuthor>
                    <p xml:id="usz_msz_g1b">Pitch #8: Natural Language GUI for SPARQL</p>
                    <p xml:id="atz_msz_g1b">Natural language sparql query interface for humanities scholars: This has been attempted but not done well enough to be intuitive and easily usable by humanities scholars. A joint effort in reviewing what exists already, determining what existing code would be most easily adapted for use across a broad range of humanities projects, and developing specs for such an interface would be really useful and potentially lead to a collaborative initiative. </p>
                    <p xml:id="btz_msz_g1b">(<persName>Susan Brown</persName>) </p>
                    <p xml:id="p_qfn_d1p_h1b">***</p>
                    <p xml:id="ysz_msz_g1b">One of the main objectives of my research is to try and explain to historians and archaeologists the benefits of incorporating LOD in their research methodologies and more specifically the benefits that the application of LOD resources will bring to the study of the cultural processes that occurred in <placeName>Spain</placeName> after the Roman arrival. In this sense, the reutilisation of the data already available online although not in a linked open format is one of the main objectives of my study, nevertheless, the barriers of data integration are endless. The users need very advanced knowledge of computer programming languages as well as SPARQL and database developing skills which are obviously not available to everybody. Many of the databases I am looking at do not fulfil one or some of the standards of LOD. In some cases, the data is not in RDF, there is no SPARQL endpoint, there is no API etc. I think one of the possible ways of improving the reuse of data would be to provide specific training on how to overcome these difficulties. In the same way, many of the projects that are starting to publish linked Open data from scratch deal with data coming from very different disciplines making it is difficult to find a unique connecting thread to link all this data together. I think that the election of a common feature such as place to produce this data as a shared reference that everyone can link to would be a very good improvement to facilitate the access to these resources. This is already being achieved by <orgName>Pelagios.org</orgName> and the data related to the ancient world but could be applied to many other disciplines in the Digital Humanities. </p>
                    <p xml:id="p_bnp_31p_h1b">(<persName>Paula Loreto Granados García</persName>) </p>
                    <p xml:id="zsz_msz_g1b">***</p>
                    <p xml:id="vsz_msz_g1b">Many DH and GLAM institutions and projects have embraced the LOD model and produced RDF from their data - this is wonderful. But the time is now to stop viewing the production and publication of RDF as the end of a successful workflow. As a community that's been pioneering in LOD development in a lot of ways, we need to begin to plan, design, and realise systems that harness the potential of the LOD cloud, benefit from smarter reasoners, and really move beyond just pushing out RDF. At the same time, we need to develop GUIs that allow users who don't know SPARQL (and have no desire to learn) to benefit (and this appreciate) the power of LOD. </p>
                    <p xml:id="wsz_msz_g1b">(<persName>Dr Alfie Abdul-Rahman</persName>, <persName>Dr Daniel Bangert</persName>, <persName>Dr Terhi Nurmikko-Fuller</persName>)</p>
                </div>
                <div type="chapter">
                    <head>Politics of Ontologies: Homogeneity, Heterogeneity, Intersectionality</head>
                    <docAuthor>Pitch #9</docAuthor>
                    <p xml:id="ctz_msz_g1b">Pitch #9: Politics of Ontologies: Homogeneity, Heterogeneity, Intersectionality</p>
                    <p xml:id="p_tpr_kp4_h1b">While digital humanities researchers and those in the GLAM (galleries, libraries, archives and museums) are engaging in projects related to Linked Data there remains a gap in connecting this engagement with questions of diversity and inclusion. Issues related to gender, sexuality and racialization are often hidden in traditional descriptive practices and ontologies, reinforcing problematic practices. </p>
                    <p xml:id="p_cjv_kp4_h1b">Working with local communities to understand and create knowledge structures as well as working toward decolonization and inclusive structures is possible with LOD. Numerous projects include some form of crowdsourcing, either in aiding the work of entity recognition or as a means of capturing annotation. While this work is helpful to the work of the project, can this work create a loop back to empower local communities in understanding the digital environment, as a hook for the expansion of advocacy for open data, open access, and the application open licensing of content, and greater access to cultural heritage materials, while also respecting the needs and sensitivities of individual communities. For example issues of ownership, cultural recovery or storytelling. Where does our responsibility lie in the creation of a means of consuming data and providing communities with the use of LOD? How will this figure into alternate models for the consumption of LOD? How do issues of preservation, persistence and control impact traditionally underrepresented communities? </p>
                    <p xml:id="p_tzf_31p_h1b">(<persName>Stacy Allison-Cassin</persName>, <persName>Joy Kirchner</persName>)</p>
                    <p xml:id="p_dp5_jp4_h1b">***</p>
                    <p xml:id="dtz_msz_g1b">[… A]pplying linked open practices to cultural records requires digital humanists to negotiate an irresolvable tension between data homogeneity and heterogeneity. If wielded as a blunt instrument across the Web, LOD practices would potentially involve imposing a universal structure and vocabulary on all linked data in order to ensure their interoperability. Such a structure would distort data that, through their heterogeneity, reflect the contingencies, ambiguities, and idiosyncrasies of human cultures. </p>
                    <p xml:id="etz_msz_g1b">Linked open biographical encoding is a key site for negotiating this tension. To date, the field of digital cultural heritage offers few models of LOD praxis that maintain the heterogeneity of biographical data to some degree while implementing an ontology that overlaps as much as possible with other linked open data structures. However, a number of digital humanities initiatives, such as the <orgName>Linked Modernisms Project</orgName> and the <orgName>Canadian Writing and Research Collaboratory</orgName>, are pioneering this work through the biographical components of their respective ontologies. <orgName>The Yellow Nineties (Y90s) Personography</orgName> also aims to contribute to the praxes of linked open biographical encoding in the digital humanities. We strive in our methods and our outputs to make visible the cultural contingencies that shape the availability of biographical records, and to document persons without eliding the complexities and contradictions of their recorded lives. </p>
                    <p xml:id="ftz_msz_g1b">Developing a shared set of best practices for balancing universality and customization would benefit digital humanities scholars developing biographical LOD. Identifying notable advantages and challenges of biographical LOD, as we have encountered these in our own work, offers a starting point for developing these best practices. Significant advantages that LOD presents to biographical scholarship include its flexibility to accommodate heterogeneous data and its capacity to link datasets across the vast research network of the semantic web. Significant challenges that LOD poses for biographical digital humanities include the structuring of socio-historically contingent attributes and classes and the negotiation of historical politics of classification. To give an example of the former, the values and classes of occupations in the Y90s ontology are specific to the Victorian period. This sub-structure of our ontology has no comprehensive precedent in the information structures developed by major cultural heritage institutions such as the <orgName>Getty Institute</orgName> and the <orgName>Library of Congress</orgName>. To give an example of the latter, Y90s collaborators are exploring how best to avoid reinscribing Victorian imperial values as we document the anglicized name variants of colonial entities. In many cases, LOD effectively reifies colonialism by including the anglicized variant as the primary designation associated with an individual’s uniform resource identifier (URI) on the Web. Recognizing such challenges as specific cases of more generalizable issues for biographical scholarship in LOD, we argue that responses to such issues developed by the Y90s team and other researchers may germinate into best practices for future scholarship that applies LOD principles without sacrificing the heterogeneous character of biographical data. </p>
                    <p xml:id="p_lrk_j1p_h1b">(<persName>Alison Hedley</persName>, <persName>Lorraine Janzen Kooistra</persName>)</p>
                    <p xml:id="gtz_msz_g1b">***</p>
                    <p xml:id="htz_msz_g1b">The present moment in the development of LOD projects is an opportunity to cultivate an intersectional approach to building technologies for curating, preserving, and linking the objects and records of cultural history, Indeed, the linked nature of LOD demands an intersectional ethos. An intersectional approach to data curation has been most prominent in RDF projects like <orgName>The Digital Index of North American Archaeology (DINAA)</orgName> and the <orgName>Australian Humanities Networked Infrastructure Service (HuNI)</orgName> and content management systems like <title level="j">Mukurtu</title>, all of which consider cultural access protocols specific to the currently living populations whose cultural heritage is subject to preservation. I contend that LOD at large must extend these projects. It no longer suffices to consider cultural access protocols exclusively in the context of data curation projects that house the cultural heritage of indigenous peoples. The decolonial logic of these projects should be expanded to LOD curation in general in order to advance an approach to data curation that considers context and history as first principles.</p>
                    <p xml:id="p_w2y_mdq_h1b">(<persName>Emily Christina Murphy</persName>)</p>
                </div>
                <div type="chapter">
                    <head>Preservation and Sustainability</head>
                    <docAuthor>Pitch #10</docAuthor>
                    <p xml:id="itz_msz_g1b">Pitch #10: Preservation and Sustainability</p>
                    <p xml:id="jtz_msz_g1b">One of the key concerns about linked data is the general fragility of URL type links. Studies on link rot reveal a great deal of instability even in well-curated documents like <orgName>Supreme Court</orgName> decisions, and respectable law journals (Lessig et al, 2013). To rely heavily on URIs to external vocabularies and instance data can represent a significant risk to a project, but the imperative to reuse identifiers is a foundational tenet of linked data. Librarians and publishers have already made significant strides towards persistent identifiers like DOIs, Handles, and Perma.cc. We need to collaborate with the DH community around frameworks and infrastructure to steward stable, persistent URIs. </p>
                    <p xml:id="p_gwb_k1p_h1b">(<persName>Lisa Goddard</persName>)</p>
                    <p xml:id="ktz_msz_g1b">***</p>
                    <p xml:id="ltz_msz_g1b">. . . [W]ithin the <orgName>AHRC</orgName> projects dataset, the majority of Linked Data projects seem to focus primarily on data production, with very few concentrating on data consumption or enhancement. If a production-focused project runs out of time or funding before a user-friendly interface can be developed, use of the data is then often restricted to people with the technical skills to use a SPARQL endpoint, greatly reducing the number of potential users.</p>
                    <p xml:id="mtz_msz_g1b">This apparent prioritisation of production over consumption could be due to a real or perceived funder bias towards projects that are seen to be more innovative. To address this, funders should actively encourage proposals for projects that seek to enhance existing resources or perform usability research. Additionally, funders should be prepared to provide small-scale follow-on funding to ensure the data produced by a project is accessible to a wider audience, increasing the potential usage and usefulness of the resulting resource. A demonstrable increase in the scope and use of a resource, the reuse of its data in different contexts, as well as gaining important insights to inform future resource development, should provide an attractive proposition for future funding. </p>
                    <p xml:id="ntz_msz_g1b">The above issues are largely infrastructural, and relate to the shift in ways of working between the 'traditional' and the 'digital' Humanities project. A digital resource should not be a discrete unit that is abandoned at the end of a project, and Linked Data should be a way of ensuring sustainability of such resources by their connection to the wider web, and the reuse of their material. </p>
                    <p xml:id="otz_msz_g1b">(<persName>Sarah Middle</persName>)</p>
                </div>
                <div type="chapter">
                    <head>Scholarly Reuse, Recycle, Refinement, Enhancement</head>
                    <docAuthor>Pitch #11</docAuthor>
                    <p xml:id="ptz_msz_g1b">Pitch #11: Scholarly Reuse, Recycle, Refinement, Enhancement </p>
                    <p xml:id="ztz_msz_g1b"><emph>Contribution Crowdsourcing workflow</emph>: One of the promises of LOD is the potential to have experts contribute casually to the improvement of online resources, whether by annotating, identifying, correcting, transcribing, or linking materials. A generic tool, ideally building on an existing annotation tool, that would support the contributions of external contributors including citizen scholars to scholarly resources, and provide a workflow that would vett the contributions for inclusion/action, either by crowd-sourcing a certain number of approvals, delegating to a group of trusted individuals, or sending through a centralized workflow. <persName>Carl Stahmer</persName> at the <orgName>UC Davis University Library</orgName> has been developing an example of the first type of workflow for the linked data enhancement of the <title level="j">English Short Title Catalogue (ESTC21)</title>. It would be useful to learn what other similar workflows exist and consider whether the use cases are generic enough that it would make sense to collaborate on specs and possibly development. </p>
                    <p xml:id="p_ysf_q1p_h1b">(<persName>Susan Brown</persName>)</p>
                    <p xml:id="p_f5k_q1p_h1b">***</p>
                    <p xml:id="wtz_msz_g1b">Another challenge lies in the incorporation of or the collaboration with the cultural heritage sector. For example in disciplines such as papyrology and epigraphy textual sources have been somewhat alienated from the physical documents, and in particular the whereabouts of the text are often neglected. This has led to a situation where museums and other institutions housing the documents often do not have access to the wealth of information collected by academia. Vice-versa academics often lack pieces of information that are only known to those who keep the items safe. Trismegistos is currently trying to bridge this gap (see also the aforementioned collaboration with the <orgName>British Museum</orgName> or the <title level="j">Vienna papyrus collection</title>), but this is a slowly progressing process that is dependent on many factors (e.g., availability of open source material on museum websites and academic publishers, linked open data standards, ...). With initiatives such as <orgName>Trismegistos Collections</orgName> (<ref target="http://www.trismegistos.org/coll/index.php">http://www.trismegistos.org/coll/index.php</ref>), the TM project has undertaken a first step towards a better retrievability of the physical location of papyrological and epigraphic texts in museum and private collections and linking them to academic publications, associated with these texts.</p>
                    <p xml:id="xtz_msz_g1b">(<persName>Tom Gheldof</persName>) </p>
                    <p xml:id="ytz_msz_g1b">***</p>
                    <p xml:id="ttz_msz_g1b">I have begun working on annotations of places mentioned in Diderot’s 18th-century <title level="j">Encyclopédie</title>, and I am working on the creation of a database of all novelesque works published in French in the eighteenth century. These eighteenth-century projects both use and create LOD. Modeled on the way that my colleague <persName>Jason Ensor</persName> has created a method for annotating metadata for his collection of archival research photos and then exporting it as LOD (<orgName>ARCHivER</orgName>, <ref target="https://www.westernsydney.edu.au/dhrg/digital_humanities/featured/archiver">https://www.westernsydney.edu.au/dhrg/digital_humanities/featured/archiver</ref>), we understand the methodology of using LOD as a cycle. Right now, there are fairly high walls in place if a humanities researcher wants to connect evidence from sources with LOC. How can we break through this barrier and make it easier for scholars to access LOD at different stages of the research process? For example, the historian walks into an archive with a camera, takes photos, makes spreadsheets, and writes notes. Where does LOD enter the sequence? In the French novel database project, LOD becomes part of the project almost at the end of the line. With Ensor’s ARCHivER project, it is integrated immediately after photos are uploaded from an archive trip. The opportunity to feed existing LOD into a collection of historical evidence (in my case) allows me to think about the relationships between the archival evidence and LOD (e.g. a Geonames record). Further along the line, creating LOD from the metadata of my own research documents allows me to imagine new publication environments and future combinations with other data. </p>
                    <p xml:id="utz_msz_g1b">I am interested in understanding what goals humanities scholars have that incorporate LOD, how LOD transforms research methods that are meant to help scholars achieve those goals, and how these new methods produce connection points in usually isolated humanities research projects. Depending on the ways that people use and make LOD, they can forge strong, explicit connections to GLAM repositories or other researchers/collaborative groups. LOD is by definition meant to facilitate these links. How we use them in the humanities will reflect the values we hold about data accessibility and preservation. In my own work, the resources of <orgName>Pleiades</orgName> or of the BnF catalog are gold mines. Using this publicly available data often comes with no responsibility for creating more open data, though many of us will complete the “cycle” and make our new data available. So, what are the ethics of LOD? How do we give credit to the intellectual labor behind the data we use? Is there an opening to create new methods of acknowledging creative work? In considering the ethics of using LOD, we have an opportunity to reframe what “collaborative” research means in the humanities. </p>
                    <p xml:id="p_nlr_p1p_h1b">(<persName>Katherine McDonough</persName>, <persName>Matje van de Camp</persName>)</p>
                    <p xml:id="vtz_msz_g1b">***</p>
                    <p xml:id="qtz_msz_g1b">Linked data provides the framework to facilitate the publication, sharing and linking of data for and by, researchers. While <orgName>Canadiana</orgName> has focused on the large-scale overhaul of its metadata platform that will allow for us to test out LOD mappings and tools, many of our collections lack the metadata at the document level to facilitate the semantic linking and discovery of our extensive digital resources. Collections such as <orgName>Héritage</orgName> contain extensive archival documents organized in reels with thousands of images. As is the nature with most archival content, Héritage has the most information at the Fonds level, and brief descriptive records at the reel level; there is a complete lack of metadata at the document level. In addition most of the content is handwritten, making it difficult to extract useable OCR, and there is a diversity of documents that require different approaches to structuring annotations. Our upgrade of our platform to a <orgName>IIIF</orgName>-compatible system provides the opportunity to incorporate annotations into the presentation layer and to then consider the opportunities for working with researchers to enhance our metadata, provide semantic capabilities, and transform annotations into linked datasets and applications. The goal is to assess how we can enable researchers to annotate, enrich, and reuse their contributed data through current open RDF-compliant frameworks, standards and publishing platforms. In this case involving digital humanities researchers in the development of tools to annotate and semantically enrich our datasets provides the starting point for a dialogue and eventual collaboration whereby we can engage our scholarly communities with our documentary collections. </p>
                    <p xml:id="rtz_msz_g1b">There is a gap in understanding how research annotations can be repurposed towards the goals of linked data with cultural heritage collections. The ability to partner with researchers on these areas would provide the opportunity to enrich our heritage resources and link with existing RDF data on the Semantic Web. This proposal thus aims to be the start of a dialogue with the digital humanities community and its highly engaged and innovative researchers to explore the intersection of DH research and cultural heritage collections, looking at the latest frameworks, standards, and platforms for contributing, linking, and publishing annotations. We will review some challenges in terms of providing enhanced access to our collections, including different types of content requiring flexible annotation approaches, legacy data that requires normalization, reconciliation, and differentiation in order to be used as LOD, as well as assessing the transformation of annotations into linked datasets. Specific examples and use cases will be provided based on our collections and discussion points will centre around the experiences of the DH community in providing annotations and working with linked datasets. As we are in the early stages of moving to the IIIF platform and assessing annotation tools, standards and linked data implications, we are eager to start with considering the potential users of our resources, their roles, requirements, and interactions with cultural heritage data. In addition to case studies and examples from our collections using IIIF, we will have a set of questions to facilitate a discussion around the role of annotations in the context of linked data, how can we leverage the capabilities of the DH community to enhance our metadata and generate new possibilities offered by linking our digital resources with the wider web.</p>
                    <p xml:id="p_l2c_l1p_h1b">(<persName>Julienne Pascoe</persName>)</p>
                </div>
                <div type="chapter">
                    <head>TEI to Linked Data</head>
                    <docAuthor>Pitch #12</docAuthor>
                    <p xml:id="a5z_msz_g1b">Pitch #12: TEI to Linked Data</p>
                    <p xml:id="e5z_msz_g1b">. . . [F]ocus on <orgName>TEI</orgName>, as TEI projects often have rich, interlinked 'ographies built using standard elements. Indeed, many TEI projects are LOD ready. </p>
                    <p xml:id="f5z_msz_g1b">Despite calls in the digital humanities for TEI-LOD compatibility, we have yet to develop tools that bring the two together to create linked data from richly encoded TEI resources. The challenge is to build conversion tools that work with the wide range of materials encoded in TEI (from manuscripts, periodicals, and journals to born-digital texts, metadata, and images). While bespoke experiments with any single TEI-encoded data set would produce engaging linked data, LOD is often a "would be nice to have" part of TEI-encoded projects. This status often makes LOD a line of inquiry that a project team plans to investigate as time and money permit, rather than a core part of project activity. User-friendly workflows and tools could reduce the time commitment that TEI projects which have a peripheral interest in LOD have to invest in order to produce and serve LOD. I have a personal interest in producing TEI-LOD conversion tools, starting with ones for prosopographies, modelled on the TEI's Roma webtool. The key next step for this line of interest is to work out which output formats a tool that maps TEI input onto existing ontologies would be most useful.</p>
                    <p xml:id="g5z_msz_g1b">(<persName>Constance Crompton</persName> and <persName>Michelle Schwartz</persName>)</p>
                    <p xml:id="p_ukf_t1p_h1b">***</p>
                    <p xml:id="b5z_msz_g1b"><orgName>The Kolb-Proust Archive for Research</orgName> was created by digitizing the extensive notecards about <persName>Proust</persName>'s correspondence and life that <persName>Philip Kolb</persName> amassed over his career. Being a <orgName>TEI</orgName>-encoded text collection, the Archive posed a set of unique challenges, more about mapping an outcome of scholarship than about mapping traditional library metadata. Since many texts-based digital humanities collections use TEI as an encoding format, this project opens up several questions that would benefit from community-wide discussion.</p>
                    <p xml:id="c5z_msz_g1b">As described in the TEI webpage (<ref target="http://www.tei-c.org/Guidelines/">http://www.tei-c.org/Guidelines/</ref>) TEI is “a standard for the representation of texts in digital form” not a metadata standard. Mapping from TEI to <ref target="http://schema.org">Schema.org</ref> (LOD-compliant vocabularies) requires unique considerations and workflows. Unlike metadata, a TEI tag identifies a part of a text not an object (a notecard) per se. While mapping TEI tags to Schema.org, we have encountered several questions: Whether a complete TEI document should be represented as an appropriate Schema.org class? Whether every TEI tag necessarily maps to LOD? How to treat the descriptive text blobs that are not encoded with TEI markup? We have tested several versions of mappings and concluded that it is important for context to preserve the boundaries of each notecard. However, questions on how to understand TEI tags in the LOD environment and whether discovery on the web is the most important consideration when transforming TEI-encoded documents into LOD. </p>
                    <p xml:id="p_jpn_pdq_h1b">(<persName><persName>Myung-Ja K. Han</persName>, Timothy W. Cole </persName>, <persName>Jacob Jett</persName>, <persName>Caroline Szylowicz</persName>)</p>
                </div>
                <div type="chapter">
                    <head>The Limits of Open</head>
                    <docAuthor>Pitch #13</docAuthor>
                    <p xml:id="p_oc4_4dq_h1b">Pitch #13: The Limits of Open</p>
                    <p xml:id="p_pc4_4dq_h1b">LOD promises to correct the siloed nature of humanities inquiry—to link previously separate bodies of research, to render them interoperable. In tandem with this promise, it is imperative that the development of LOD technologies integrate the cultural critical lenses developed by communities that have argued most persuasively for the problematic nature of the settler logic of open access. Current LOD projects have been far from apolitical: the premise of <orgName>Canadiana</orgName> and <orgName>Europeana</orgName> is a Western nation-building discourse. <orgName>DINAA</orgName> and <orgName>HuNI</orgName> challenge the western settler colonial ethics of open access by integrating a non-technological reliance on domain-experts and indigenous community members into the project workflow. <orgName>Mukurtu</orgName> alone in content management projects considers cultural access protocols to be integral to its technological substrate. LOD is coming to prominence at the intersection of major advances in data interoperability and of the increasing cultural critical turn in the digital humanities. I wish to ask how LOD may take an intersectional, decolonizing ethics as the basis of its future development in general.</p>
                    <p xml:id="p_fkk_wdq_h1b">(Emily Christina Murphy)</p>
                </div>
                <div type="chapter">
                    <head>Tool Blitz</head>
                    <docAuthor>Pitch #14</docAuthor>
                    <p xml:id="h5z_msz_g1b">Pitch #14: Tool Blitz</p>
                    <p xml:id="i5z_msz_g1b">Lightning demos of tools (<emph>not</emph> of projects) of general applicability that would be of interest to and available for possible adoption by other projects or researchers.</p>
                    <p xml:id="j5z_msz_g1b">If this pitch is a popular choice, we'll put out a call for proposals for tools to present.</p>
                    <p xml:id="k5z_msz_g1b">(<orgName>Program Committee</orgName>)</p>
                </div>
                <div type="chapter">
                    <head>Towards a Better Biblio/Print Culture Ontology</head>
                    <docAuthor>Pitch #15</docAuthor>
                    <p xml:id="l5z_msz_g1b">Pitch #15: Towards a Better Biblio/Print Culture Ontology </p>
                    <p xml:id="m5z_msz_g1b"><orgName>The American Antiquarian Society</orgName> is partnering with the <orgName>Bodleian Library’s British Book Trade Index (BBTI)</orgName> as well as the <orgName>Consortium of European Research Libraries (CERL)</orgName> Thesaurus to create an <orgName>Ontology for the Work of the Early Modern Printing Trade</orgName>. This ontology will conceptually model the roles of people engaged in the European-American printing trades in the handpress and early industrial eras, 1450-1850. It will occupy a unique place in the landscape of existing ontologies and vocabularies describing the occupations of people involved in printing and publishing trades: its chronological breadth, extending into early industrial printing; its geographic focus, including both the American and the European context; its publication format, as linked data freely available on the internet; and its focus on people, rather than imprints. It will bridge gaps between extant ontologies and vocabularies for the printing and publishing trades and be published in a manner that can be both read by humans and manipulated by machines.</p>
                    <p xml:id="n5z_msz_g1b">The BBTI is a comparable resource to the Printers’ File. It, too, offers a way to search for individuals by their role in the book trade, via drop-down list of Book Trade Descriptors, and delves deeply into the specificity of the book trades. However, its list is derived from the British book trades, and the terminology used by the British and the American book trades diverged, with terms having different meanings depending on the country of origin.</p>
                    <p xml:id="o5z_msz_g1b">Unlike BBTI’s Book Trade Descriptors, the <title level="j">Getty Research Institute’s Art &amp; Architecture Thesaurus Online</title> is freely available online as linked data, defines its terms, and places said terms in a relationship model. However, the Art &amp; Architecture Thesaurus Online lacks the specificity needed to illuminate individuals’ roles in the early printing and publishing trades. Although the Art &amp; Architecture Thesaurus Online is comparable to the proposed ontology in structure and in publication format, this ontology is designed for the early modern printing and publishing trades, and it will be able to enrich descriptions of those in said trades. Other vocabularies that take too broad and comprehensive approach to describing historical occupations include the <title level="j">Historical International Classification of Occupations (HISCO)</title> and the <title level="j">Index Terms for Occupations in Archival and Manuscript Collections (ITOAMC)</title>.</p>
                    <p xml:id="p5z_msz_g1b">Like ITOAMC, <title level="j">Relationship Designators for Use in Rare Book and Special Collections Cataloging</title>, maintained by the Rare Books and Manuscripts Section of the <orgName>American Library Association</orgName>, is designed by and for the library community. It takes a book-centric approach to relationships, and its terms define relationships between printed materials and the people involved in their creation. Many terms in the RBMS vocabulary will appear in this ontology, but it does not situate individuals within the printing and publishing trades as this ontology will; instead, it situates individuals within the bibliographic universe of individual imprints in library catalogs. This focus on the individuals rather than our objects will make this ontology useful to CERL and the Bodleian and for potential future projects, other data sets organized around individuals.</p>
                    <p xml:id="p_v1b_v1p_h1b">(<persName>Molly O'Hagan Hardy</persName>)</p>
                </div>
                <div type="chapter">
                    <head>Versioning</head>
                    <docAuthor>Pitch #16</docAuthor>
                    <p xml:id="q5z_msz_g1b">Pitch #16: Versioning</p>
                    <p xml:id="r5z_msz_g1b">As ontologies and instance data evolve there is a significant problem of versioning that needs to be addressed. If links are automatically updated to the most recent version of an ontology, for example, then we run the risk of changing assertions that may have been based on a previous definition of a term or entity. If we don’t automatically update terms then we face the problem of sustaining a huge number of URIs for similar versions of entities, classes, and predicates. This is not only a sustainability problem, but it will increase the already substantial overhead for inference processing.</p>
                    <p xml:id="s5z_msz_g1b">(<persName>Lisa Goddard</persName>)</p>
                </div>
            
            <div>
                <div type="chapter">
                    <head><title>FULL POSITION PAPERS</title></head>
                    <figure>
                        <graphic url="http://beta.cwrc.ca/islandora/object/cwrc%3A733068a5-230e-480f-9351-cbd012de599f/datastream/MEDIUM_SIZE/view"/>
                    </figure>
                    <p xml:id="p_jtn_12x_h1b"><title level="m"><hi rend="bold">FULL POSITION PAPERS</hi></title></p>
                    <p xml:id="t5z_msz_g1b">Contributors were also asked to provide brief position paper on gaps or opportunities re: current Linked Open Data tools and/or ideas for new ways to use LOD in the humanities. Most but not all participants provided a paper. These were sliced, diced and combined as the basis for the <emph>Program Pitches</emph>, above, on which contributors voted to help guide the Program Committee in the formation of the program.</p>
                    <p xml:id="p_zfk_x3q_h1b"><hi rend="italic">Image credit: Linking Open Data cloud diagram 2017, by <persName>Andrejs Abele</persName>, <persName>John P. McCrae</persName>, <persName>Paul Buitelaar</persName>, <persName>Anja Jentzsch</persName> and <persName>Richard Cyganiak</persName>. License: CC BY-SA <ref target="http://lod-cloud.net/">http://lod-cloud.net/</ref></hi> </p>
                </div>
                <div type="chapter">
                    <head><title level="a">Advancing social justice in the LAM, Wikipedia, and Wikidata communities through linked data</title></head>
                    <docAuthor><hi rend="italic"><persName>Stacy Allison-Cassin</persName>, <persName>Joy Kirchner</persName></hi>, <orgName>York University</orgName></docAuthor>
                    <head><title>Advancing social justice in the LAM, Wikipedia, and Wikidata communities through linked data</title> </head>
                    <p xml:id="p_xtb_1bp_h1b">In this current time, issues related to diversity and inclusion, social responsibility, as well as access to information are increasingly coming to the fore. At the same time algorithms are increasingly shaping how people come to understand themselves and the world around them. While digital humanities researchers and those in the GLAM (galleries, libraries, archives and museums) are engaging in projects related to Linked Data there remains a gap in connecting this engagement with questions of diversity and inclusion. Issues related to gender, sexuality and racialization are often hidden in traditional descriptive practices and ontologies, reinforcing problematic practices. </p>
                    <p xml:id="p_ytb_1bp_h1b"><orgName>Wikidata</orgName> is an international community-driven platform and a reliable data store for persistent, common URIs. It is international in scope and already supports a multilingual environment allowing users to work in their language of choice. Properties can be added with community consensus. Because it has a very low threshold for the creation of entities, including the upload of datasets, it possible to think of it as a productive space for the creation of entities outside, or alongside, the more formal bounds of academic institutions and cultural heritage institutions. </p>
                    <p xml:id="p_ztb_1bp_h1b">Working with local communities to understand and create knowledge structures as well as working toward decolonization and inclusive structures is possible with LOD. Numerous projects include some form of crowdsourcing, either in aiding the work of entity recognition or as a means of capturing annotation. While this work is helpful to the work of the project, can this work create a loop back to empower local communities in understanding the digital environment, as a hook for the expansion of advocacy for open data, open access, and the application open licensing of content, and greater access to cultural heritage materials, while also respecting the needs and sensitivities of individual communities. For example issues of ownership, cultural recovery or storytelling. Where does our responsibility lie in the creation of a means of consuming data and providing communities with the use of LOD? How will this figure into alternate models for the consumption of LOD? How do issues of preservation, persistence and control impact traditionally underrepresented communities? </p>
                </div>
                <div type="chapter">
                    <head><title level="a">Collaborative Linked Data Infrastructures</title> </head>
                    <docAuthor><hi rend="italic"><persName>Susan Brown</persName></hi>, <orgName>University of Guelph</orgName> </docAuthor>
                    <head><title>Collaborative Linked Data Infrastructures</title> </head>
                    <p xml:id="pxz_msz_g1b">Several initiatives if undertaken and developed well with input from the LOD community in the humanities could help increase uptake and understanding of the potential of the semantic web. </p>
                    <p xml:id="qxz_msz_g1b"><emph>Natural language sparql query interface for humanities scholars</emph>: This has been attempted but not done well enough to be intuitive and easily usable by humanities scholars. A joint effort in reviewing what exists already, determining what existing code would be most easily adapted for use across a broad range of humanities projects, and developing specs for such an interface would be really useful and potentially lead to a collaborative initiative. </p>
                    <p xml:id="rxz_msz_g1b"><emph>Aggregator widget</emph>: a generic and easily adaptable piece of web code that could be configured to </p>
                    <list>
                        <item>
                            Start from a privileged particular LOD store (i.e. that of the project whose work is being showcased in that particular interface.
                        </item>
                        <item>
                            Look for associated triples/objects by order of priority in a configurable list
                        </item>
                        <item>
                            Provide an organized view of the results, along the lines of the information box generated from the Google Knowledge Graph or the Social Networks and Archival Context (SNAC) project (e.g.
                            <ref target="http://socialarchive.iath.virginia.edu/ark:/99166/w6dz07bk">
                                http://socialarchive.iath.virginia.edu/ark:/99166/w6dz07bk
                            </ref>
                            ), with extensibility to allow for greater interaction with the content such as inviting contributions or sending it to tools.
                        </item>
                    </list>
                    <p xml:id="sxz_msz_g1b"><emph>Contribution Crowdsourcing workflow</emph>: One of the promises of LOD is the potential to have experts contribute casually to the improvement of online resources, whether by annotating, identifying, correcting, transcribing, or linking materials. A generic tool, ideally building on an existing annotation tool, that would support the contributions of external contributors including citizen scholars to scholarly resources, and provide a workflow that would vett the contributions for inclusion/action, either by crowd-sourcing a certain number of approvals, delegating to a group of trusted individuals, or sending through a centralized workflow. <persName>Carl Stahmer</persName> at the <orgName>UC Davis University Library</orgName> has been developing an example of the first type of workflow for the linked data enhancement of the <title level="j">English Short Title Catalogue (ESTC21)</title>. It would be useful to learn what other similar workflows exist and consider whether the use cases are generic enough that it would make sense to collaborate on specs and possibly development. </p>
                </div>
                <div type="chapter">
                    <head><title level="a">Nice to Have: Easing the Conversion of LOD to TEI</title></head>
                    <docAuthor><hi rend="italic"><persName>Constance Crompton</persName></hi>, <orgName>University of Ottawa</orgName>; <hi rend="italic"><persName>Michelle Schwartz</persName></hi>, <orgName>Ryerson University</orgName></docAuthor>
                    <head><title>Nice to Have: Easing the Conversion of LOD to TEI</title> </head>
                    <div type="section">
                        <p xml:id="hxz_msz_g1b">Digital Humanities scholars working on small-to-medium sized projects need clear workflows to show them out to convert their data into LOD and where and how to deposit it so that their LOD can make a meaningful contribution to scholarship. While I am certain that workflows and tools for getting material out of relational databases would be welcome in the community, my personal inclination is to focus on TEI, as TEI projects often have rich, interlinked 'ographies built using standard elements. Indeed, many TEI projects are LOD ready. </p>
                        <p xml:id="ixz_msz_g1b">Despite calls in the digital humanities for TEI-LOD compatibility, we have yet to develop tools that bring the two together to create linked data from richly encoded TEI resources. The challenge is to build conversion tools that work with the wide range of materials encoded in TEI (from manuscripts, periodicals, and journals to born-digital texts, metadata, and images). While bespoke experiments with any single TEI-encoded data set would produce engaging linked data, LOD is often a "would be nice to have" part of TEI-encoded projects. This status often makes LOD a line of inquiry that a project team plans to investigate as time and money permit, rather than a core part of project activity. User-friendly workflows and tools could reduce the time commitment that TEI projects which have a peripheral interest in LOD have to invest in order to produce and serve LOD. I have a personal interest in producing TEI-LOD conversion tools, starting with ones for prosopographies, modelled on the TEI's Roma webtool. The key next step for this line of interest is to work out which output formats a tool that maps TEI input onto existing ontologies would be most useful.</p>
                    </div>
                </div>
                    <div type="chapter">
                        <head><title level="a">Zeri &amp; LODE</title></head>
                        <docAuthor><hi rend="italic"><persName>Marilena Daquino</persName></hi>, <orgName>CRR-MM - University of Bologna</orgName>; <hi rend="italic"><persName>Francesca Mambelli</persName></hi>, <orgName>Fondazione Federico Zeri - University of Bologna</orgName>; <hi rend="italic"><persName>Silvio Peroni</persName></hi>, <orgName>Department of Computer Science and Engineering - University of Bologna</orgName>; <hi rend="italic"><persName>Francesca Tomasi</persName></hi>, <orgName>Department of Classical Philology and Italian Studies - University of Bologna - Italy</orgName>; <hi rend="italic"><persName>Fabio Vitali</persName></hi>, <orgName>Department of Computer Science and Engineering - University of Bologna</orgName></docAuthor>
                        <head><title>Zeri &amp; LODE</title></head>
                        <div type="section">
                            <p xml:id="p_p1z_k4m_kbb">The Art Historical Photo Archive Federico Zeri of the University of Bologna owns one of the most precious European collections of photographs depicting artworks, aside a relevant library of art history and a collection of auction catalogs. The <orgName>Zeri &amp; LODE</orgName> project, as part of the wider <orgName>PHAROS</orgName> project, addresses the data publication of Zeri Photo Archive as Linked Open Data. </p>
                            <p xml:id="p_q1z_k4m_kbb">About 30.000 catalog entries describing photographs, which reproduce about 19.000 works of modern art, are described according to <title level="j">CIDOC-CRM</title> and other few models known in other communities: the <title level="j">SPAR Ontologies</title> from publishing domain to enhance bibliographic descriptions, and <title level="j">HiCO Ontology</title> to make statements about provenance and methodology underlying attributions.</p>
                            <p xml:id="p_r1z_k4m_kbb">Two specular ontologies were realized, called respectively the <title level="j">F Entry Ontology</title> and the <title level="j">OA Entry Ontology</title>, which are capable to represent the expressivity of the above described samples of F/OA Entries. Such ontologies reuse named models and extend them with new classes, predicates and controlled vocabularies, so as to integrate them with CIDOC-CRM terms.</p>
                            <p xml:id="p_s1z_k4m_kbb">Through the use of these models, several common scenarios may be described: a physical description of the cultural object, and its archival collocation (including the description of the hierarchy); roles and events, part of the life cycle of the object (e.g., commission, reproduction, print, change of property and movings); relations between documents, attached to photographs or cited as sources during the cataloguing process; finally, attributions, supported by technical criteria or bibliographic references.</p>
                        </div>
                    </div>
                <div type="chapter">
                    <head><title level="a">Cultural Contact in Early Roman Spain through Linked Open Data</title> </head>
                    <docAuthor><hi rend="italic"><persName>Paula Loreto Granados García</persName></hi>, <orgName>The Open University</orgName> </docAuthor>
                    <head><title>Cultural Contact in Early Roman Spain through Linked Open Data</title> </head>
                    <div type="section">
                        <p xml:id="gvz_msz_g1b">One of the main objectives of my research is to try and explain to historians and archaeologists the benefits of incorporating LOD in their research methodologies and more specifically the benefits that the application of LOD resources will bring to the study of the cultural processes that occurred in <placeName>Spain</placeName> after the Roman arrival. In this sense, the reutilisation of the data already available online although not in a linked open format is one of the main objectives of my study, nevertheless, the barriers of data integration are endless. The users need very advanced knowledge of computer programming languages as well as SPARQL and database developing skills which are obviously not available to everybody. Many of the databases I am looking at do not fulfil one or some of the standards of LOD. In some cases, the data is not in RDF, there is no SPARQL endpoint, there is no API etc. I think one of the possible ways of improving the reuse of data would be to provide specific training on how to overcome these difficulties. In the same way, many of the projects that are starting to publish linked Open data from scratch deal with data coming from very different disciplines making it is difficult to find a unique connecting thread to link all this data together. I think that the election of a common feature such as place to produce this data as a shared reference that everyone can link to would be a very good improvement to facilitate the access to these resources. This is already being achieved by <ref target="http://pelagios.org">Pelagios.org</ref> and the data related to the ancient world but could be applied to many other disciplines in the Digital Humanities. The only way to get Linked Data to really take off as a technological resource capable of advancing humanities research is to get researchers to start working with it. Because of this, I think that some of the main barriers we need to surpass are the lack of training and a more insightful documentation of the projects that are being carried out at the moment so that new users can have a model to look at the time to integrate or link their own data. The improvement of these two will reduce the barriers for beginners to get into the use of this technology. Finally, The next step would be to get all these new researchers to become part of a big community of LOD users as a place to share common difficulties and possible solutions. I expect this workshop to be the appropriate forum for qualified researchers to present their projects and discuss their difficulties and possible ways to advance research in LOD by facilitating the creation of a big community of LOD users. </p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Trismegistos, a Linked Open Data environment for metadata on Ancient World Texts</title> </head>
                    <docAuthor><hi rend="italic">Tom Gheldof</hi>, <orgName>KU Leuven/DARIAH-BE</orgName> </docAuthor>
                    <head><title>Trismegistos, a Linked Open Data environment for metadata on Ancient World Texts</title> </head>
                    <div type="section">
                        <p xml:id="qvz_msz_g1b">As the Trismegistos project focusses on the domain of linked open data in digital (ancient) history, a lot of work remains to be done. Initiatives such as <orgName>EAGLE</orgName> (<ref target="https://www.eagle-network.eu/">https://www.eagle-network.eu/</ref>), PELAGIOS (<ref target="http://commons.pelagios.org/">http://commons.pelagios.org/</ref>) or <orgName>SNAP:DRGN</orgName> (<ref target="https://snapdrgn.net/">https://snapdrgn.net/</ref>) have proven that it is possible to establish a working linked open data environment in their respective field of epigraphy, (ancient) place names and prosopography. Still, a lot of newly founded digital projects in the field of ancient history try to reinvent the wheel with their own vocabularies, data standards, et cetera, mostly because they are unaware of the existence or the possibilities of the existing LOD environments. The TM project believes in a better communication about these tools, as well as documenting their user specifications and requirements. Hence it takes part in initiatives such as the <orgName>Digital Classicist Wiki</orgName> (<ref target="https://wiki.digitalclassicist.org/">https://wiki.digitalclassicist.org/</ref>) or the aforementioned <orgName>Pelagios Commons</orgName>.</p>
                        <p xml:id="rvz_msz_g1b">Another challenge lies in the incorporation of or the collaboration with the cultural heritage sector. For example in disciplines such as papyrology and epigraphy textual sources have been somewhat alienated from the physical documents, and in particular the whereabouts of the text are often neglected. This has led to a situation where museums and other institutions housing the documents often do not have access to the wealth of information collected by academia. Vice-versa academics often lack pieces of information that are only known to those who keep the items safe. Trismegistos is currently trying to bridge this gap (see also the aforementioned collaboration with the <orgName>British Museum</orgName> or the <title level="j">Vienna papyrus collection</title>), but this is a slowly progressing process that is dependent on many factors (e.g., availability of open source material on museum websites and academic publishers, linked open data standards, ...). With initiatives such as <orgName>Trismegistos Collections</orgName> (<ref target="http://www.trismegistos.org/coll/index.php">http://www.trismegistos.org/coll/index.php</ref>), the TM project has undertaken a first step towards a better retrievability of the physical location of papyrological and epigraphic texts in museum and private collections and linking them to academic publications, associated with these texts.</p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Library Linked Data</title> </head>
                    <docAuthor><hi rend="italic"><persName>Lisa Goddard</persName></hi>, <orgName>University of Victoria Libraries</orgName> </docAuthor>
                    <head><title>Library Linked Data</title></head>
                    <div type="section">
                        <head>Preservation and sustainability:</head>
                        <p xml:id="u5z_msz_g1b">One of the key concerns about linked data is the general fragility of URL type links. Studies on link rot reveal a great deal of instability even in well-curated documents like <orgName>Supreme Court</orgName> decisions, and respectable law journals (Lessig et al, 2013). To rely heavily on URIs to external vocabularies and instance data can represent a significant risk to a project, but the imperative to reuse identifiers is a foundational tenet of linked data. Librarians and publishers have already made significant strides towards persistent identifiers like DOIs, Handles, and Perma.cc. We need to collaborate with the DH community around frameworks and infrastructure to steward stable, persistent URIs. </p>
                    </div>
                    <div type="section">
                        <head>Need for APIs:</head>
                        <p xml:id="v5z_msz_g1b">The real benefit of linked data is derived when datasets are tightly interlinked through the reuse of instance URIs and shared vocabularies. DH linked data is often fairly siloed in a single project infrastructure, and only rarely are well-documented HTTP APIs offered to allow machine access to the data store. There is a huge opportunity to collaboratively develop fairly standardized APIs to allow researchers to query, harvest, mash-up, and hack stores of cultural linked data. </p>
                    </div>
                    <div type="section">
                        <head>Tools:</head>
                        <p xml:id="w5z_msz_g1b">We need improved tools for exploring linked data. Most academics are not going to learn SPARQL in order to query linked data stores, just as few people learned SQL in order to query relational databases. Better visualization and discovery tools are essential in order to demonstrate the benefits of linked data (for example, the ability to find connections across degrees of separation), and to drive wider adoption of these technologies. <orgName>Big Diva</orgName> is a good early example of a linked data visualization interface, but we really need more examples that expose the richness and unique capabilities of linked data stores. In order to develop these interfaces, however, we need to be able to query the data via APIs, as above. </p>
                    </div>
                    <div type="section">
                        <head>Versioning:</head>
                        <p xml:id="x5z_msz_g1b">As ontologies and instance data evolve there is a significant problem of versioning that needs to be addressed. If links are automatically updated to the most recent version of an ontology, for example, then we run the risk of changing assertions that may have been based on a previous definition of a term or entity. If we don’t automatically update terms then we face the problem of sustaining a huge number of URIs for similar versions of entities, classes, and predicates. This is not only a sustainability problem, but it will increase the already substantial overhead for inference processing. </p>
                    </div>
                    <div type="section">
                        <head>Certainty:</head>
                        <p xml:id="y5z_msz_g1b">When cataloguing rare and unpublished material librarians often make assertions that are either probable or approximate. It would be useful in a linked data environment to capture the degree of certainty with which an assertion has been made. </p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Linked Pasts</title></head>
                    <docAuthor><hi rend="italic">Karl Grossner</hi>, <orgName>University of Pittsburgh World History Center</orgName> </docAuthor>
                    <head><title>Linked Pasts</title></head>
                    <div type="section">
                        <p xml:id="nwz_msz_g1b">An overarching goal of LOD publication is to enable data sharing for re-use and integration, in turn permitting new analyses and comparative studies. The number of datasets in the LOD “cloud” has doubled in the last few years (from 570 to 1,140) [1]. Those relating to humanities research are by and large bibliographic, geographic, archaeological, and biographical. A large proportion of linked data publishers are in the GLAM domain (galleries, libraries, archives, and museums). These include large scale individual collections (e.g. <orgName>British Museum</orgName> [2]) and aggregation initiatives at various scales, including disciplinary (<orgName>Open Context for archaeology</orgName> [3]), national (<orgName>Mis Museos</orgName> for <placeName>Spain</placeName> [4]) and continental (<orgName>Europeana</orgName> [5]) </p>
                        <p xml:id="owz_msz_g1b">By most accounts, the promise of LOD for humanities research is significant, but not nearly fully realized. We do not yet see large numbers of individual researchers and small project teams publishing linked data, although that would be highly desirable. And we are hard-pressed to identify research projects dependent on LOD for novel results. Impediments to publication include technical difficulty, cost, and an understandable reluctance to share data prior to publication of analytical results. We are still in early stages it seems, and it will be helpful to identify factors that make some efforts successful. </p>
                        <p xml:id="pwz_msz_g1b">The Pelagios project stands out for the way it has facilitated publication of small historical gazetteer datasets. It has produced the <title level="j">Recogito</title> [6] tool, which enables the annotation of “early geographic documents” (texts and maps) for place references, and developed a system for linking multiple such gazetteers to each other. Each participating gazetteer publishes its place records as annotations in an abbreviated “interconnection format,” which Pelagios ingests into a master index. The contents of the resulting aggregated gazetteer are visualized and made searchable in the <title level="j">Peripleo</title> [7] mapping application. Current work includes linking place records to other kinds of data, including named periods, archaeological objects, and people. </p>
                        <p xml:id="qwz_msz_g1b">All of this brings me to <orgName>Linked Pasts</orgName> [8], the Pelagios-sponsored working group mentioned in my bio document. Pelagios has demonstrated effectively that place is a powerful integrating dimension for all sorts of historical data; after all, everything is/was somewhere or happens/happened somewhere. Linked Pasts asks, “how can we as a community best join other categories of historical data to the growing Pelagios graph of places, artifacts and people?”</p>
                        <p xml:id="rwz_msz_g1b">One answer is suggested by the cognate project <orgName>PeriodO</orgName>, which is demonstrating the integrative power of named time periods; in fact, everything has happened at some time or during some period. Another category of data affording integration is that of people—individuals and groups. Peripleo development includes some experimentation along those lines, with an eye towards several large prosopographical projects that are at various stages of development. </p>
                        <p xml:id="swz_msz_g1b">The Linked Pasts Working Group seeks to promote discussion about best practices for integrating both object and people data with places, and we speculate that events and event models may be highly relevant. Events are a powerfully integrative category of data, as demonstrated by their effective modeling in the <orgName>CIDOC-CRM ontology</orgName>, which has arguably seen growing uptake in the GLAM domain. I do not advocate wholesale adoption of CIDOC-CRM—in my view it is far too complex to garner support from small projects—but a simple, upwardly-compatible event data standard may be a worthwhile goal. Comments are welcome at my recent <orgName>Pelagios Commons</orgName> blog post on the topic [9]. </p>
                        <p xml:id="twz_msz_g1b">----</p>
                        <p xml:id="uwz_msz_g1b">[1] <ref target="http://lod-cloud.net/">http://lod-cloud.net/</ref> </p>
                        <p xml:id="vwz_msz_g1b">[2] <ref target="http://www.researchspace.org/">http://www.researchspace.org/</ref> </p>
                        <p xml:id="wwz_msz_g1b">[3] <ref target="https://www.opencontext.org/">https://www.opencontext.org/</ref> </p>
                        <p xml:id="xwz_msz_g1b">[4] <ref target="http://mismuseos.net/comunidad/museos">http://mismuseos.net/comunidad/museos</ref> </p>
                        <p xml:id="ywz_msz_g1b">[5] <ref target="http://www.europeana.eu/portal/en">http://www.europeana.eu/portal/en</ref> </p>
                        <p xml:id="zwz_msz_g1b">[6] <ref target="http://recogito.pelagios.org/">http://recogito.pelagios.org/</ref> </p>
                        <p xml:id="axz_msz_g1b">[7] <ref target="http://pelagios.org/peripleo/map">http://pelagios.org/peripleo/map</ref> </p>
                        <p xml:id="bxz_msz_g1b">[8] <ref target="http://commons.pelagios.org/groups/linked-pasts/">http://commons.pelagios.org/groups/linked-pasts/</ref> </p>
                        <p xml:id="cxz_msz_g1b">[9] <ref target="http://commons.pelagios.org/2017/03/events-and-pelagios/">http://commons.pelagios.org/2017/03/events-and-pelagios/</ref> </p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">TEI to Linked Data: Exploring Opportunities to publish TEI-encoded text collection as Linked Data</title> </head>
                    <docAuthor><hi rend="italic"><persName>Myung-Ja K. Han</persName>, <persName>Timothy W. Cole</persName>, <persName>Jacob Jett</persName>, <persName>Caroline Szylowicz</persName></hi>, <orgName>University of Illinois at Urbana-Champaign</orgName> </docAuthor>
                    <head><title>TEI to Linked Data: Exploring Opportunities to publish TEI-encoded text collection as Linked Data</title></head>
                    <div type="section">
                        <p xml:id="mvz_msz_g1b">The <orgName>Kolb-Proust Archive for Research</orgName> was created by digitizing the extensive notecards about Proust's correspondence and life that <persName>Philip Kolb</persName> amassed over his career. Being a TEI-encoded text collection, the Archive posed a set of unique challenges, more about mapping an outcome of scholarship than about mapping traditional library metadata. Since many texts-based digital humanities collections use TEI as an encoding format, this project opens up several questions that would benefit from community-wide discussion.</p>
                    </div>
                    <div type="section">
                        <head>1. Mapping TEI tags to Schema.org vocabularies</head>
                        <p xml:id="nvz_msz_g1b">As described in the TEI webpage (<ref target="http://www.tei-c.org/Guidelines/">http://www.tei-c.org/Guidelines/</ref>) TEI is “a standard for the representation of texts in digital form” not a metadata standard. Mapping from TEI to <ref target="http://schema.org">Schema.org</ref> (LOD-compliant vocabularies) requires unique considerations and workflows. Unlike metadata, a TEI tag identifies a part of a text not an object (a notecard) per se. While mapping TEI tags to <orgName>Schema.org</orgName>, we have encountered several questions: Whether a complete TEI document should be represented as an appropriate Schema.org class? Whether every TEI tag necessarily maps to LOD? How to treat the descriptive text blobs that are not encoded with TEI markup? We have tested several versions of mappings and concluded that it is important for context to preserve the boundaries of each notecard. However, questions on how to understand TEI tags in the LOD environment and whether discovery on the web is the most important consideration when transforming TEI-encoded documents into LOD. </p>
                    </div>
                    <div type="section">
                        <head>2. Managing local authority work</head>
                        <p xml:id="ovz_msz_g1b">Entities, including personal names, place names, and event names, included in the Archive are very specific to one person, <persName>Marcel Proust</persName>, and his family, i.e., entities found in the collection often are not expressed using established controlled authority names that could provide additional contextual information or authorized forms of names. While trying to reconcile entities with authorized LOD sources, including VIAF and BnF, we also tried to publish information about personal names housed in the local database as Schema,org vocabularies assuming the &lt;schema:Person&gt; class. We analyzed the information included in the database and selected appropriate vocabularies so it can integrate with LOD sources when found. This work was only possible because the local authority control that has been undertaken for the Archive. In the absence of such upfront investment, questions arise, such as what is the best way to ensure the authority work for digitized special collections, and how to make them available as LOD? </p>
                    </div>
                    <div type="section">
                        <head>3. Scholar engagement with LOD</head>
                        <p xml:id="pvz_msz_g1b">While libraries have been busy experimenting with LOD, it is not as well known yet how scholars engage with LOD, e.g., how do they harvest and use published LOD, and what do they want to get out of new LOD-based user services like those mentioned above? LOD promises the possibility of new discovery services and functionalities but, the tools that scholars need to use LOD for research and teaching have not been clearly identified or thoroughly discussed. What is the best way to gather and discuss these needs? </p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">An Ontology for the Work of the Early Modern Printing Trade</title></head>
                    <docAuthor><hi rend="italic"><persName>Molly O'Hagan Hardy</persName></hi>, <orgName>American Antiquarian Society</orgName> </docAuthor>
                    <head><title>An Ontology for the Work of the Early Modern Printing Trade</title></head>
                    <div type="section">
                        <p xml:id="avz_msz_g1b">The <orgName>American Antiquarian Society</orgName> is partnering with the <orgName>Bodleian Library’s British Book Trade Index (BBTI)</orgName> as well as the <orgName>Consortium of European Research Libraries (CERL) Thesaurus</orgName> to create an <orgName>Ontology for the Work of the Early Modern Printing Trade</orgName>. This ontology will conceptually model the roles of people engaged in the European-American printing trades in the handpress and early industrial eras, 1450-1850. It will occupy a unique place in the landscape of existing ontologies and vocabularies describing the occupations of people involved in printing and publishing trades: its chronological breadth, extending into early industrial printing; its geographic focus, including both the American and the European context; its publication format, as linked data freely available on the internet; and its focus on people, rather than imprints. It will bridge gaps between extant ontologies and vocabularies for the printing and publishing trades and be published in a manner that can be both read by humans and manipulated by machines.</p>
                        <p xml:id="bvz_msz_g1b">The BBTI is a comparable resource to the Printers’ File. It, too, offers a way to search for individuals by their role in the book trade, via drop-down list of Book Trade Descriptors, and delves deeply into the specificity of the book trades. However, its list is derived from the British book trades, and the terminology used by the British and the American book trades diverged, with terms having different meanings depending on the country of origin.</p>
                        <p xml:id="cvz_msz_g1b">Unlike BBTI’s Book Trade Descriptors, the <title level="j">Getty Research Institute’s Art &amp; Architecture Thesaurus Online</title> is freely available online as linked data, defines its terms, and places said terms in a relationship model. However, the Art &amp; Architecture Thesaurus Online lacks the specificity needed to illuminate individuals’ roles in the early printing and publishing trades. Although the Art &amp; Architecture Thesaurus Online is comparable to the proposed ontology in structure and in publication format, this ontology is designed for the early modern printing and publishing trades, and it will be able to enrich descriptions of those in said trades. Other vocabularies that take too broad and comprehensive approach to describing historical occupations include the <title level="j">Historical International Classification of Occupations (HISCO)</title> and the <title level="j">Index Terms for Occupations in Archival and Manuscript Collections (ITOAMC)</title>.</p>
                        <p xml:id="dvz_msz_g1b"> Like ITOAMC, <title level="j">Relationship Designators for Use in Rare Book and Special Collections Cataloging</title>, maintained by the Rare Books and Manuscripts Section of the <orgName>American Library Association</orgName>, is designed by and for the library community. It takes a book-centric approach to relationships, and its terms define relationships between printed materials and the people involved in their creation. Many terms in the RBMS vocabulary will appear in this ontology, but it does not situate individuals within the printing and publishing trades as this ontology will; instead, it situates individuals within the bibliographic universe of individual imprints in library catalogs. This focus on the individuals rather than our objects will make this ontology useful to <orgName>CERL</orgName> and the <orgName>Bodleian</orgName> and for potential future projects, other data sets organized around individuals.</p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">The Yellow Nineties</title></head>
                    <docAuthor><hi rend="italic"><persName>Alison Hedley</persName>, <persName>Lorraine Janzen Kooistra</persName></hi>, <orgName>Ryerson University</orgName> </docAuthor>
                    <head><title>The Yellow Nineties</title></head>
                    <div type="section">
                        <p xml:id="xvz_msz_g1b">Linked open data (LOD) principles inform digital humanities scholarship in promising ways. Cultural knowledge exchange—a core value of the humanities—can be fostered on an unprecedented scale through the use of globally unique identifiers that allow for the easy dereferencing of research objects online. However, applying linked open practices to cultural records requires digital humanists to negotiate an irresolvable tension between homogeneity and heterogeneity of data on the Semantic Web. If wielded as a blunt instrument across the Web, the LOD philosophy would impose a universal structure and vocabulary on all linked data in order to ensure their interoperability. Imposing such a structure would mangle data that, through their heterogeneity, reflect the contingencies, ambiguities, and idiosyncrasies of human cultures. </p>
                        <p xml:id="yvz_msz_g1b">Linked open biographical encoding is a key site for negotiating this tension. To date, the field of digital cultural heritage offers few models of LOD praxis that maintain the heterogeneity of biographical data to some degree while implementing an ontology that overlaps as much as possible with other linked open data structures. However, a number of digital humanities initiatives, such as the <orgName>Linked Modernisms Project</orgName> and the <orgName>Canadian Writing and Research Collaboratory</orgName>, are pioneering this work through the biographical components of their respective ontologies. </p>
                        <p xml:id="zvz_msz_g1b"><orgName>The Yellow Nineties (Y90s) Personography</orgName>, a database about the persons who contributed to the periodicals curated by the <orgName>Yellow Nineties Online</orgName>, also aims to contribute to the praxes of linked open biographical encoding. The Y90s Personography’s ontology reflects our ongoing efforts to balance the LOD ideal of universality with the necessary customization of biographical data derived from socio-historical and individual contexts. This balancing act is crucial to how our personographic model argues. We strive in our methods and our outputs to make visible the cultural contingencies that shape the availability of biographical records, and to document persons without eliding the complexities and contradictions of their recorded lives. </p>
                        <p xml:id="awz_msz_g1b">In keeping with LOD principles, the ontology of the Y90s Personography draws on other linked open vocabularies as much as possible. However, the structure of our ontology is necessarily unique to our project; we have discovered no existing model that adequately incorporates Victorian-specific vocabularies and taxonomies. For example, the values and classes of occupations in the Y90s ontology are specific to the Victorian period. This sub-structure of our ontology has no comprehensive precedent among the occupations taxonomies used by major cultural heritage institutions such as the <orgName>Getty Institute</orgName> and the <orgName>Library of Congress</orgName>. We are also investigating methods for documenting the imperialist history of anglicized name variants associated with entities in our personography who were colonial subjects. In many cases, LOD effectively reifies colonialism by including the anglicized variant as the primary designation associated with an individual’s uniform resource identifier (URI) on the Web. By articulating these considerations in our RDF data and in the documentation about our ontology, the Y90s Personography team hopes that our project will offer a productive model for future scholarship that applies LOD principles without sacrificing the heterogeneous character of biographical data.</p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Geospatial and Linguistic LOD</title></head>
                    <docAuthor><hi rend="italic"><persName>Timo Homburg</persName></hi>, PhD Student, <orgName>Mainz University Of Applied Sciences</orgName> </docAuthor>
                    <head><title>Geospatial and Linguistic LOD</title></head>
                    <div type="section">
                        <head>Introduction:</head>
                        <p xml:id="ewz_msz_g1b">In this position paper one example of a possible application of Linguistic Linked Data in the Digital Humanities Which should receive more attention in the community is presented. It is the wish of the author to get into contact with relevant researchers in the field and to investigate in which way they perceive those areas as useful for their own work. </p>
                    </div>
                    <div type="section">
                        <head>Application of Linguistic Linked Open Data:</head>
                        <p xml:id="fwz_msz_g1b">The linguistic linked open data working group (<ref target="http://linguistic-lod.org/llod-cloud">http://linguistic-lod.org/llod-cloud</ref>) is pushing to depict most languages in a Semantic Web representation. This includes word forms, Part-of-Speech Tags, translations, unicode representations, word etymology and senses ususally modelled according to one of the different available standards such as Lemon-RDF. While such resources can play a valuable role in applications such as machine translation, the impact of semantic dictionaries in the Digital Humanities has in the opinion of the author been underrepresented. The author therefore proposes to increasingly link linguistic linked open data with artifacts that are already present on the web in whatever form. A great example of such an interlinkage is the SPARQL endpoint of the <orgName>British museum</orgName> in <placeName>London</placeName> (<ref target="http://collection.britishmuseum.org">http://collection.britishmuseum.org</ref>). Here, artifacts of the museum are highlighted and linked together in a semantic sense. What is usually missing however, is the interlinkage on an inscription text level. With the emergence of linguistic linked data, artifacts could be: </p>
                    </div>
                    <div>
                        <list>
                            <item> Categorized using textual semantics</item>
                            <item>
                                Automatically cross-related to different artifacts/important people of that time or other referenced content recognized from the text
                            </item>
                            <item>
                                Ready for applying data science algorithms to increase knowledge gain from historical objects
                            </item>
                        </list>
                    </div>
                    <div type="section">
                        <head>Application Example:</head>
                        <p xml:id="jwz_msz_g1b">As an application example the author recommends an automated analysis of cuneiform texts present in the <orgName>Cuneiform Digital Library Initiative (CDLI)</orgName> (<ref target="http://cdli.ucla.edu">http://cdli.ucla.edu</ref>) repository. Every cuneiform tablet available would be registered using a URI and properties appended to the cuneiform tablet would be interlinked in an automated fashion. Meanwhile a textual analysis of the cuneiform tablets, typically done via concept matching over nouns and named entities would provide an additional categorization which complements already existing metadata well. In a next step further analysis for co-ocurrence and various other text mining approaches can be tested to extract information previously inaccessible to the domain experts.</p>
                    </div>
                    <div type="section">
                        <head>Possible Benefits:</head>
                        <p xml:id="kwz_msz_g1b">
                            Benefits of the aforementioned approach can be summarized as follows:
                        </p>
                    </div>
                    <div>
                        <list>
                            <item>
                                Accessibility - A universal SPARQL access point for a particular set of cultural heritage objects (here cuneiform tablets) adhering to the linked data principles and interlinked to other knowledge bases
                            </item>
                            <item>
                                Flexible text precategorization and text mining analysis in order to find new correlations of knowledge in already existing non-harvested text repositories
                            </item>
                        </list>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Linking REED London to all the other Londons</title></head>
                    <docAuthor><hi rend="italic"><persName>Diane Jakacki</persName></hi>, <orgName>Bucknell University</orgName></docAuthor>
                    <head><title>Linking REED London to all the other Londons</title></head>
                    <div type="section">
                        <p xml:id="jxz_msz_g1b">My goal for participating in this workshop is to gain a better understanding and develop the vocabulary to articulate ways in which my nascent research project, <orgName>REED London</orgName>, can from its inception integrate best practices for designing its data structure to make it linkable and worth linking from (and to). This need to focus on outward-facing data speaks to a larger challenge as REED London assists in supporting the Records of Early English Drama's shift from a position of closed to open data structures.</p>
                        <p xml:id="kxz_msz_g1b">My association with the <orgName>Records of Early English Drama project</orgName> spans fourteen years. Over that time I have focused on developing electronic means to sustain and strengthen REED's viability as a scholarly and pedagogical resource. I have given a series of conference papers dedicated to questions about how this needs to be considered, including "<ref target="http://dianejakacki.net/data-envy-at-mla-2016/">Data Envy</ref>" (MLA 2016), "<ref target="http://dianejakacki.net/reed-and-the-prospect-of-networked-data/">REED and the Prospect of Networked Data</ref>" (CSRS 2016), "<ref target="http://dianejakacki.net/reed-london-humanistic-roots-humanistic-futures/">REED London: Humanistic Roots, Humanistic Futures</ref>" (MLA 2017). In these presentations I tried to explain the challenges inherent in translating – and transliterating – printed records into electronic format, reconfiguring connections among archival and editorial assets that were envisioned in prescribed (usually spatially) ways, and the need to make the data intra-operable before it can have value in a landscape that needs interoperable or interchangeable data. </p>
                        <p xml:id="lxz_msz_g1b">REED's experience to date with LOD has been focused on establishing ontologies that make sense of REED's entities for REED's "internal" publication purposes. In its first born-digital edition, Staffordshire, the REED staff worked with an EATS/KILN process to develop and publish people, places, and organizations included in the Staffordshire records (see "<ref target="https://ereed.library.utoronto.ca/about/digital/#introduction">REED Online Digital Methodology</ref>" for an outline of REED's current approach to mark-up and entity tagging; see the <ref target="https://eats.readthedocs.io/en/latest/">Entity Authority Tool Set</ref> website for an overview of EATS; see the <ref target="https://wiki.tei-c.org/index.php/Kiln">Kiln TEI wiki</ref> page for an overview of its features and capabilities). With REED London we are at a juncture where we need to think about how to work forward with the <placeName>London</placeName> -centric data, which has obvious value for other research projects beyond performance history, including and political, religious, and cultural studies, and linguistics. At the same time, we need to ensure that the dataset outlined in Staffordshire and developed for further deployment with future REED collections is synchronized with the LOD development we undertake for REED London. </p>
                        <p xml:id="mxz_msz_g1b">Our production and publication methods and the nature of the records means that the REED London project offers an important opportunity to link our data with other projects focusing on complementary subject matter at the same time that we extend the value of these materials to our colleagues in fields Our intention is to provide invaluable open access to transcribed archival resources to researchers focusing on British historical subjects. </p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Linking Early Modern London Toponyms</title></head>
                    <docAuthor><hi rend="italic"><persName>Janelle Jenstad</persName></hi>, <orgName>University of Victoria / MoEML / ISE</orgName> </docAuthor>
                    <head>
                        <title>Linking Early Modern London Toponyms</title>
                    </head>
                    <div type="section">
                        <p xml:id="nxz_msz_g1b">Three potential paths for MoEML’s triples in LINCS are as follows. </p>
                    </div>
                    <div>
                        <list>
                            <item> Other projects use <orgName>MoEML</orgName> ids to handcode and curate their own location entities. REED, ISE, and DRE are already hoping to do so in its new texts and collections. LINCS would enable these projects to realize a long-standing research objective to locate REED, ISE, and DRE locations on MoEML’s maps. If their locations already have ids, LINCS helps build a crosswalk to link their ids to MoEML ids and URIs. These crosswalks are then published on LINCS to facilitate tagging. </item>
                            <item>
                                Other projects use the MoEML-Pantzer, MoEML-GIS, and MoEML-(E)STC crosswalks (published on LINCS) to collocate pre-existing tagging in their texts or fields in their data with MoEML ids. MoEML and DEEP have already used the MoEML-Pantzer crosswalk to parse DEEP’s XML and resolve its Pantzer ids into MoEML ids.
                            </item>
                            <item> MoEML’s gazetteer enables NER to identify London toponyms in untagged, unmodernized early modern texts. <orgName>LINCS</orgName>’ <title level="j">NER</title> tools, coupled with MoEML’s triples, will be able to find new instances of placenames in the EEBO-STC corpus and in the remainder of the <title level="j">EEBO</title>-corpus as OCR’d by eMOP, or in <orgName>Voyant</orgName> ’s <title level="j">DREaM</title> corpus (as tokenized and VARD-standardized by the <orgName>EMC project</orgName>). MoEML will publish these instances with links to their URIs. NER will also help parse location metadata in the prosopographical database proposed by <persName>Brent Nelson</persName>’s <orgName>Early Modern Social Networks</orgName>. Ideally, users would run their data through LINCS NER application, using MoEML’s gazetteer triples to find location entities. </item>
                        </list>
                    </div>
                    <div type="section">
                        <p xml:id="oxz_msz_g1b">LINCS benefits MoEML and similar projects by giving us enough data to answer our research questions, helping us mobilize expertise from a variety of disciplines, and providing a central hub where tools and documentation are available to help cognate projects parse their data, build crosswalks, and link their data. LINCS will provide new projects with the knowledge and tools to make their data LOD-ready from project inception, thus minimizing the silo effect of boutique projects. LINCS can provide out-metrics on the use of MoEML’s cross-walks and triples and help projects track the re-use of their data in other environments. </p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Linked Open Data and Geographic Analysis for Early Modern French Texts</title></head>
                    <docAuthor><hi rend="italic"><persName>Katherine McDonough</persName>, <persName>Matje van de Camp</persName></hi>, <orgName>Western Sydney University</orgName></docAuthor>
                    <head><title>Linked Open Data and Geographic Analysis for Early Modern French Texts</title></head>
                    <div type="section">
                        <p xml:id="kvz_msz_g1b">These eighteenth-century projects both use and create LOD. Modeled on the way that my colleague <persName>Jason Ensor</persName> has created a method for annotating metadata for his collection of archival research photos and then exporting it as LOD (<orgName>ARCHivER</orgName>, <ref target="https://www.westernsydney.edu.au/dhrg/digital_humanities/featured/archiver">https://www.westernsydney.edu.au/dhrg/digital_humanities/featured/archiver</ref>) , we understand the methodology of using LOD as a cycle. Right now, there are fairly high walls in place if a humanities researcher wants to connect evidence from sources with LOC. How can we break through this barrier and make it easier for scholars to access LOD at different stages of the research process? For example, the historian walks into an archive with a camera, takes photos, makes spreadsheets, and writes notes. Where does LOD enter the sequence? In the French novel database project, LOD becomes part of the project almost at the end of the line. With Ensor’s ARCHivER project, it is integrated immediately after photos are uploaded from an archive trip. The opportunity to feed existing LOD into a collection of historical evidence (in my case) allows me to think about the relationships between the archival evidence and LOD (e.g. a <title level="j">Geonames</title> record). Further along the line, creating LOD from the metadata of my own research documents allows me to imagine new publication environments and future combinations with other data. </p>
                        <p xml:id="lvz_msz_g1b">I am interested in understanding what goals humanities scholars have that incorporate LOD, how LOD transforms research methods that are meant to help scholars achieve those goals, and how these new methods produce connection points in usually isolated humanities research projects. Depending on the ways that people use and make LOD, they can forge strong, explicit connections to GLAM repositories or other researchers/collaborative groups. LOD is by definition meant to facilitate these links. How we use them in the humanities will reflect the values we hold about data accessibility and preservation. In my own work, the resources of <orgName>Pleiades</orgName> or of the <title level="j">BnF catalog</title> are gold mines. Using this publicly available data often comes with no responsibility for creating more open data, though many of us will complete the “cycle” and make our new data available. So, what are the ethics of LOD? How do we give credit to the intellectual labor behind the data we use? Is there an opening to create new methods of acknowledging creative work? In considering the ethics of using LOD, we have an opportunity to reframe what “collaborative” research means in the humanities.</p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Investigating Humanities Linked Data by connecting UK projects</title></head>
                    <docAuthor><hi rend="italic"><persName>Sarah Middle</persName></hi>, <orgName>The Open University, UK</orgName></docAuthor>
                    <head><title>Investigating Humanities Linked Data by connecting UK projects</title></head>
                    <div type="section">
                        <p xml:id="svz_msz_g1b">In using a Linked Data approach to explore projects funded by the UK's <orgName>Arts and Humanities Research Council (AHRC)</orgName>, I have identified several issues that may be impeding the progress of Linked Data in Humanities projects. </p>
                        <p xml:id="tvz_msz_g1b">Firstly, it seems that there is often a lack of awareness about the possibilities of Linked Data, leading to a reliance on familiar approaches such as relational databases. Additionally, where Linked Data is considered as an option, the technical barrier may be seen as too high. Both of these issues could be resolved by researchers and developers forming a collaborative relationship, rather than the developers being seen predominantly as service providers. This way of working would ensure that Humanities researchers receive sufficient advice on the data structures that would best allow them to fulfil their research objectives, as well as providing an insight into the development process. For the developers, working with potential users would facilitate the successful development of accessible tools and resources. Both parties would also benefit by learning to speak the other's 'language', which would be extremely valuable when communicating with new colleagues in future collaborations.</p>
                        <p xml:id="uvz_msz_g1b">More opportunities lie not in the production of new datasets and the creation of new resources, but in enhancing existing material. Projects that focus on improving resource usability should increase the reach of the data, making it more accessible to researchers without a technical background, as well as users beyond academia. However, within the AHRC projects dataset, the majority of Linked Data projects seem to focus primarily on data production, with very few concentrating on data consumption or enhancement. If a production-focused project runs out of time or funding before a user-friendly interface can be developed, use of the data is then often restricted to people with the technical skills to use a SPARQL endpoint, greatly reducing the number of potential users.</p>
                        <p xml:id="vvz_msz_g1b">This apparent prioritisation of production over consumption could be due to a real or perceived funder bias towards projects that are seen to be more innovative. To address this, funders should actively encourage proposals for projects that seek to enhance existing resources or perform usability research. Additionally, funders should be prepared to provide small-scale follow-on funding to ensure the data produced by a project is accessible to a wider audience, increasing the potential usage and usefulness of the resulting resource. A demonstrable increase in the scope and use of a resource, the reuse of its data in different contexts, as well as gaining important insights to inform future resource development, should provide an attractive proposition for future funding. </p>
                        <p xml:id="wvz_msz_g1b">The above issues are largely infrastructural, and relate to the shift in ways of working between the 'traditional' and the 'digital' Humanities project. A digital resource should not be a discrete unit that is abandoned at the end of a project, and Linked Data should be a way of ensuring sustainability of such resources by their connection to the wider web, and the reuse of their material. </p>
                    </div>
                </div>
                    <div type="chapter">
                        <head><title level="a">Linked Modernisms</title> </head>
                        <docAuthor><hi rend="italic"><persName>Jana Millar Usiskin</persName></hi>, <orgName>UVic</orgName> PhD candidate; <hi rend="italic"><persName>Stephen Ross</persName></hi>, <orgName>Linked Modernisms</orgName> project lead; <hi rend="italic"><persName>Christine Walde</persName></hi>, <orgName>UVic</orgName> librarian; <hi rend="italic"><persName>Caroline Winter</persName></hi>, <orgName>UVic</orgName>  PhD candidate</docAuthor>
                        <head><title>Linked Modernisms</title></head>
                        <div type="section">
                            <p xml:id="p_hwk_f3n_kbb">Launched in 2015, and frequently updated since, <orgName>Linked Modernisms</orgName> is more than just a powerful tool for browsing, searching, and visualizing information. It is a dynamic platform and interface that allows digital humanities scholars to chart new directions in global modernist studies. </p>
                            <p xml:id="p_iwk_f3n_kbb">Part of the reason why Linked Modernisms is so dynamic, is because it utilizes a custom ontology -- <title level="j">Causabon</title> -- the most comprehensive ontology for describing cultural production yet produced. It was created as a core framework of classes sufficient to cover all the types of entities contained in the <title level="j">Routledge Encyclopedia of Modernism</title> (REM), along with additional sub-classes, properties, and attributes. Causabon was then prototyped using <title level="j">Protégé</title> and adapted so that it would correspond more with more widely used web vocabulary standards (such as FOAF, SKO, OWL, LIBRIS, and DC). </p>
                            <p xml:id="p_jwk_f3n_kbb">Using a combination of natural language-based SPARQL querying and intuitive auto-completion, Linked Modernisms’ powerful system of filters zeroes in on relevant results and adjust the graphs to show only what the user is interested in seeing. Additionally, the algorithm created for Linked Modernisms responds to human feedback on its results so that it continues to learn how to provide better results over time. Constantly evolving in response to both the user and how the user interacts with it, Linked Modernisms has an intelligent series of interoperable parts at its core that anticipates the future of scholarship and information design. As a result, the metadata adjusts itself with each shift in any or all of the other parts. In fact, all the parts change constantly in response to changes in one another. The end result is a platform which is not a static system of enquiry based on dead-end keyword searching, but a rhizomatic hybrid of scholarly enquiry that flattens information into a network of dynamic components that – though it will never be perfect – continues to improve with time. </p>
                            <p xml:id="p_kwk_f3n_kbb">In keeping with modernism's shifting perspectives, an information ontology —a formal method for describing the structure of and relationships between items in a domain— productively allows us to consider modernism from multiple angles as a fluid network of actors, productions and places. And since modernism/modernity is not a fixed series of consequential historical events, but a fluid network of cultural associations and interconnected global activities, Linked Modernisms is the first tool of its kind to visualize and illustrate relevancies and degrees of separation and influence, both directly and indirectly, to help scholars reconceptualize modernism. As such, and in the true spirit of open access and open scholarship, the Linked Modernisms’ ontology is open-source and freely available for download at <ref target="http://linkedmods.uvic.ca/data/ontology.json The entire project’s codebase is also Open Source, at https://github.com/LinkedModernismProject/web_code">http://linkedmods.uvic.ca/data/ontology.json The entire project’s codebase is also Open Source, at https://github.com/LinkedModernismProject/web_code</ref></p>
                        </div>
                    </div>
                <div type="chapter">
                    <head><title level="a">Intersectional (Open) Data: Feminism, Decolonialist Ethics, and the Politics of Linked Open Data</title></head>
                    <docAuthor><hi rend="italic"><persName>Emily Christina Murphy</persName>, <orgName>Queen's University</orgName>; <orgName>Linked Modernisms</orgName>, <orgName>University of Victoria</orgName></hi></docAuthor>
                    <head><title>Intersectional (Open) Data: Feminism, Decolonialist Ethics, and the Politics of Linked Open Data</title></head>
                    <div type="section">
                        <p xml:id="p_u55_c2q_h1b">The present moment in the development of LOD projects is an opportunity to cultivate an intersectional approach to building technologies for curating, preserving, and linking the objects and records of cultural history, Indeed, the linked nature of LOD demands an intersectional ethos. An intersectional approach to data curation has been most prominent in RDF projects like <orgName>The Digital Index of North American Archaeology (DINAA)</orgName> and the <orgName>Australian Humanities Networked Infrastructure Service (HuNI)</orgName> and content management systems like <title level="j">Mukurtu</title>, all of which consider cultural access protocols specific to the currently living populations whose cultural heritage is subject to preservation. I contend that LOD at large must extend these projects. It no longer suffices to consider cultural access protocols exclusively in the context of data curation projects that house the cultural heritage of indigenous peoples. The decolonial logic of these projects should be expanded to LOD curation in general in order to advance an approach to data curation that considers context and history as first principles.</p>
                        <p xml:id="p_v55_c2q_h1b">This position emerges from my work preparing for a <orgName>SSHRC</orgName> post-doctoral project with the <orgName>Linked Modernisms</orgName> project. In my time as a researcher with Linked Modernisms, I will apply LOD technologies to the study of the personal, professional, and artistic networks of early-twentieth century British activist, writer, and editor, <persName>Nancy Cunard</persName>, drawing upon the archived collection of her work at the <orgName>Harry Ransom Center</orgName> at <orgName>University of Texas at Austin</orgName>. I seek to answer two research questions: (1) How can contemporary technologies and social networks change how we understand the nature of women’s artistic and cultural contributions? (2) How can the study of women’s personal and artistic networks change the way we develop technologies for literary and historical inquiry? Cunard may at first seem an unlikely subject of research upon which to develop a decolonial approach to LOD. However, her life’s work concentrated upon social justice advocacy and effected that advocacy through an editorial practice that gathered an astonishing range of writers and other contributors to her edited collections. </p>
                        <p xml:id="p_w55_c2q_h1b">LOD promises to correct the siloed nature of humanities inquiry—to link previously separate bodies of research, to render them interoperable. In tandem with this promise, it is imperative that the development of LOD technologies integrate the cultural critical lenses developed by communities that have argued most persuasively for the problematic nature of the settler logic of open access. Current LOD projects have been far from apolitical: the premise of <orgName>Canadiana</orgName> and <orgName>Europeana</orgName> is a Western nation-building discourse. DINAA and HuNI challenge the western settler colonial ethics of open access by integrating a non-technological reliance on domain-experts and indigenous community members into the project workflow. Mukurtu alone in content management projects considers cultural access protocols to be integral to its technological substrate. LOD is coming to prominence at the intersection of major advances in data interoperability and of the increasing cultural critical turn in the digital humanities. I wish to ask how LOD may take an intersectional, decolonizing ethics as the basis of its future development in general.</p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">Balancing the Needs of Web Publication for Humans and Linked Open Data</title></head>
                    <docAuthor><hi rend="italic"><persName>Dr. Patrick Murray-John</persName></hi>, <orgName>Roy Rosenzweig Center for History and New Media</orgName></docAuthor>
                    <head><title>Balancing the Needs of Web Publication for Humans and Linked Open Data</title></head>
                    <div type="section">
                        <p xml:id="hvz_msz_g1b">In my experience with Omeka Classic and Omeka S, as well as Linked Open Data more generally, I have often encountered a divergence between the needs of easy, flexible, and attractive web publishing for a general audience and the needs of producing and consuming precise and consistent metadata. Because <orgName>Omeka</orgName> (both Classic and S) are primarily web publishing platforms (as opposed, e.g., to a cataloging system), we design the system to encourage good metadata practices, but also need to facilitate the web-publishing needs of our users. This can sometimes led to choices that emphasize public presentation over good metadata practices. For example, a request we received for Omeka classic was to allow HTML to be entered in the <title level="j">Dublin Core</title> metadata fields, with the result that people could and would use the embed code for a YouTube video in the Dublin Core Description field.</p>
                        <p xml:id="ivz_msz_g1b">Other users, of course, are more precise in their use of metadata fields, and Omeka S takes greater pains to enforce interoperable metadata, as outlined above. Indeed, many of the design choices for Omeka S were informed by our experience with Omeka Classic in negotiating the balance of easy website creation (with good metadata), and best Linked Open Data practices (that still allows experts and non-experts alike to build the sites they want to build).</p>
                        <p xml:id="jvz_msz_g1b">I would like to explore this balance, and discuss how others have approached it.</p>
                    </div>
                </div>
                <div type="chapter">
                    <head><title level="a">JazzCats - Jazz Collection of Aggregated Triples</title></head>
                    <docAuthor><hi rend="italic"><persName>Dr Terhi Nurmikko-Fuller</persName>, <persName>Dr Daniel Bangert</persName>, <persName>Dr Alfie Abdul-Rahman</persName></hi>, <orgName>Australian National University</orgName></docAuthor>
                    <head><title>JazzCats - Jazz Collection of Aggregated Triples</title></head>
                    <div type="section">
                        <p xml:id="z5z_msz_g1b">Many DH and GLAM institutions and projects have embraced the LOD model and produced RDF from their data - this is wonderful. But the time is now to stop viewing the production and publication of RDF as the end of a successful workflow. As a community that's been pioneering in LOD development in a lot of ways, we need to begin to plan, design, and realise systems that harness the potential of the LOD cloud, benefit from smarter reasoners, and really move beyond just pushing out RDF. At the same time, we need to develop GUIs that allow users who don't know SPARQL (and have no desire to learn) to benefit (and this appreciate) the power of LOD. </p>
                    </div>
                </div>
                <div type="chapter">
                    <head> <title level="a">Canadiana.org: Annotations and Linked Data</title></head>
                    <docAuthor><hi rend="italic"><persName>Julienne Pascoe</persName></hi>, <orgName><ref target="http://canadiana.org">Canadiana.org</ref></orgName></docAuthor>
                    <head><title>Canadiana.org: Annotations and Linked Data</title></head>
                    <div type="section">
                        <p xml:id="evz_msz_g1b">Linked data provides the framework to facilitate the publication, sharing and linking of data for and by, researchers. While <orgName>Canadiana</orgName> has focused on the large-scale overhaul of its metadata platform that will allow for us to test out LOD mappings and tools, many of our collections lack the metadata at the document level to facilitate the semantic linking and discovery of our extensive digital resources. Collections such as <orgName>Héritage</orgName> contain extensive archival documents organized in reels with thousands of images. As is the nature with most archival content, Héritage has the most information at the Fonds level, and brief descriptive records at the reel level; there is a complete lack of metadata at the document level. In addition most of the content is handwritten, making it difficult to extract useable OCR, and there is a diversity of documents that require different approaches to structuring annotations. Our upgrade of our platform to a IIIF-compatible system provides the opportunity to incorporate annotations into the presentation layer and to then consider the opportunities for working with researchers to enhance our metadata, provide semantic capabilities, and transform annotations into linked datasets and applications. The goal is to assess how we can enable researchers to annotate, enrich, and reuse their contributed data through current open RDF-compliant frameworks, standards and publishing platforms. In this case involving digital humanities researchers in the development of tools to annotate and semantically enrich our datasets provides the starting point for a dialogue and eventual collaboration whereby we can engage our scholarly communities with our documentary collections.</p>
                        <p xml:id="fvz_msz_g1b">There is a gap in understanding how research annotations can be repurposed towards the goals of linked data with cultural heritage collections. The ability to partner with researchers on these areas would provide the opportunity to enrich our heritage resources and link with existing RDF data on the Semantic Web. This proposal thus aims to be the start of a dialogue with the digital humanities community and its highly engaged and innovative researchers to explore the intersection of DH research and cultural heritage collections, looking at the latest frameworks, standards, and platforms for contributing, linking, and publishing annotations. We will review some challenges in terms of providing enhanced access to our collections, including different types of content requiring flexible annotation approaches, legacy data that requires normalization, reconciliation, and differentiation in order to be used as LOD, as well as assessing the transformation of annotations into linked datasets. Specific examples and use cases will be provided based on our collections and discussion points will centre around the experiences of the DH community in providing annotations and working with linked datasets. As we are in the early stages of moving to the IIIF platform and assessing annotation tools, standards and linked data implications, we are eager to start with considering the potential users of our resources, their roles, requirements, and interactions with cultural heritage data. In addition to case studies and examples from our collections using IIIF, we will have a set of questions to facilitate a discussion around the role of annotations in the context of linked data, how can we leverage the capabilities of the DH community to enhance our metadata and generate new possibilities offered by linking our digital resources with the wider web.</p>
                    </div>
                </div>
                    <div type="chapter">
                        <head><title level="a">Discovering Literature' in the BBC's Research and Education Space (RES) Project</title> </head>
                        <docAuthor><hi rend="italic"><persName>Mia Ridge</persName></hi>, <orgName>British Library</orgName></docAuthor>
                        <head><title>Discovering Literature' in the BBC's Research and Education Space (RES) Project</title></head>
                        <div type="section">
                            <p xml:id="p_xwz_skn_kbb">We reviewed the material most likely to be suitable for a schools audience. <orgName>Discovering Literature</orgName> is a free educational resource that puts manuscript and printed collection items in historical, cultural and political context. The Romantics and Victorians site includes thousands of collection items, hundreds of articles, films, teachers’ notes and more to help make collection items more accessible. Having selected a resource, we worked out which vocabularies to apply to describe people, the works they created, the collection items used to illustrate articles, the articles themselves, etc. Where possible, we linked to existing vocabularies, but some terms were unique to the Library. We posted work in progress online (<ref target="http://museum-api.pbworks.com/w/page/111197071/British%20Library%20BBC%20RES%20data%20modelling">http://museum-api.pbworks.com/w/page/111197071/British%20Library%20BBC%20RES%20data%20modelling</ref>) so that other people could review and comment on our work. The Library's content management system was updated to produce Turtle files for each relevant page, and a VOID file provided the entry point for the RES crawler.</p>
                        </div>
                    </div>
                <div type="chapter">
                    <head><title level="a">Setting local culture on a global stage with Wikidata</title></head>
                    <docAuthor><hi rend="italic"><persName>Dan Scott</persName></hi>, <orgName>Laurentian University</orgName></docAuthor>
                    <head><title>Setting local culture on a global stage with Wikidata</title></head>
                    <div type="section">
                        <p xml:id="dxz_msz_g1b">Researchers and practitioners have demonstrated an encouraging understanding and embrace of the principles of publishing five-star LOD. Datahub.io catalogues over 11,000 linked data sets (<ref target="https://datahub.io/dataset">https://datahub.io/dataset</ref>), although many of these data sets do not specify an open license and are thus LD, not LOD; or their license requires attribution, which can be cumbersome when integrating data from many different data sets; or the data is not offered in a linked format. These are all barriers that prevent digital humanists from using LOD tools and methodologies to incorporate the data in their work.</p>
                        <p xml:id="exz_msz_g1b">We must also acknowledge the prevalence of non-LOD practices by memory institutions like libraries, archives, and galleries that continue to describe entities such as people, texts, fonds, art, music, and events using traditional techniques and formats. Even the use of authority fields in a "machine readable" format such as MARC that does link to a data set often leads to the barest additional data; in the case of the <orgName>Virtual International Authority File (VIAF)</orgName>, birth and death dates, a sampling of works to which the person has contributed, and selected publishers is typical. There is no richness in the representation of the human being central to the work: no expression of relationships to others outside of potential collaborations, or to events in which they participated, or the lives they have lived, or samples of their work, or images, or videos.</p>
                        <p xml:id="fxz_msz_g1b">Many of the traditional centralized data sets for memory institutions impose barriers to participation. For an author, musician, or artist to surface in VIAF, they must appear in records contributed to <orgName>WorldCat</orgName> by a library that is a member of <orgName>OCLC</orgName>; not only does this rule out many libraries that cannot afford an OCLC cataloguing membership, but it also prevents individuals from contributing to the data set. As a result, the perspectives of that subset of libraries that can afford the financial and resource cost of a membership are privileged, and a band like <title level="j">A Tribe Called Red</title> that has received multiple Juno awards has only a skeletal presence (<ref target="http://viaf.org/viaf/308795327">http://viaf.org/viaf/308795327</ref>); individual band members, such as <persName>Deejay NDN aka Ian Campeau</persName>, are not represented at all in VIAF.</p>
                        <p xml:id="gxz_msz_g1b">A potential solution is to adopt <orgName>Wikidata</orgName> as a ready-to-hand tool, only publishing data outside of Wikidata when its constraints demand an augmented solution. By requiring the <title level="j">Creative Commons Zero</title> dedication for all contributions, Wikidata's truly open dataset can be used for any purpose. Its SPARQL endpoint supports dynamic use by standard LOD tools, while the complete dataset can be mirrored for more intense local use. Memory institutions, researchers, and practitioners can adopt Wikidata as not only a source of authority data, but can independently add new entities and extend existing descriptions to reflect local culture in a global database--and they can dynamically integrate Wikidata's rich representations of people, places, and events back into their own collections and works.</p>
                    </div>
                </div>
                    <div type="chapter">
                        <head><title level="a">LITMUS (Linked Irish Traditional MUSic)</title></head>
                        <docAuthor><hi rend="italic"><persName>Lynnsey Weissenberger</persName></hi>, <orgName>Irish Traditional Music Archive</orgName></docAuthor>
                        <head><title>LITMUS (Linked Irish Traditional MUSic)</title></head>
                        <div type="section">
                            <p xml:id="p_ems_rjn_kbb">As there is a need to expand available ontologies for music to better accommodate what occurs within oral transmission, <orgName>LITMUS</orgName> focuses on the development of the first linked data ontology specifically to address the needs of Irish traditional song, instrumental music, and dance–and by extension serve as a reference point for other linked data projects involving orally-based music traditions. Once completed, the ontology will enable future opportunities for digital discovery, exploration, and facilitate meaningful research connections in a variety of humanities and social science disciplines. Our target audience includes academic and practitioner communities within music librarianship; digital cultural heritage; digital humanities; linked data and computing in libraries, archives, and museums (LODLAM); ethnomusicology; folklore; and, anthropology. In addition, we remain connected to the music and dance practitioner communities in <placeName>Ireland</placeName> and abroad, who will also benefit when the ontology is employed within linked data frameworks.</p>
                        </div>
                    </div>
                    <div type="chapter">
                        <head><title level="a">Oxford Text Archive</title></head>
                        <docAuthor><hi rend="italic"><persName>Martin Wynne</persName></hi>, <orgName>University of Oxford</orgName></docAuthor>
                        <head><title>Oxford Text Archive</title></head>
                        <div type="section">
                            <p xml:id="p_wvl_hhm_kbb">The <orgName>Oxford Text Archive</orgName> develops, collects, catalogues and preserves electronic literary and linguistic resources for use in Higher Education, in research, teaching and learning. </p>
                        </div>
                    </div>
            </div>
            <div type="index">
                <list>
                    <item><ref target="gmz_msz_g1b">ancient history</ref></item>
                    <item><ref target="pnz_msz_g1b">ancient languages</ref></item>
                    <item><ref target="gmz_msz_g1b">ancient world texts</ref></item>
                    <item><ref target="dlz_msz_g1b">annotations</ref></item>
                    <item><ref target="fnz_msz_g1b ynz_msz_g1b">archaeology</ref></item>
                    <item><ref target="v4z_msz_g1b p_i2s_j11_h1b">archives</ref></item>
                    <item><ref target="pmz_msz_g1b">Arts and Humanities Research Council</ref></item>
                        <item><ref target="p_szp_hjm_kbb">attribution</ref></item>
                    <item><ref target="dpz_msz_g1b">authority names</ref></item>
                        <item><ref target="p_szp_hjm_kbb">authorship</ref></item>
                    <item><ref target="vkz_msz_g1b p_gyv_22m_kbb">bibliography</ref></item>
                    <item><ref target="ymz_msz_g1b">biography</ref></item>
                    <item><ref target="vkz_msz_g1b">book history</ref></item>
                    <item><ref target="r4z_msz_g1b">Canada</ref></item>
                    <item><ref target="vkz_msz_g1b">catalog</ref></item>
                    <item><ref target="spz_msz_g1b">collaboration</ref></item>
                    <item><ref target="llz_msz_g1b">cultural contact</ref></item>
                    <item><ref target="dlz_msz_g1b pnz_msz_g1b p_i2s_j11_h1b">cultural heritage</ref></item>
                    <item><ref target="fnz_msz_g1b">cyberinfrastructure</ref></item>
                        <item><ref target="p_oqw_r3n_kbb">dance</ref></item>
                    <item><ref target="vlz_msz_g1b">database</ref></item>
                    <item><ref target="pmz_msz_g1b">data consumption</ref></item>
                    <item><ref target="llz_msz_g1b">data integration </ref></item>
                    <item><ref target="pmz_msz_g1b">data production</ref></item>
                    <item><ref target="knz_msz_g1b">decolonial ethics</ref></item>
                    <item><ref target="knz_msz_g1b">decolonization</ref></item>
                    <item><ref target="pnz_msz_g1b">dictionaries</ref></item>
                    <item><ref target="kkz_msz_g1b">digital asset management</ref></item>
                    <item><ref target="knz_msz_g1b">digital cultural history</ref></item>
                    <item><ref target="dlz_msz_g1b gmz_msz_g1b p_i3s_pfn_kbb">digital humanities</ref></item>
                    <item><ref target="bmz_msz_g1b">digital repository</ref></item>
                    <item><ref target="p_i2s_j11_h1b">diversity</ref></item>
                    <item><ref target="llz_msz_g1b">Early Roman Spain</ref></item>
                    <item><ref target="vlz_msz_g1b">eighteenth century</ref></item>
                        <item><ref target="p_gyv_22m_kbb">english</ref></item>
                    <item><ref target="vlz_msz_g1b">ethics</ref></item>
                    <item><ref target="knz_msz_g1b">feminism</ref></item>
                    <item><ref target="pmz_msz_g1b">funding</ref></item>
                    <item><ref target="vlz_msz_g1b dpz_msz_g1b">gazetteer</ref></item>
                    <item><ref target="dpz_msz_g1b">GIS</ref></item>
                    <item><ref target="r4z_msz_g1b">graph databases</ref></item>
                    <item><ref target="v4z_msz_g1b">history</ref></item>
                    <item><ref target="ynz_msz_g1b">historical gazetteers</ref></item>
                    <item><ref target="ynz_msz_g1b">historical journeys and routes</ref></item>
                        <item><ref target="p_gyv_22m_kbb">historical texts</ref></item>
                    <item><ref target="kkz_msz_g1b">hydra</ref></item>
                        <item><ref target="p_i3s_pfn_kbb">information</ref></item>
                    <item><ref target="pmz_msz_g1b spz_msz_g1b">infrastructure</ref></item>
                    <item><ref target="knz_msz_g1b">intersectionality</ref></item>
                        <item><ref target="p_oqw_r3n_kbb">Ireland</ref></item>
                    <item><ref target="qkz_msz_g1b">jazz music</ref></item>
                    <item><ref target="dpz_msz_g1b">JSON</ref></item>
                    <item><ref target="kkz_msz_g1b j4z_msz_g1b p_i2s_j11_h1b p_jnt_d3y_31b">libraries</ref></item>
                    <item><ref target="kkz_msz_g1b dlz_msz_g1b llz_msz_g1b bmz_msz_g1b gmz_msz_g1b pmz_msz_g1b ymz_msz_g1b ipz_msz_g1b">linked open data</ref></item>
                    <item><ref target="ynz_msz_g1b">living archive</ref></item>
                    <item><ref target="j4z_msz_g1b p_jnt_d3y_31b">local culture</ref></item>
                    <item><ref target="ipz_msz_g1b">LOD for improving user experience</ref></item>
                    <item><ref target="ipz_msz_g1b">LOD for special digital collections</ref></item>
                    <item><ref target="v4z_msz_g1b dpz_msz_g1b">London</ref></item>
                        <item><ref target="p_i3s_pfn_kbb">machine reasoning</ref></item>
                    <item><ref target="fnz_msz_g1b">material culture</ref></item>
                    <item><ref target="j4z_msz_g1b p_jnt_d3y_31b">memory institutions</ref></item>
                    <item><ref target="kkz_msz_g1b qkz_msz_g1b dlz_msz_g1b gmz_msz_g1b p_i3s_pfn_kbb">metadata</ref></item>
                    <item><ref target="qlz_msz_g1b">metadata creation</ref></item>
                    <item><ref target="vlz_msz_g1b">methods</ref></item>
                        <item><ref target="p_i3s_pfn_kbb">modernism</ref></item>
                        <item><ref target="p_i3s_pfn_kbb">modernity</ref></item>
                        <item><ref target="p_oqw_r3n_kbb">music</ref></item>
                    <item><ref target="qlz_msz_g1b">omeka</ref></item>
                    <item><ref target="ymz_msz_g1b fnz_msz_g1b pnz_msz_g1b p_szp_hjm_kbb p_i3s_pfn_kbb p_oqw_r3n_kbb">ontology</ref></item>
                        <item><ref target="p_oqw_r3n_kbb">oral transmission</ref></item>
                    <item><ref target="v4z_msz_g1b">performance</ref></item>
                    <item><ref target="ymz_msz_g1b dpz_msz_g1b">personography</ref></item>
                        <item><ref target="p_szp_hjm_kbb">photo archive</ref></item>
                    <item><ref target="pmz_msz_g1b">project classification</ref></item>
                    <item><ref target="pmz_msz_g1b">projects</ref></item>
                    <item><ref target="qkz_msz_g1b vkz_msz_g1b">prosopography</ref></item>
                        <item><ref target="p_i3s_pfn_kbb">protege</ref></item>
                    <item><ref target="r4z_msz_g1b">queer studies</ref></item>
                    <item><ref target="vkz_msz_g1b">rare books</ref></item>
                    <item><ref target="kkz_msz_g1b fnz_msz_g1b">RDF</ref></item>
                    <item><ref target="qkz_msz_g1b">RDF workflow</ref></item>
                    <item><ref target="pmz_msz_g1b">research methods</ref></item>
                    <item><ref target="ipz_msz_g1b">schema.org</ref></item>
                    <item><ref target="ipz_msz_g1b">scholar engagement with LOD</ref></item>
                    <item><ref target="bmz_msz_g1b">searching</ref></item>
                    <item><ref target="pnz_msz_g1b">semantics</ref></item>
                    <item><ref target="dlz_msz_g1b fnz_msz_g1b">semantic web</ref></item>
                    <item><ref target="r4z_msz_g1b ipz_msz_g1b">TEI</ref></item>
                    <item><ref target="v4z_msz_g1b">theatre</ref></item>
                    <item><ref target="bmz_msz_g1b">thesaurus</ref></item>
                    <item><ref target="dpz_msz_g1b">toponyms</ref></item>
                    <item><ref target="dlz_msz_g1b">transcriptions</ref></item>
                    <item><ref target="dpz_msz_g1b">variant names</ref></item>
                    <item><ref target="ymz_msz_g1b">Victorian</ref></item>
                        <item><ref target="p_i3s_pfn_kbb">visualization</ref></item>
                    <item><ref target="qlz_msz_g1b">web publishing</ref></item>
                    <item><ref target="j4z_msz_g1b p_i2s_j11_h1b p_jnt_d3y_31b">wikidata</ref></item>
                    <item><ref target="knz_msz_g1b spz_msz_g1b">women's writing</ref></item>
                </list>
            </div>
            </div>
        </body>
    </text>
</TEI>
